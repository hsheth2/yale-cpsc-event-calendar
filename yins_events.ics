BEGIN:VCALENDAR
X-WR-CALDESC:Yale Institute for Network Sciences (YINS)
X-WR-CALNAME:YINS Events
BEGIN:VEVENT
SUMMARY:YINS Seminar: Patrick Shafto (Rutgers)
DTSTART:20221109T170000
DTEND:20221109T180000
DESCRIPTION:Event description:\nYINS Seminar\n\n“Mathematical foundation
 s for human and machine cooperation”\n\nSpeaker: Patrick Shafto\nMember 
 of the School of Mathematics at the Institute for Advanced Study\, Princet
 on\nProfessor of Mathematics and Computer Science at Rutgers University - 
 Newark\n\nAbstract:\nAI plays an increasing role in society\, with uncerta
 in long run consequences. We present a mathematical framework that formali
 zes cooperation using tools from mathematical theory of Optimal Transport.
  We illustrate by analyzing the elemental problem of cooperatively communi
 cating agents\, which plays a key role in theories of learning\, developme
 nt\, and culture. We derive provable properties of cooperatively communica
 ting agents and analyze prior models in cognitive science\, machine learni
 ng\, and robotics as special cases. We conclude with prospects for unified
  mathematical foundations for understanding the possibilities and pitfalls
  of dynamic networks of humans and machines in society.\n\nSpeaker bio:\nD
 r. Patrick Shafto is Member of the School of Mathematics at the Institute 
 for Advanced Study\, Princeton and Professor of Mathematics and Computer S
 cience at Rutgers University - Newark. Research in his lab focuses on math
 ematical foundations of learning in humans and machines. His research has 
 been supported by NSF (EHR\, CISE\, SBE)\, DARPA\, DoD\, NIH\, and the int
 elligence community and has formed the basis for multiple successful machi
 ne learning start-up companies.\n\nAdd event to calendar\n\n\n\n\n\n\n\n.\
 n\n\nhttps://yins.yale.edu/event/yins-seminar-patrick-shafto-rutgers
LOCATION:Yale Institute for Network Science
STATUS:CONFIRMED
URL:https://yins.yale.edu/event/yins-seminar-patrick-shafto-rutgers
END:VEVENT
BEGIN:VEVENT
SUMMARY:FDS Seminar: Priya Panda
DTSTART:20221109T210000
DTEND:20221109T220000
DESCRIPTION:Event description:\nFDS Seminar\n\n“Exploring Robustness and
  Energy-Efficiency in Neural Systems with Spike-based Machine Intelligence
 ”\n\nSpeaker: Priya Panda\nAssistant Professor\, Electrical Engineering\
 , Yale University\n\nAbstract:\nSpiking Neural Networks (SNNs) have recent
 ly emerged as an alternative to deep learning due to their huge energy eff
 iciency benefits on neuromorphic hardware. In this presentation\, I will t
 alk about important techniques for training SNNs which bring a huge benefi
 t in terms of latency\, accuracy\, interpretability\, and robustness. We w
 ill first delve into how training is performed in SNNs. Training SNNs with
  surrogate gradients presents computational benefits due to short latency.
  However\, due to the non-differentiable nature of spiking neurons\, the t
 raining becomes problematic and surrogate methods have thus been limited t
 o shallow networks. To address this training issue with surrogate gradient
 s\, we will go over a recently proposed method Batch Normalization Through
  Time (BNTT) that allows us to train SNNs from scratch with very low laten
 cy and enables us to target interesting applications like video segmentati
 on and beyond traditional learning scenarios\, like federated training. An
 other critical limitation of SNNs is the lack of interpretability. While a
  considerable amount of attention has been given to optimizing SNNs\, the 
 development of explainability still is at its infancy. I will talk about o
 ur recent work on a bio-plausible visualization tool for SNNs\, called Spi
 ke Activation Map (SAM) compatible with BNTT training. The proposed SAM hi
 ghlights spikes having short inter-spike interval\, containing discriminat
 ive information for classification. Finally\, with proposed BNTT and SAM\,
  I will highlight the robustness aspect of SNNs with respect to adversaria
 l attacks. In the end\, I will talk about interesting prospects of SNNs fo
 r non-conventional learning scenarios such as privacy-preserving distribut
 ed learning as well as unraveling the temporal correlation in SNNs with fe
 edback connections. Finally\, time permitting\, I will talk about the pros
 pects of SNNs for novel and emerging compute-in-memory hardware that can p
 otentially yield order of magnitude lower power consumption than conventio
 nal CPUs/GPUs.\n\nBio:\nPriya Panda is an assistant professor in the elect
 rical engineering department at Yale University\, USA. She received her B.
 E. and Master’s degree from BITS\, Pilani\, India in 2013 and her PhD fr
 om Purdue University\, USA in 2019. During her PhD\, she interned in Intel
  Labs where she developed large scale spiking neural network algorithms fo
 r benchmarking the Loihi chip. She is the recipient of the 2019 Amazon Res
 earch Award\, 2022 Google Research Scholar Award\, 2022 DARPA Riser Award.
  Her research interests lie in Neuromorphic Computing\, energy-efficient a
 ccelerators\, in-memory processing among others.\n\nIn-person talk\, but r
 emote access available here:\nhttps://yale.hosted.panopto.com/Panopto/Page
 s/Viewer.aspx?id=f20086eb-012d-4ead-a949-af1c01268d6d\n\nAdd event to cale
 ndar\n\n\n\n\n\n\n\n.\n\n\nhttps://yins.yale.edu/event/fds-seminar-priya-p
 anda
LOCATION:DL220
STATUS:CONFIRMED
URL:https://yins.yale.edu/event/fds-seminar-priya-panda
END:VEVENT
BEGIN:VEVENT
SUMMARY:YINS Seminar: Florian Ederer
DTSTART:20221130T170000
DTEND:20221130T180000
DESCRIPTION:Event description:\nYINS Seminar\n\n“A Tale of Two Networks:
  Common Ownership and Product Market Rivalry”\n\nSpeaker: Florian Ederer
 \nAssociate Professor of Economics\, Yale School of Management\n\n\n\nAbst
 ract:\nWe study the welfare implications of the rise of common ownership i
 n the United States from 1994 to 2018. We build a general equilibrium mode
 l with a hedonic demand system in which firms compete in a network game of
  oligopoly. Firms are connected through two large networks: the first refl
 ects ownership overlap\, the second product market rivalry. In our model\,
  common ownership of competing firms induces unilateral incentives to soft
 en competition. The magnitude of the common ownership effect depends on ho
 w much the two networks overlap. We estimate our model for the universe of
  U.S. public corporations using a combination of firm financials\, investo
 r holdings\, and text-based product similarity data. We perform counterfac
 tual calculations to evaluate how the efficiency and the distributional im
 pact of common ownership have evolved over time. According to our baseline
  estimates the welfare cost of common ownership\, measured as the ratio of
  deadweight loss to total surplus\, has increased nearly tenfold (from 0.3
 % to over 4%) between 1994 and 2018. Under alternative assumptions about g
 overnance\, the deadweight loss ranges between 1.9% and 4.4% of total surp
 lus in 2018. The rise of common ownership has also resulted in a significa
 nt reallocation of surplus from consumers to producers.\n\n\n\nhttps://www
 .nber.org/papers/w30004\n\n\n\n\nSpeaker Bio:\nFlorian Ederer is an Associ
 ate Professor of Economics at the Yale School of Management\, a Research S
 taff Member at the Cowles Foundation for Research in Economics\, and an NB
 ER faculty research fellow. Professor Ederer’s research\, which has been
  widely published in leading journals\, is in the areas of organizational 
 economics\, innovation\, and antitrust. Some of his recent work explores t
 he impact of networks of common ownership on managerial compensation and p
 roduct market competition and the existence and pervasiveness of “killer
  acquisitions” that prevent startups from challenging dominant market in
 cumbents. In his academic work he draws on a broad set of tools often comb
 ining theoretical models\, experimental methods\, and empirical analysis. 
 Prior to joining the Yale School of Management Professor Ederer was a facu
 lty member of the UCLA Anderson School of Management. He earned his doctor
 ate in economics at the Massachusetts Institute for Technology and his mas
 ter’s and undergraduate degrees from the University of Oxford.\n\n\n\nTh
 is is an in-person event\, with remote access available here:\nhttps://yal
 e.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=1e08bc99-13d1-4da1-9e8d-
 af4100f1e59f\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.\n\n\nhtt
 ps://yins.yale.edu/event/yins-seminar-florian-ederer
LOCATION:Yale Institute for Network Science
STATUS:CONFIRMED
URL:https://yins.yale.edu/event/yins-seminar-florian-ederer
END:VEVENT
BEGIN:VEVENT
SUMMARY:FDS Seminar: John Langford (Microsoft Research)
DTSTART:20221207T210000
DTEND:20221207T220000
DESCRIPTION:Event description:\nFDS Seminar\n\nSpeaker: John Langford\nMic
 rosoft Research New York\n\nThis is an in-person seminar\, with remote acc
 ess available:\nhttps://yale.hosted.panopto.com/Panopto/Pages/Viewer.aspx?
 id=1a9628bf-c5c4-4830-948b-af420136ee87\n\n\nhttps://yins.yale.edu/event/f
 ds-seminar-john-langford-microsoft-research
LOCATION:DL220
STATUS:CONFIRMED
URL:https://yins.yale.edu/event/fds-seminar-john-langford-microsoft-resear
 ch
END:VEVENT
BEGIN:VEVENT
SUMMARY:FDS Seminar: Robert Schapire (Microsoft)
DTSTART:20221214T210000
DTEND:20221214T220000
DESCRIPTION:Event description:\nFDS Seminar\n\n“Convex Analysis at Infin
 ity: An Introduction to Astral Space”\n\nSpeaker: Robert Schapire\nMicr
 osoft Research\n\nAbstract:\nNot all convex functions have finite minimize
 rs\; some can only be minimized by a sequence as it heads to infinity.  I
 n this work\, we aim to develop a theory for understanding such minimizers
  at infinity.  We study\nastral space\n\, a compact extension of Euclidea
 n space to which such points at infinity have been added.  Astral space i
 s constructed to be as small as possible while still ensuring that all lin
 ear functions can be continuously extended to the new space.  Although no
 t a vector space\, nor even a metric space\, astral space is nevertheless 
 so well-structured as to allow useful and meaningful extensions of such co
 ncepts as convexity\, conjugacy\, and subdifferentials.  We develop these
  concepts and analyze various properties of convex functions on astral spa
 ce\, including the detailed structure of their minimizers\, exact characte
 rizations of continuity\, and convergence of descent algorithms.\n\nThis i
 s joint work with Miroslav Dudík and Matus Telgarsky.\n\nSpeaker bio:\nRo
 bert Schapire is a Partner Researcher at Microsoft Research in New York Ci
 ty.  He received his PhD from MIT in 1991.  After a short postdoc at Har
 vard\, he joined the technical staff at AT&T Labs (formerly AT&T Bell Labo
 ratories) in 1991.  In 2002\, he became a Professor of Computer Science 
 at Princeton University.  He joined Microsoft Research in 2014.  His aw
 ards include the 1991 ACM Doctoral Dissertation Award\, the 2003 Gödel Pr
 ize\, and the 2004 Kanelakkis Theory and Practice Award (both of the last 
 two with Yoav Freund).  He is a fellow of the AAAI\, and a member of both
  the National Academy of Engineering and the National Academy of Sciences
 .  His main research interest is in theoretical and applied machine learn
 ing.\n\nThis is an in-person seminar with a remote access option:\nhttps:/
 /yale.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=fd7320df-18fc-441e-b
 852-af42013692e4\n\n.\n\n\nhttps://yins.yale.edu/event/fds-seminar-robert-
 schapire-microsoft
LOCATION:DL220
STATUS:CONFIRMED
URL:https://yins.yale.edu/event/fds-seminar-robert-schapire-microsoft
END:VEVENT
BEGIN:VEVENT
SUMMARY:Data Science Project Match Event
DTSTART:20221213T200000
DTEND:20221213T210000
DESCRIPTION:No description provided\n\nhttps://yins.yale.edu/event/data-sc
 ience-project-match-event
LOCATION:Yale Institute for Network Science
STATUS:CONFIRMED
URL:https://yins.yale.edu/event/data-science-project-match-event
END:VEVENT
END:VCALENDAR
