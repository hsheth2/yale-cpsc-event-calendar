BEGIN:VCALENDAR
X-WR-CALDESC:Yale Computation and Society Initiative
X-WR-CALNAME:Computation and Society
BEGIN:VEVENT
SUMMARY:Colloquium on Fairness and Bias in Algorithmic Decision-Making by 
 Jon Kleinberg
DTSTART;VALUE=DATE-TIME:20201023T150000
DTEND;VALUE=DATE-TIME:20201023T160000
DESCRIPTION:Event description\nSpeaker:\nJon Kleinberg\n\, Tisch Universit
 y Professor\, Departments of Computer Science and Information Science\, Co
 rnell\n\n\n\nTitle:  Fairness and Bias in Algorithmic Decision-Making\n\n
 \n\nHost:\nElisa Celis\n\n\n\nAbstract: As algorithms trained via machine 
 learning are increasingly used as a component of screening decisions in ar
 eas such as hiring\, lending\, and education\, discussion in the public sp
 here has turned to the question of what it means for algorithmic classific
 ation to be fair to different groups. We consider several of the key fairn
 ess conditions that lie at the heart of these debates\, and discuss recent
  research establishing inherent trade-offs between these conditions. We al
 so explore how the complexity of a classification rule interacts with its 
 fairness properties\, showing how natural ways of approximating a classifi
 er via a simpler rule can act in conflict with fairness goals.\n\n\n\nThe 
 talk will be based on joint work with Jens Ludwig\, Sendhil Mullainathan\,
  Manish Raghavan\, and Cass Sunstein.\n\n\n\nSpeaker biography: Jon Kleinb
 erg is the Tisch University Professor in the Departments of Computer Scien
 ce and Information Science at Cornell University. His research focuses on 
 the interaction of algorithms and networks\, the roles they play in large-
 scale social and information systems\, and their broader societal implicat
 ions. He is a member of the National Academy of Sciences and the National 
 Academy of Engineering\, and the recipient of MacArthur\, Packard\, Simons
 \, Sloan\, and Vannevar Bush research fellowships\, as well awards includi
 ng the Harvey Prize\, the Nevanlinna Prize\, and the ACM Prize in Computin
 g.\n\n\n\nZoom:\nhttps://yale.zoom.us/j/92573843263\n\n\nhttps://computati
 onsociety.yale.edu/event/colloquium-on-fairness-and-bias-in-algorithmic-de
 cision-making-by-jon-kleinberg
LOCATION:TBA
STATUS:CONFIRMED
URL:https://computationsociety.yale.edu/event/colloquium-on-fairness-and-b
 ias-in-algorithmic-decision-making-by-jon-kleinberg
END:VEVENT
BEGIN:VEVENT
SUMMARY:Colloquium on AI & Gender: A Human Rights Toolbox Approach
DTSTART;VALUE=DATE-TIME:20201030T150000
DTEND;VALUE=DATE-TIME:20201030T160000
DESCRIPTION:Event description\nSpeakers:\n\nSurya Deva\n\,\nSchool of Law\
 , City University of Hong Kong\; UN Working Group on Business and Human Ri
 ghts\n\nAsako Hattori\n\,\nWomen’s Human Rights and Gender Section\, Off
 ice of the United Nations High Commissioner for Human Rights\n\nCaitlin Kr
 aft-Buchman\n\,\n<A+> Alliance\n\,\nWomen at the Table\n\n\n\n\n\n\n\n\n\n
 \n\n\nTitle:  AI & Gender: A Human Rights Toolbox Approach\n\n\n\nHost:\
 nElisa Celis\n\n\n\nAbstract:  In this crucial moment when AI is transfor
 ming the fabric of our society — potentially the greatest global paradig
 m shift yet — it is crystal clear that the design and deployment of Arti
 ficial Intelligence must be grounded in human rights. Similarly\, gender e
 quality — the very heart of human rights — must be included in Artific
 ial Intelligence design and deployment. How can a human rights based appro
 ach be applied to computer science\, engineering and innovation? It is urg
 ent that computer scientists\, engineers and policy makers understand the 
 nature of bias\, its technical roots\, its social impact\, and have practi
 cal frameworks to think about solutions. It is equally important that scie
 ntists as well as policy makers and citizens feel empowered to act upon th
 eir desires for a just and inclusive technology. Our three speakers work i
 n multilateral environments: the Office of the High Commissioner for Human
  Rights\, the UN Working Group on the Guiding Principles to Business and H
 uman Rights\, and the activist <A+> Alliance for Inclusive Algorithms. The
 y will discuss the growing movement to apply a human-rights based approach
  — grounded in human rights concepts and settled international law — t
 o AI as opposed to à la carte Tech Ethics\, and discuss an integration of
  a gender perspective into the everyday work of AI design and deployment. 
 This conversation is particularly urgent given the scale at which Automate
 d Decision-Making (ADM) systems and machine learning are being deployed.\n
 \n\n\nAuthor biographies:\n\nSurya Deva\nis an Associate Professor at the\
 nSchool of Law\nof City University of Hong Kong\, and a member of the\nUN 
 Working Group on Business and Human Rights\n. Prof Deva’s primary resear
 ch interests lie in Business and Human Rights\, India-China Constitutional
  Law\, and Sustainable Development. He has published extensively in these 
 areas\, and has advised the UN bodies\, governments\, multinational corpor
 ations and civil society organisations on matters related to business and 
 human rights. He is one of the founding Editors-in-Chief of the\nBusiness 
 and Human Rights Journal\n. Prof Deva drafted the report on\ngender dimens
 ions\nof the UN Guiding Principles on Business and Human Rights.\n\n\n\nAs
 ako Hattori\nis\nHuman Rights Officer at the Women’s Human Rights and Ge
 nder Section\, the Office of the United Nations High Commissioner for Huma
 n Rights\n(UN Human Rights Office– – OHCHR). At the UN Human Rights Of
 fice\, she also works on economic\, social and cultural rights\, land and 
 human rights\, gender stereotyping\, digital technologies and women’s ri
 ghts.\n\n\n\nCaitlin Kraft-Buchman\nis CEO/Founder of\nWomen at the Table\
 n\, a growing global CSO based in Geneva\, Switzerland – and the first o
 rganization to focus on systems change by helping feminists gain influence
  in sectors that have key structural impact: economy\, sustainability\, de
 mocracy and governance\, and technology.\n\n\n\nA serial coalition builder
  focused on impact\, she is founder of International Gender Champions (IGC
 ) with hubs in Geneva\, New York\, Vienna\, Nairobi\, The Hague\, and Pari
 s\, with 300+ Champion heads of organizations including the UN Secretary G
 eneral\, heads of UN-Habitat\, UNHCR\, ICRC\, WTO\, ILO\, WHO\, WIPO\, ISO
 \, Ambassadors\, and Civil Society. She is responsible for IGC’s Trade I
 mpact Group (Buenos Aires Declaration on Trade + Women’s Economic Empowe
 rment\, 2017)\; Disarmament Impact Group (nominated Arms Control Person/s 
 of the Year\, 2018)\; Standards Impact Group (Gender Responsive Standards 
 Declaration\, 2019).\n\n\n\nCaitlin founded and co-leads the new\n<A+> All
 iance for Inclusive Algorithms\nwith Ciudadania Inteligente\, a global coa
 lition focused on affirmative action for algorithms\, so that machine lear
 ning does not embed an already biased system into our future. <A+> is one 
 of the leaders of the UN Women Generation Equality Action Coalition for Te
 chnology and Innovation for Gender Equality.\n\n\n\nZoom:\nhttps://yale.zo
 om.us/j/99259504681\n\n\nhttps://computationsociety.yale.edu/event/colloqu
 ium-on-ai-gender-a-human-rights-toolbox-approach
LOCATION:TBA
STATUS:CONFIRMED
URL:https://computationsociety.yale.edu/event/colloquium-on-ai-gender-a-hu
 man-rights-toolbox-approach
END:VEVENT
END:VCALENDAR
