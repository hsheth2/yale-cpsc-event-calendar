BEGIN:VCALENDAR
X-WR-CALDESC:Yale Department of Computer Science
X-WR-CALNAME:Yale CS Events
BEGIN:VEVENT
SUMMARY:CS Colloquium - Marios Kogias
DTSTART;VALUE=DATE-TIME:20210218T153000
DTEND;VALUE=DATE-TIME:20210218T163000
DESCRIPTION:Event description:\nCS Colloquium\nMarios Kogias\n\nTitle: Bui
 lding Latency-Critical Datacenter Systems\n\nHost: Avi Silberschatz\n\nAbs
 tract:\n\nOnline services play a major role in our everyday life for commu
 nication\, entertainment\, socializing\, e-commerce\, etc.  These service
 s run inside the datacenter under strict tail-latency service level object
 ives in order to remain interactive. The emergence of new hardware for IO
  has enabled microsecond-scale datacenter communications that challenge th
 e efficiency of existing operating system and network mechanisms. Also\, 
 new in-network programmable devices start being deployed in datacenters an
 d introduce a new computing paradigm that shifts functionality traditional
 ly performed at the end-points to the network.\n\nIn this talk I will revi
 sit the operating systems\, networking\, and distributed systems infrastru
 cture specifically targeting latency-critical datacenter systems\, while d
 rawing intuition from basic queueing theory results. In the first part of
  the talk\, I will focus on ZygOS[SOSP 2017]\, a system optimized for μs-
 scale\, in-memory computing on multicore servers. ZygOS implements a work
 -conserving scheduler within a specialized operating system designed for h
 igh request rates and a large number of network connections. ZygOS reveal
 ed the challenges associated with serving remote procedure calls (RPCs) on
  top of a byte-stream oriented protocol\, such as TCP. In the second part
  of the talk\, I will present R2P2[ATC 2019]. R2P2 is a transport protoco
 l specifically designed for datacenter RPCs\, that exposes the RPC abstrac
 tion to the endpoints and the network\, making RPCs first-class datacenter
  citizens. R2P2 enables pushing functionality\, such as scheduling\, faul
 t-tolerance\, and tail-tolerance\, inside the transport protocol. I will 
 show how using R2P2 allowed us to offload RPC scheduling to programmable s
 witches that can schedule requests directly on individual CPU cores.\n\nBi
 o:\n\nMarios Kogias is a researcher at MSR Cambridge. He graduated from E
 PFL in August 2020. His main research focus is at the intersection of oper
 ating systems and networking in the datacenter. He’s working on buildin
 g and understanding systems with strict tail-latency SLOs leveraging new 
 emerging hardware. He was an IBM PhD Fellow and won the best student paper
  award at Eurosys2020. Before joining EPFL he got his undergrad degree fro
 m the National Technical University of Athens. He has interned at Cern\, 
 Google\, and Microsoft Research.\n\n*Contact\nAlicia\nor\nNancy\nfor Zoom 
 link and password\n\nCS Colloquium flyer\n\n\n\nhttps://cpsc.yale.edu/even
 t/cs-colloquium-marios-kogias
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-marios-kogias
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium -Sima Jafarikhah
DTSTART;VALUE=DATE-TIME:20210219T153000
DTEND;VALUE=DATE-TIME:20210219T163000
DESCRIPTION:Event description:\nCS Colloquium\nSima (Tahereh) Jafarikhah\n
 \nTitle: Publicly Evaluatable Perceptual Hashing\n\nHost: Holly Rushmeier\
 n\nAbstract:\n\nRobust Perceptual Hash (\nPH\n) allows social media platfo
 rms to prevent uploading explicit multimedia files of their users without 
 their consent. Using PH algorithms raise a vital privacy concern\; If user
 s are aware that an explicit image of theirs is in another’s possession 
 and want to prevent such an image from being posted\, they have to provide
  the image to the social media platform so that the PH can be evaluated on
  it and added to the blacklist. Is it possible to have robust and publicly
  evaluatable perceptual hash functions? With three undergraduate students 
 at the City University of New York\, we answered this question in an affir
 mative.\n\nBio:\n\nSima (Tahereh) Jafarikhah is a Ph.D. candidate of Compu
 ter Science at the City University of New York under the supervision of Ro
 sario Gennaro and expect to complete her Ph.D. degree requirements by Spri
 ng 2021. Prior to this\, she earned her first Ph.D. in Mathematics from T
 ehran. Her research lies at the intersection of cryptography\, network sec
 urity\, and\, more in general\, theoretical computer science. She served a
 s the main lecturer of various computer science and Math courses at gradua
 te\, undergraduate levels. She also taught at the Johns Hopkins Center for
  Talented Youth.\n\n*Contact\nAlicia\nor\nNancy\nfor Zoom link and passwor
 d\n\nCS Colloquium flyer\n\n\n\nhttps://cpsc.yale.edu/event/cs-colloquium-
 sima-jafarikhah
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-sima-jafarikhah
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Mingfei Zhao
DTSTART;VALUE=DATE-TIME:20210222T193000
DTEND;VALUE=DATE-TIME:20210222T203000
DESCRIPTION:Event description:\nDissertation Defense\nMingfei Zhao\n\nTitl
 e: Simple vs. Optimal Mechanism Design\n\nAdvisor: Yang Cai\n\nOther comm
 ittee members:\n\nDirk Bergemann\nJoan Feigenbaum\nMatt Weinberg (Princeto
 n University)\n\nAbstract:\n\nIn Mechanism Design\, the goal is to design 
 a mechanism/system such that a group of strategic agents\, who are only in
 terested in optimizing their own utilities\, are incentivized to choose ac
 tions that also help achieve the designer’s objective. However\, even in
  fairly basic settings\, the theoretically optimal mechanisms are complex 
 and randomized\, while mechanisms used in practice are usually simple and 
 deterministic. My work aims to resolve this discrepancy between theory and
  practice by studying the following questions: are the mechanisms used in 
 practice close to optimal? Can we design simple mechanisms to approximate 
 the optimal one? We show that in important settings such as multi-item auc
 tions and two-sided markets\, there are indeed simple and approximately op
 timal mechanisms.\n\n\nhttps://cpsc.yale.edu/event/dissertation-defense-mi
 ngfei-zhao
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-mingfei-zhao
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Amy Zhang
DTSTART;VALUE=DATE-TIME:20210224T210000
DTEND;VALUE=DATE-TIME:20210224T220000
DESCRIPTION:Event description:\nCS Colloquium\nAmy Zhang\n\nTitle: Exploit
 ing latent structure and bisimulation metrics for better generalization in
  reinforcement learning\n\nHost: Marynel Vázquez\n\nAbstract:\n\nThe adve
 nt of deep learning has shepherded unprecedented progress in various field
 s of machine learning. Despite recent advances in deep reinforcement learn
 ing (RL) algorithms\, however\, there is no method today that exhibits any
 where near the generalization that we have seen in computer vision and NLP
 . Indeed\, one might ask whether deep RL algorithms are even capable of th
 e kind of generalization that is needed for open-world environments.  Thi
 s challenge is fundamental and will not be solved with incremental algorit
 hmic advances.\n\nIn this talk\, we propose to incorporate different assum
 ptions that better reflect the real world and allow the design of novel al
 gorithms with theoretical guarantees to address this fundamental problem. 
 We first present how state abstractions can accelerate reinforcement learn
 ing from rich observations\, such as images\, without relying either on do
 main knowledge or pixel-reconstruction. Our goal is to learn state abstrac
 tions that both provide for effective downstream control and invariance to
  task-irrelevant details. We use bisimulation metrics to quantify behavior
 al similarity between states\, and learn robust latent representations whi
 ch encode only the task-relevant information from observations. We provide
  theoretical guarantees for the learned approximate abstraction and extend
  this notion to families of tasks with varying dynamics.\n\nBio:\n\nI am a
  final year PhD candidate at McGill University and the Mila Institute\, co
 -supervised by Profs. Joelle Pineau and Doina Precup. I am also a research
 er at Facebook AI Research. My work focuses on bridging theory and practic
 e through learning approximate state abstractions and learning representat
 ions for generalization in reinforcement learning. I previously obtained a
 n M.Eng. in EECS and dual B.Sci. degrees in Mathematics and EECS from MIT.
 \n\n*Contact\nAlicia\nor\nNancy\nfor Zoom link and password\n\n\nhttps://c
 psc.yale.edu/event/cs-colloquium-amy-zhang
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-amy-zhang
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Alexander R. Fabbri
DTSTART;VALUE=DATE-TIME:20210225T140000
DTEND;VALUE=DATE-TIME:20210225T150000
DESCRIPTION:Event description:\nDissertation Defense\nAlexander R. Fabbri\
 n\nTitle: Text Summarization Across High and Low-resource Settings\n\nAdv
 isor: Dragomir Radev\n\nOther committee members:\n\nNisheeth Vishnoi\nRob
 ert Frank\nSmaranda Muresan (Columbia University)\n\nAbstract:\n\nNatural 
 language processing aims to build automated systems that can both understa
 nd and generate natural language textual data. As the amount of textual da
 ta available online has increased exponentially\, so has the need for inte
 lligence systems to comprehend and present this data to the world. As a re
 sult\, automatic text summarization\, the process by which a text’s sali
 ent content is automatically distilled into a concise form\, has become a 
 necessary tool.\n\nAutomatic text summarization approaches and application
 s vary based on the input summarized\, which may constitute single or mult
 iple documents of different genres. Furthermore\, the desired output style
  may consist of a sentence or sub-sentential units chosen directly from th
 e input in extractive summarization or a fusion and paraphrase of the inpu
 t document in abstractive summarization. Despite differences in the above 
 use-cases\, specific themes\, such as the role of large-scale data for tra
 ining these models\, the application of summarization models in real-world
  scenarios\, and the need for adequately evaluating and comparing summarie
 s\, are common across these settings.\n\nThis dissertation presents novel 
 data and modeling techniques for deep neural network-based summarization m
 odels trained across large-scale and low-resource data settings and a comp
 rehensive evaluation of the model and metric progress in the field.  We e
 xamine both Recurrent Neural Network (RNN)-based and Transformer-based mod
 els to extract and generate summaries from the input. We introduce dataset
 s to facilitate the training of large-scale networks in two applications o
 f multi-document summarization. We also propose unsupervised learning tech
 niques for both extractive summarization in question answering and abstrac
 tive summarization and few-shot and distant supervision learning to use un
 labeled data better.\n\nIn particular\, this dissertation addresses the fo
 llowing research objectives:\n\n1) High-resource Summarization. We introdu
 ce two datasets for multi-document summarization\, focusing on pedagogical
  applications for NLP and news summarization. In both cases\, we analyze h
 ow the models trained on these large-scale datasets fare when applied to r
 eal-world scenarios and introduce a novel model to reduce redundancy in mu
 lti-document summaries.\n2) Low-resource Summarization. We propose a pipel
 ine for creating synthetic training data for training extractive question-
 answering models\, a form of query-based extractive summarization with sho
 rt-phrase summaries. In other work\, we propose an automatic pipeline for 
 training a multi-document summarizer in answer summarization on community 
 question-answering forums without labeled data. Finally\, we push the boun
 daries of abstractive summarization model performance when little or no tr
 aining data is available.\n3) Automatic Summarization Evaluation. We study
  the current metrics used to compare summarization output quality across 1
 2 metrics across 23 deep neural network models and propose better-motivate
 d summarization evaluation guidelines.\n\n\nhttps://cpsc.yale.edu/event/di
 ssertation-defense-alexander-r-fabbri
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-alexander-r-fabbri
END:VEVENT
BEGIN:VEVENT
SUMMARY:JBPO Meeting Dates\, AY 2020-21 - Information Only
DTSTART;VALUE=DATE-TIME:20210225T210000
DTEND;VALUE=DATE-TIME:20210225T220000
DESCRIPTION:Event description:\nThe dates for the Joint Boards of Permanen
 t Officers (JBPO) have been scheduled for the 2020-21 academic year.  Ple
 ase reserve:\n\nThursday\, February 25\, 2021\n\nThursday\, April 15\, 202
 1\n\nThursday\, May 13\, 2021\n\nAll meetings start at 4:00 p.m. and will 
 be via Zoom for the foreseeable future. Two weeks prior to each meeting\, 
 an email will be sent with the link to preregister for the meeting\, along
  with the CONFIDENTIAL agenda and supporting materials. After preregisteri
 ng you will receive a confirmation email containing the Zoom link to join 
 the meeting.\n\nIn order to ensure a quorum*\, please attend if you are ab
 le\, especially if you are a designated quorum officer of your department 
 or program.\n\n*Voting in the Joint Boards of Permanent Officers. Full pro
 fessors whose primary or fully joint appointments are in a Faculty of Arts
  and Sciences department may vote\, as may full professors of professional
  schools with secondary appointments in a Faculty of Arts and Sciences dep
 artment and explicit Corporation approval for such voting rights. The only
  exception to this rule is for faculty in Molecular Biophysics and Biochem
 istry who are assigned to vote in the School of Medicine’s Board of Perm
 anent Officers and may not also vote in the Joint Boards of Permanent Offi
 cers of Yale College and the Graduate School. By long standing custom\, a 
 quorum for the conduct of business at a meeting of the Joint Boards consis
 ts of 37 members eligible to vote. No vote has force if the number of vote
 s\, plus recorded abstentions\, falls short of that number. Tenure appoint
 ments are forwarded to the Corporation only upon an affirmative vote by tw
 o-thirds of the members present and eligible to vote. All other appointmen
 ts are approved by majority vote. (Faculty Handbook\, Section IV.F.5)\n\nY
 ale University | Faculty of Arts and Sciences |\nhttp://fas.yale.edu/\n\n\
 nhttps://cpsc.yale.edu/event/jbpo-meeting-dates-ay-2020-21-information-onl
 y
LOCATION:Zoom
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/jbpo-meeting-dates-ay-2020-21-information-
 only
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Connor Bain
DTSTART;VALUE=DATE-TIME:20210226T153000
DTEND;VALUE=DATE-TIME:20210226T163000
DESCRIPTION:Event description:\nCS Colloquium\nConnor Bain\n\nTitle: “Te
 aching Demo: Comparing Algorithms - What makes one algorithm ‘better’ 
 than another?”\n\nHost: Holly Rushmeier\n\nAbstract:\n\nIt seems like a 
 simple question: what makes one algorithm “better” than another? In th
 is demo class\, a few weeks into a CS fundamentals course\, we’ll work t
 ogether to design two distinct algorithms to solve a seemingly basic task:
  search for a particular name in a list. But how do we compare multiple a
 lgorithms that solve the same problem? We’ll discuss various methods of 
 comparison\, do a group activity\, and learn the fundamentals of an import
 ant tool in the CS toolbox–Big O notation.\n\nMany students in CS fundam
 entals coursework struggle to both develop practical programming skills\na
 nd\ninternalize deeper CS thinking practices like analyzing algorithms. An
 d while Big O notation exists as an ideal tool for this sort of work\, it 
 is often reserved as a formal mathematical tool introduced later on in the
  CS core curriculum. In this demo class\, we choose to introduce students 
 to the fundamentals of Big O notation as\na thinking tool\nwhen comparing 
 two algorithms. We don’t expect learners to become experts in the mathem
 atical underpinnings of Big O in a single class period. Instead\, we aim t
 o prepare them for future use of the tool in formal algorithmic analysis b
 y focusing on building\ncomputational intuition\non how an algorithm’s r
 un time might grow as its input grows larger and larger.\n\nBio:\n\nConnor
  Bain is a Ph.D. candidate in the joint program in Computer Science and Le
 arning Sciences at Northwestern University in Evanston\, Illinois. His res
 earch focuses on developing tools and frameworks for teachers to integrate
  computing into K-12 STEM classrooms. This work has resulted in new findin
 gs on CT integration in STEM showing that it can simultaneously broaden pa
 rticipation in computing\, represent scientific inquiry in a more authenti
 c manner\, and deepen learners’ understanding of STEM topics. Connor’s
  teaching experience spans a number of different departments and audiences
 \, from introductory classes in statistics\, economics\, and computer scie
 nce\, to advanced seminars on causal inference and multiagent-based modeli
 ng. At the core of his pedagogy is framing computation not as a tool reser
 ved for the few\, but as a way of empowering learners to challenge the wor
 ld around them. Connor’s teaching and research sit at the intersection o
 f computer science and the learning sciences and combine computational\, q
 uantitative\, and qualitative methods to create evidenced-based frameworks
  for a new kind of computing education focused on CS+X ideas.\n\n*Contact\
 nAlicia\nor\nNancy\nfor Zoom link and password\n\n\nhttps://cpsc.yale.edu/
 event/cs-colloquium-connor-bain
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-connor-bain
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Peizhen Guo
DTSTART;VALUE=DATE-TIME:20210304T190000
DTEND;VALUE=DATE-TIME:20210304T200000
DESCRIPTION:Event description:\nDissertation Defense\nPeizhen Guo\n\nTitle
 : Service Abstractions for Scalable Deep Learning Inference at the Edge\n
 \nAdvisor: Wenjun Hu\n\nOther committee members:\n\nLin Zhong\nJames Aspn
 es\nMahadev Satyanarayanan (Carnegie Mellon University)\n\nAbstract:\n\nDe
 ep learning driven intelligent edge has already become a reality\, where m
 illions of mobile\, wearable\, and IoT devices analyze real-time data and 
 transform those into actionable insights on-device. Typical approaches for
  optimizing deep learning inference mostly focus on accelerating the execu
 tion of individual inference tasks\, without considering the contextual c
 orrelation unique to edge environments and the statistical nature of learn
 ing-based computation. Specifically\, they treat inference workloads as in
 dividual black boxes and apply canonical system optimization techniques\, 
 developed over the last few decades\, to handle them as yet another type o
 f computation-intensive applications. As a result\, deep learning inferenc
 e on edge devices still face the ever increasing challenges of customizati
 on to edge device heterogeneity\, fuzzy computation redundancy between inf
 erence tasks\, and end-to-end deployment at scale.\n\nIn this thesis\, we
  propose the first framework that automates and scales the end-to-end proc
 ess of deploying efficient deep learning inference from the cloud to heter
 ogeneous edge devices. The framework consists of a series of service abstr
 actions that handle DNN model tailoring\, model indexing and query\, and c
 omputation reuse for runtime inference respectively. Together\, these serv
 ices bridge the gap between deep learning training and inference\, elimina
 te computation redundancy during inference execution\, and further lower t
 he barrier for deep learning algorithm and system co-optimization.\n\nTo b
 uild efficient and scalable services\, we take a unique algorithmic approa
 ch of harnessing the semantic correlation between the learning-based compu
 tation. Rather than viewing individual tasks as isolated black boxes\, we 
 optimize them collectively in a white box approach\, proposing primitives 
 to formulate the semantics of the deep learning workloads\, algorithms to 
 assess their hidden correlation (in terms of the input data\, the neural n
 etwork models\, and the deployment trials) and merge common processing ste
 ps to minimize redundancy.\n\n\n\nhttps://cpsc.yale.edu/event/dissertation
 -defense-peizhen-guo
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-peizhen-guo
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Arman Cohan
DTSTART;VALUE=DATE-TIME:20210310T210000
DTEND;VALUE=DATE-TIME:20210310T220000
DESCRIPTION:Event description:\nCS Colloquium\nArman Cohan\n\nTitle: Adapt
 ing Transformer models for Document-level Natural Language Tasks\n\nHost: 
 Dragomir Radev\n\nAbstract:\n\nTransformer models have been extremely effe
 ctive at producing word- and sentence-level contextualized representations
 \, achieving state-of-the-art results in many Natural Language Processing 
 (NLP) tasks. However\, extending these models to document-level NLP tasks 
 faces challenges\, including lack of inter-document relatedness informatio
 n\, decreased performance in low-resource settings\, and computational ine
 fficiency when scaling to long documents.\n\nIn this talk\, I will describ
 e a few of my recent works on developing Transformer-based models that tar
 get document-level natural language tasks. I will first introduce SPECTER\
 , a method for producing document representations using a Transformer mode
 l that incorporates document-level relatedness signals and achieves state-
 of-the-art results in multiple document-level tasks in the scientific doma
 in.  Second\, I will describe TLDR\, the task of extreme summarization fo
 r scientific papers as well as CATTs\, a simple yet effective training str
 ategy for generating summaries in low-resource settings. Next\, I will dis
 cuss the practical challenges of scaling existing Transformer models to lo
 ng documents\, and our proposed solution\, Longformer. Longformer\, introd
 uces a new sparse self-attention pattern that scales linearly with the inp
 ut length while capturing both local and global context in the document\, 
 achieving state-of-the-art results in both character-level language modeli
 ng and document NLP tasks. Finally\, I’ll discuss CDLM\, our newly propo
 sed general pre-trained model for addressing multi-document tasks.\n\nBio:
 \n\nArman Cohan is a Research Scientist at the Allen Institute for AI (AI2
 ). He received his PhD in computer Science at Georgetown University in May
  2018\, advised by Prof. Nazli Goharian. His research is primarily focused
  on developing general Natural Language Processing capabilities to address
  information overload\, particularly in specialized domains that pose uniq
 ue challenges. These include core representation learning and language mod
 eling methods\, systems and models designed for extracting and summarizing
  salient information\, and models for improved search and categorization i
 n large collections of data.\n\nHe has served as program committee member 
 of major NLP venues including ACL\, EMNLP\, and NAACL in the past 4 years\
 , served as area chair at ACL 2020\, ICLR 2021 and NAACL 2021\, and organi
 zed workshops including SciNLP and SDP.\n\nHis research has been recognize
 d with multiple awards including best paper award at EMNLP 2017\, area cha
 ir favorite paper award at COLING 2018\, and Harold N. Glassman Distinguis
 hed Doctoral Dissertation award in 2019.\n\n*Contact\nAlicia\nor\nNancy\nf
 or Zoom link and password\n\n\nhttps://cpsc.yale.edu/event/cs-colloquium-a
 rman-cohan
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-arman-cohan
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Tao Yu
DTSTART;VALUE=DATE-TIME:20210310T223000
DTEND;VALUE=DATE-TIME:20210310T233000
DESCRIPTION:Event description:\nDissertation Defense\nTao Yu\n\nTitle: Le
 arning to Map Natural Language to Executable Programs Over Databases\n\nAd
 visor: Dragomir Radev\n\nOther committee members:\n\nRobert Frank\nMaryne
 l Vazquez\nKathleen McKeown (Columbia University)\nLuke Zettlemoyer (Unive
 rsity of Washington)\n\nAbstract:\n\nNatural language is a fundamental for
 m of information and communication and will be the next frontier in comput
 er interfaces. Natural Language Interfaces (NLI) bridge the data and the u
 ser\, significantly promoting the possibility and efficiency of informatio
 n access for many users besides data experts. All consumer-facing software
  will one day have a dialogue interface\, the next vital leap in the evolu
 tion of search engines. Such intelligent dialogue systems should be able t
 o understand the meaning of language grounded in various contexts and gene
 rate effective language responses in different forms for information reque
 sts and human-computer communication. In particular\, this dissertation fo
 cuses on answering the following three questions: 1) How can NLI ground hu
 man requests in natural language into formal programs (e.g.\, SQL)? 2) How
  can NLI converse with humans in a robust manner? 3) How can neural models
  understand compositionality in human language?\n\n\nhttps://cpsc.yale.edu
 /event/dissertation-defense-tao-yu
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-tao-yu
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Karl Wüst
DTSTART;VALUE=DATE-TIME:20210311T153000
DTEND;VALUE=DATE-TIME:20210311T163000
DESCRIPTION:Event description:\nCS Colloquium\nKarl Wüst\n\nTitle: Trust 
 or Decentralize? Balancing Trust and Performance in Decentralized Systems\
 n\nHost: Zhong Shao\n\nAbstract:\n\nIn recent years\, cryptocurrencies and
  blockchains have received widespread attention. These systems are general
 ly designed to be decentralized in order to reduce the required trust assu
 mptions as much as possible. However\, there are choices to be made about 
 how much to trust and how much to decentralize which in turn greatly affec
 t the properties that can be achieved efficiently.\nIn this talk\, I will 
 discuss how these choices can be leveraged for large performance gains and
  to achieve new properties in smart contract systems and for privacy-prese
 rving cryptocurrency transactions.\nIn particular\, I will show how smart 
 contract scalability can be improved by executing contracts in smaller com
 mittees\, while at the same time allowing safe interaction between untrust
 ed contracts. Further\, I will show how lightweight blockchain clients for
  fully anonymous cryptocurrencies can be enabled efficiently\, and how pri
 vacy and accountability can be balanced in central bank digital currencies
 .\n\nBio:\n\nKarl Wüst is a PhD Candidate in the System Security Group at
  ETH Zurich.\nHis research focuses on the security and privacy of blockcha
 in technology with a particular focus on smart contract scalability and ce
 ntral bank cryptocurrencies. In his research\, he combines techniques from
  cryptography\, distributed systems\, and trusted computing to balance the
  trade-off between reducing trust and achieving high performance. His rese
 arch has been published at top venues in security (CCS\, Usenix Security\,
  NDSS) and resulted in multiple patent applications.\n\n*Contact\nAlicia\n
 or\nNancy\nfor Zoom link and password\n\n\nhttps://cpsc.yale.edu/event/cs-
 colloquium-karl-wust
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-karl-wust
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Luciano Dyballa
DTSTART;VALUE=DATE-TIME:20210312T180000
DTEND;VALUE=DATE-TIME:20210312T190000
DESCRIPTION:Event description:\nDissertation Defense\nLuciano Dyballa\n\nT
 itle: The Manifold of Neural Responses Informs Physiological Circuits in M
 ouse Visual System\n\nAdvisor: Steven Zucker\n\nOther committee members:\n
 \nJulie Dorsey\nRonald Coifman\nMichael Stryker (UCSF)\n\nAbstract:\n\nInf
 erring the structure and function of neural circuits is central to underst
 anding biological visual systems. Focusing on the visual system of the mou
 se\, we address two major challenges toward this goal. First\, we introduc
 e a novel stimulus ensemble. We show that it is rich enough to exercise th
 e visual system broadly but simple enough for analysis.  The ensemble inc
 ludes flow patterns\, a class of naturalistic visual stimuli that span spa
 tial frequency\, contrast\, orientation and directionality\, as well as co
 nventional grating stimuli. These flow stimuli are more constrained than n
 atural images but more variable than gratings and noise patterns. A stimul
 us generator is developed\, and it has been deployed in several neuroscien
 ce laboratories.\n\nThe second challenge is how to infer the functional st
 ructure of neural circuits from their activity to the stimulus ensemble. W
 e use machine learning techniques to develop a novel manifold of neurons. 
 This manifold is informative of basic circuit topology as well as neural f
 unction. It differs from the standard approach in which trials are embedde
 d in ‘neural coordinates.’ Our manifold\, by contrast\, embeds neurons
  in functional coordinates derived from the stimuli. It is defined so that
  those neurons that are close to one another on the manifold respond simil
 arly in both activity and time to similar features within the stimulus ens
 emble.\n\nPreliminary experiments with mouse retina and visual cortex data
  reveal examples of these different manifold structures and provide a foun
 dation for understanding the computational transition between retina and c
 ortex in awake\, behaving mice. The same algorithm can be applied to artif
 icial neural networks as well\; interestingly\, deep CNNs yield manifolds 
 that are disconnected like the retina\, not continuous like V1. For neuros
 cience\, this could explain the apparent ceiling in modeling cortical data
 \; the limitations of categorical tasks\; and suggests future modeling dir
 ections. More generally\, it illuminates limitations on the categorization
  problem\, and underlines the importance of recurrence in networks for mor
 e complex tasks.\n\n\nhttps://cpsc.yale.edu/event/dissertation-defense-luc
 iano-dyballa
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-luciano-dyballa
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Angelique Taylor
DTSTART;VALUE=DATE-TIME:20210315T200000
DTEND;VALUE=DATE-TIME:20210315T210000
DESCRIPTION:Event description:\nCS Colloquium\nAngelique Taylor\n\nTitle: 
 Perception and Decision-Making Systems for Human-Robot Teaming in Safety-C
 ritical Environments\n\nHost: Brian Scassellati\n\nAbstract:\n\nIn this ta
 lk\, I will present my current and future work on developing perception an
 d decision making systems that enable robots to team with groups of people
 . My core focus is on problems that robots encounter in human-robot teamin
 g\, including perceptions of human groups and social navigation\, particul
 arly in safety-critical environments.\n\nFirst\, I will discuss how I deve
 loped computer vision methods that enable robots to detect and track their
  teammates in real-world environments. Most group perception methods emplo
 y fixed\, overhead cameras (i.e.\, an exo-centric / third-person perspecti
 ve) to sense groups of people\, rendering them impractical for mobile robo
 ts working in most settings. I have developed a group detection and tracki
 ng system designed for ego-centric (i.e.\, first-person) perspective sensi
 ng\, which is more suitable for mobile robots\, to enable them to enter an
 y environment and accomplish their goals without external sensing requirem
 ents.\n\nNext\, I will discuss this work contextualized within a real-worl
 d application: human-robot teaming in healthcare. I am developing systems 
 for hospital Emergency Departments (ED)\, where frontline healthcare worke
 rs have been overwhelmed by the COVID-19 pandemic. I will describe my work
  characterizing ED care delivery and staff workflow to enable robots to op
 erate in these challenging environments. Building on this\, I designed a s
 ocial navigation system that enables robots to incorporate the severity of
  patients’ health while navigating in the ED\, to prevent interruptions 
 in care delivery. My work will enable robots to work in safety-critical\, 
 human-centered environments\, and ultimately help improve patient outcomes
  and alleviate clinician workload.\n\nBio:\n\nAngelique Taylor is a Ph.D. 
 candidate in Computer Science and Engineering at UC San Diego. Her researc
 h lies at the intersection of computer vision\, robotics\, and health info
 rmatics. She develops systems that enable robots to interact and work with
  groups of people in safety-critical environments. She has received the NS
 F GRFP\, Microsoft Dissertation Award\, the Google Anita Borg Memorial Fel
 lowship\, the Arthur J. Schmitt Presidential Fellowship\, a GEM Fellowship
 \, and an award from the National Center for Women in Information Technolo
 gy (NCWIT). More information on her research can be found at\nangeliquemta
 ylor.com\n.\n\n*Contact\nAlicia\nor\nNancy\nfor Zoom link and password\n\n
 CS Colloquium flyer\n\n\n\nhttps://cpsc.yale.edu/event/cs-colloquium-angel
 ique-taylor
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-angelique-taylor
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Kexin Rong
DTSTART;VALUE=DATE-TIME:20210316T200000
DTEND;VALUE=DATE-TIME:20210316T210000
DESCRIPTION:Event description:\nCS Colloquium\nKexin Rong\n\nTitle: Priori
 tizing Computation and Analyst Resources in Large-scale Data Analytics\n\n
 Host: Abhishek Bhattacharjee\n\nAbstract:\n\nData volumes are growing expo
 nentially\, fueled by an increased number of automated processes such as s
 ensors and devices. Meanwhile\, the computational power available for proc
 essing this data – as well as analysts’ ability to interpret it – re
 main limited. As a result\, database systems must evolve to address these 
 new bottlenecks in analytics. In my work\, I ask: how can we adapt classic
  ideas from database query processing to modern compute- and analyst-limit
 ed data analytics?\n\nIn this talk\, I will discuss the potential for this
  kind of systems development through the lens of several practical systems
  I have developed. By drawing insights from database query optimization\, 
 such as pushing workload- and domain-specific filtering\, aggregation\, an
 d sampling into core analytics workflows\, we can dramatically improve the
  efficiency of analytics at scale. I will illustrate these ideas by focusi
 ng on two systems — one designed to optimize visualizations for streamin
 g infrastructure and application telemetry and one designed for high-volum
 e seismic waveform analysis — both of which have been field-tested at sc
 ale. I will also discuss lessons from production deployments at companies 
 including Datadog\, Microsoft\, Google and Facebook.\n\nBio:\n\nKexin Rong
  is a Ph.D. student in Computer Science at Stanford University\, co-advise
 d by Professor Peter Bailis and Professor Philip Levis. She designs and bu
 ilds systems to enable data analytics at scale\, supporting applications i
 ncluding scientific analysis\, infrastructure monitoring\, and analytical 
 queries on big data clusters. Prior to Stanford\, she received her bachelo
 r’s degree in Computer Science from California Institute of Technology.\
 n\n*Contact\nAlicia\nor\nNancy\nfor Zoom link and password\n\n\n\n\nhttps:
 //cpsc.yale.edu/event/cs-colloquium-kexin-rong
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-kexin-rong
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Yongshan Ding
DTSTART;VALUE=DATE-TIME:20210318T143000
DTEND;VALUE=DATE-TIME:20210318T153000
DESCRIPTION:Event description:\nCS Colloquium\nYongshan Ding\n\nTitle: Arc
 hitecting Quantum Computing Systems in the Presence of Noise\n\nHost: Lin 
 Zhong\n\nAbstract:\n\nQuantum computers may solve some problems beyond the
  reach of classical digital computers. However\, emerging quantum systems 
 are typically noisy and difficult to control\, leaving a significant gap b
 etween the exacting requirements of quantum applications and the realities
  of noisy devices. Bridging this gap is crucial – my work adapts convent
 ional computer systems techniques to meet the critical theoretical and exp
 erimental constraints in quantum processors. I divide my talk into three p
 arts: (i) introducing my recent work on systematic noise mitigation for su
 perconducting transmon qubits [MICRO’20]\, which enhances the robustness
  of quantum processors through coordination of control instructions\; (ii)
  demonstrating efficient and reliable quantum memory management [ISCA’20
 ]\, which implements automated tools for allocation\, reclamation and reus
 e of qubits in quantum programs\, much like in garbage collection for clas
 sical programs\; (iii) discussing on-going work on implementing quasi-faul
 t-tolerant rotation gates in quantum error correction\, which seeks to pro
 vide correctness guarantees for quantum applications by encoding quantum b
 its in a way that errors can be detected and corrected\, analogous to clas
 sical error-correcting codes.\n\nBio:\n\nYongshan Ding is a Ph.D. candidat
 e at the University of Chicago advised by Fred Chong. He received his B.Sc
 . degrees in computer science and physics from Carnegie Mellon University.
  His research focuses on quantum computer systems\, specifically through c
 o-design of quantum algorithms\, software\, and devices. Ding has develope
 d novel techniques for quantum error correction\, quantum memory managemen
 t\, and optimizations at the quantum-classical interface. His work has bee
 n recognized with two Best Paper Awards by IBM Q and QCE’20 and two Hono
 rable Mentions in IEEE Micro Top Picks. Additionally\, Ding is the lead au
 thor of a textbook\, Quantum Computer Systems\, in Morgan-Claypool Publish
 er’s synthesis lectures in computer architecture. He has been supported 
 by a Siebel Scholarship and a William Rainey Harper Dissertation Fellowshi
 p. His personal website is\nhttps://people.cs.uchicago.edu/~yongshan/\n.\n
 \n*Contact\nAlicia\nor\nNancy\nfor Zoom link and password\n\n\nhttps://cps
 c.yale.edu/event/cs-colloquium-yongshan-ding
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-yongshan-ding
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Maria Apostolaki
DTSTART;VALUE=DATE-TIME:20210325T143000
DTEND;VALUE=DATE-TIME:20210325T153000
DESCRIPTION:Event description:\nCS Colloquium\nMaria Apostolaki\n\nTitle: 
 Building secure distributed systems atop the insecure Internet\n\nHost: An
 urag Khandelwal\n\nAbstract:\n\nDistributed systems are increasingly impor
 tant for our everyday life\, allowing for high performance\, fault toleran
 ce\, and flexibility. Many of these systems nowadays rely on the inherentl
 y insecure Internet infrastructure. Surely though\, they should have been 
 designed to take this into account…?\n\nIn this talk\, I will answer neg
 atively to this question using a concrete example: public blockchain syste
 ms such as Bitcoin. These are novel distributed systems that are designed 
 according to stringent failure models. In this context\, I will explain ho
 w an adversary controlling pieces of Internet infrastructure can practical
 ly compromise: (i) Bitcoin’s consensus protocol (by partitioning the net
 work)\; (ii) Bitcoin’s anonymity guarantees (by mapping pseudonyms to re
 al-world identities)\; and (iii) Bitcoin’s availability (by eclipsing cl
 ients).\n\nWhile these attacks are worrying\, I will also introduce practi
 cal and effective defenses to counter them both at the network and the app
 lication layer. Beyond Bitcoin\, this work teaches essential lessons for d
 istributed-system design.\n\nBio:\n\nMaria Apostolaki is a PhD Student at 
 ETH Zurich advised by Laurent Vanbever.\nDuring her studies\, she has been
  a visiting student at MIT (2019) and a research intern at Microsoft Resea
 rch (2018) and Google (2017). Before joining ETH\, she earned her diploma 
 in Electrical and Computer Engineering at the National Technical Universit
 y of Athens\, Greece.\n\nHer research focuses on building secure\, perform
 ant\, and deployable networked systems using both hardware and software. H
 er research led to discovering significant vulnerabilities in the Bitcoin 
 system and spearheaded changes to the Bitcoin codebase. Maria’s work rec
 eived widespread media coverage and was awarded an Applied Networking Rese
 arch Prize by IETF.\n\n*Contact\nAlicia\nor\nNancy\nfor Zoom link and pass
 word\n\nColloquium Flyer\n\n\n\n\n\nhttps://cpsc.yale.edu/event/cs-colloqu
 ium-maria-apostolaki
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-maria-apostolaki
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Ranjay Krishna
DTSTART;VALUE=DATE-TIME:20210331T200000
DTEND;VALUE=DATE-TIME:20210331T210000
DESCRIPTION:Event description:\nCS Colloquium\nRanjay Krishna\n\nTitle: Vi
 sual Intelligence from Human Learning\n\nHost: Marynel Vázquez\n\nAbstrac
 t:\n\nAt the core of human development is the ability to adapt to new\, pr
 eviously unseen stimuli. We comprehend new situations as a composition of 
 previously seen information and ask one another for clarification when we 
 encounter new concepts. Yet\, this ability to go beyond the confounds of t
 heir training data remains an open challenge for artificial intelligence a
 gents. My research designs visual intelligence to reason over new composit
 ions and acquire new concepts. My talk will explore these challenges and p
 resent the two following lines of work:\n\nFirst\, I will introduce scene 
 graphs\, a cognitively-grounded\, compositional visual representation. I w
 ill discuss how to integrate scene graphs into a variety of computer visio
 n tasks\, enabling models to generalize to novel compositions from a few t
 raining examples. Since our introduction of scene graphs\, the Computer Vi
 sion community has developed hundreds of scene graph models and utilized s
 cene graphs to achieve state-of-the-art results across multiple core tasks
 \, including object localization\, captioning\, image generation\, questio
 n answering\, 3D understanding\, and spatio-temporal action recognition.\n
 \nSecond\, I will introduce a framework for socially situated learning. Th
 is framework pushes agents beyond traditional computer vision training par
 adigms and enables learning from human interactions in online social envir
 onments. I will showcase a real-world deployment of our agent\, which lear
 ned to acquire new visual concepts by asking people targeted questions on 
 social media. By interacting with over 230K people over 8 months\, our age
 nt learned to recognize hundreds of new concepts. This work demonstrates t
 he possibility for agents to adapt and self-improve in real-world social e
 nvironments.\n\nBio:\n\nRanjay Krishna is a 5th-year Ph.D. candidate at St
 anford University\, where he is co-advised by Fei-Fei Li and Michael Berns
 tein. His research lies at the intersection of computer vision and human-c
 omputer interaction\; it draws on ideas from behavioral and social science
 s to improve visual intelligence. His work has been recognized by the Chri
 stofer Stephenson Memorial award\, as an Accell Innovation Scholar and by 
 two Brown Institute for Media Innovation grants. His work has also been fe
 atured in Forbes magazine and in a PBS NOVA documentary. During his Ph.D.\
 , he re-designed Stanford’s undergraduate Computer Vision course and cur
 rently also instructs the graduate Computer Vision course\, Stanford’s s
 econd largest course. He received an M.Sc. from Stanford University. Befor
 e that\, he conferred a B.Sc. with a double major in Electrical Engineerin
 g and in Computer Science from Cornell University. In the past\, he has in
 terned at Google AI\, Facebook AI Research\, and Yahoo Research.\n\n*Conta
 ct\nAlicia\nor\nNancy\nfor Zoom link and password\n\n\n\n\nhttps://cpsc.ya
 le.edu/event/cs-colloquium-ranjay-krishna
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-ranjay-krishna
END:VEVENT
END:VCALENDAR
