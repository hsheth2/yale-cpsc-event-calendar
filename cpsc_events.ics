BEGIN:VCALENDAR
X-WR-CALDESC:Yale Department of Computer Science
X-WR-CALNAME:Yale CS Events
BEGIN:VEVENT
SUMMARY:CS Distinguished Colloquium - James E. Smith\, University of Wisco
 nsin-Madison (Emeritus)
DTSTART;VALUE=DATE-TIME:20210212T150000
DTEND;VALUE=DATE-TIME:20210212T160000
DESCRIPTION:Event description:\nCS Distinguished Colloquium\n\nJames E. Sm
 ith\nUniversity of Wisconsin-Madison (Emeritus)\n\nTitle: A Temporal Neura
 l Network Architecture for Online Learning\n\nZoom link: Join from PC\, M
 ac\, Linux\, iOS or Android:\nhttps://yale.zoom.us/j/98080001575\nOr Telep
 hone：203-432-9666 (2-ZOOM if on-campus) or 646 568 7788\nMeeting ID: 980
  8000 1575\nInternational numbers available:\nhttps://yale.zoom.us/u/acO3V
 IdKco\n\nHost: Abhishek Bhattacharjee\n\nAbstract:\n\nA long-standing prop
 osition is that by emulating the operation of the brain’s neocortex\, a 
 spiking neural network (SNN) can achieve similar desirable features: flexi
 ble learning\, speed\, and efficiency.  Temporal neural networks (TNNs) a
 re SNNs that communicate and process information encoded as relative spike
  times (in contrast to spike rates).  A TNN architecture is proposed\, an
 d as a proof-of-concept\, TNN operation is demonstrated within the larger 
 context of online supervised classification.  First\, through unsupervise
 d learning\, a TNN partitions input patterns into clusters based on simila
 rity.  The TNN learning process adjusts synaptic weights by using only si
 gnals local to each synapse\, and global clustering behavior emerges. The 
 TNN then passes a cluster identifier to a simple online supervised decoder
  which finishes the classification task. Besides features of the overall a
 rchitecture\, several TNN components and methods are new to this work.  A
  long term research objective is a direct hardware implementation.  Conse
 quently\, the architecture is described at a level analogous to the gate a
 nd register transfer levels used in conventional digital design\, and proc
 essing is done at very low precision.\n\nBio:\n\nJames E. Smith is Profess
 or Emeritus in the Department of Electrical and Computer Engineering at th
 e University of Wisconsin-Madison. He received his PhD from the University
  of Illinois in 1976. He then joined the faculty of the University of Wisc
 onsin-Madison\, teaching and conducting research  ̶  first in fault-tol
 erant computing\, then in computer architecture.  He has been involved in
  a number of computer research and development projects both as a faculty 
 member at Wisconsin and in industry.\n\nProf. Smith made a number of contr
 ibutions to the development of superscalar processors. These contributions
  include basic mechanisms for dynamic branch prediction and implementing p
 recise traps.  He has also studied vector processor architectures and wor
 ked on the development of innovative microarchitecture paradigms. He recei
 ved the 1999 ACM/IEEE Eckert-Mauchly Award for these contributions.\n\nFor
  the past several years\, he has been studying neuron-based computing para
 digms at home along the Clark Fork near Missoula\, Montana.\n\n\nhttps://c
 psc.yale.edu/event/cs-distinguished-colloquium-james-e-smith-university-wi
 sconsin-madison-emeritus
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-distinguished-colloquium-james-e-smith-
 university-wisconsin-madison-emeritus
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Jonathan K. Kummerfeld
DTSTART;VALUE=DATE-TIME:20210215T210000
DTEND;VALUE=DATE-TIME:20210215T220000
DESCRIPTION:Event description:\nCS Colloquium\nJonathan K. Kummerfeld\n\nT
 itle: You Are What You Train On:  Creating Robust Natural Language Inte
 rfaces\n\nHost: Dragomir Radev\n\nAbstract:\n\nNatural Language Interfaces
  like Siri and Alexa help people do things more efficiently\, but they are
  brittle\, unable to handle the full range of ways people naturally expres
 s themselves. Each of their actions is manually defined by developers\, wi
 th limited ability to compose actions to make more sophisticated ones. The
  choice of action is made by a statistical model that is limited by the ra
 nge of data seen in training. Despite steady progress in the accuracy of t
 hese systems\, the true scope of remaining challenges has been obscured by
  the way researchers collect and prepare data.\n\nIn this talk\, I will de
 scribe two of my projects that have revealed previously unknown limitation
 s of natural language interfaces and ways to address them. First\, I will 
 show that systems for converting questions to SQL queries have limited gen
 eralizability beyond examples seen in training (ACL 2018). I propose a new
  model and a new way to split data into training and test sets that explor
 e this challenge. Second\, I will show that standard crowd-worker data col
 lection processes miss the long and heavy tail of ways people speak (ACL 2
 017). I propose an outlier-based data collection workflow (NAACL 2019)\, a
 nd a complementary taboo list workflow (EMNLP 2020)\, that improve data di
 versity and reduce the cost of data cleaning. I will conclude by outlining
  a research agenda for fundamentally changing the capabilities of these sy
 stems. Today we use these systems to do simple tasks\, e.g. “start a 5 m
 inute timer”. My work will enable systems to do complex tasks as part of
  applications\, e.g. “Plot population over the last 2000 years with a tr
 end line only and a log scale on the y-axis”.\n\nBio:\n\nJonathan K. Kum
 merfeld is a Postdoctoral Research Fellow in Computer Science and Engineer
 ing at the University of Michigan. He completed his Ph.D. at the Universit
 y of California\, Berkeley\, advised by Prof. Dan Klein. Jonathan’s rese
 arch has revealed new challenges in syntactic parsing\, coreference resolu
 tion\, and dialogue. He has proposed models and algorithms to address thes
 e challenges\, improving the speed and accuracy of natural language proces
 sing systems. He has been on the program committee for 55 conferences and 
 workshops\, including Area Chair at ACL and Shared Task Coordinator for th
 e DSTC workshops. He currently serves as a standing reviewer for the Compu
 tational Linguistics journal and the Transactions of the Association for C
 omputational Linguistics journal. For more details\, see his website:\nhtt
 ps://www.jkk.name\n\n*Contact\nAlicia\nor\nNancy\nfor Zoom link and passwo
 rd\n\nCS Colloquium flyer\n\n\n\n\nhttps://cpsc.yale.edu/event/cs-colloqui
 um-jonathan-k-kummerfeld
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-jonathan-k-kummerfeld
END:VEVENT
BEGIN:VEVENT
SUMMARY:EE Seminar Series - Professor R. Iris Bahar\, Brown University
DTSTART;VALUE=DATE-TIME:20210216T190000
DTEND;VALUE=DATE-TIME:20210216T200000
DESCRIPTION:Event description:\nEE Seminary Series\nProfessor R. Iris Baha
 r\, Brown University\n\nTitle:  Accurate\, Real-time Energy-efficient Sce
 ne Perception through Hardware Acceleration\n\nAbstract:\n\nTechnological 
 advancements have led to a proliferation of robots using machine learning 
 systems to assist humans in a wide range of tasks. However\, we are still 
 far from accurate\, reliable\, and resource-efficient operations of these 
 systems. Despite the strengths of convolutional neural networks (CNNs) for
  object recognition\, these discriminative techniques have several shortco
 mings that leave them vulnerable to exploitation from adversaries.  In ad
 dition\, the computational cost incurred to train these discriminative mod
 els can be quite significant.  Discriminative-generative approaches offer
 s a promising avenue for robust perception and action. Such methods combin
 e inference by deep learning with sampling and probabilistic inference mod
 els to achieve robust and adaptive understanding.  The focus is now on im
 plementing a computationally efficient generative inference stage that can
  achieve real-time results in an energy efficient manner.  In this talk\,
  I will present our work on Generative Robust Inference and Perception (GR
 IP)\, a discriminative-generative approach for pose estimation that offers
  high accuracy especially in unstructured and adversarial environments.  
 I will then describe how we have designed an all-hardware implementation o
 f this algorithm to obtain real-time performance with high energy-efficien
 cy.\n\nBio:\n\nR. Iris Bahar received the B.S. and M.S. degrees in compute
 r engineering from the University of Illinois\, Urbana-Champaign\, and the
  Ph.D. degree in electrical and computer engineering from the University o
 f Colorado\, Boulder. Before entering the Ph.D program at CU-Boulder\, she
  worked for Digital Equipment Corporation on their microprocessor designs.
    She has been on the faculty at Brown University since 1996 and now ho
 lds a dual appointment as Professor of Engineering and Professor of Comput
 er Science.   Her research interests have centered on energy-efficient a
 nd reliable computing\, from the system level to device level.  Most rece
 ntly\, this includes the design of robotic systems.   Recently\, she ser
 ved as the Program Chair and General Chair of the International Conference
  on Computer-Aided Design (ICCAD) in 2017\, 2018 respectively and the Gene
 ral Chair of the International Conference on Architectural Support for Pro
 gramming Languages and Operating Systems (ASPLOS) in 2019. She is the 2019
  recipient of the Marie R. Pistilli Women in Engineering Achievement Award
  and the Brown University School of Engineering Award for Excellence in Te
 aching in Engineering.  More information about her research can be found 
 at\nhttp://cs.brown.edu/people/irisbahar\n\n*Join from PC\, Mac\, Linux\, 
 iOS or Android:\nhttps://yale.zoom.us/j/97928301216\nOr Telephone：203-43
 2-9666 (2-ZOOM if on-campus) or 646 568 7788\nMeeting ID: 979 2830 1216\nI
 nternational numbers available:\nhttps://yale.zoom.us/u/abTKt9xscx\n\nFor 
 H.323 and SIP information for video conferencing units please click here:\
 nhttps://yale.service-now.com/it?id=support_article&sys_id=434b72d3db9e8fc
 83514b1c0ef961924\n\nHave questions about how to use Zoom? Check out the Z
 oom Help Center at\nhttps://support.zoom.us/hc/en-us\n\n\n\n\nhttps://cpsc
 .yale.edu/event/ee-seminar-series-professor-r-iris-bahar-brown-university
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/ee-seminar-series-professor-r-iris-bahar-b
 rown-university
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Deepak Narayanan
DTSTART;VALUE=DATE-TIME:20210216T210000
DTEND;VALUE=DATE-TIME:20210216T220000
DESCRIPTION:Event description:\nCS Colloquium\nDeepak Narayanan\n\nTitle: 
 Resource-Efficient Execution for Deep Learning\n\nHost: Abhishek Bhattacha
 rjee\n\nAbstract:\n\nDeep Learning models have enabled state-of-the-art re
 sults across a broad range of applications\; however\, training these mode
 ls is extremely time- and resource-intensive\, taking weeks on clusters wi
 th thousands of expensive accelerators in the extreme case. In this talk\,
  I will describe two systems that improve the resource efficiency of model
  training. The first system\, PipeDream\, proposes the use of pipelining t
 o accelerate distributed training. Pipeline parallelism facilitates model 
 training with lower communication overhead than previous methods while sti
 ll ensuring high compute resource utilization. Pipeline parallelism also e
 nables the efficient training of large models that do not fit on a single 
 worker. Pipeline parallelism is being used at Facebook\, Microsoft\, OpenA
 I\, and Nvidia for efficient large-scale model training. The second system
 \, Gavel\, determines how resources in a shared cluster with heterogeneous
  compute resources (e.g.\, different types of hardware accelerators) shoul
 d be partitioned among different users to optimize objectives specified ov
 er multiple training jobs. Gavel can improve various scheduling objectives
 \, such as average completion time\, makespan\, or cloud computing resourc
 e cost\, by up to 3.5x. I will conclude the talk with discussion on future
  directions for optimizing Machine Learning systems.\n\nBio\n:\n\n\nDeepak
  Narayanan is a final-year PhD student at Stanford University advised by 
 Prof. Matei Zaharia. He is interested in designing and building software t
 o improve the runtime performance and efficiency of emerging machine learn
 ing and data analytics workloads on modern hardware. His work is supported
  by a NSF graduate fellowship.\n\n*Contact\nAlicia\nor\nNancy\nfor Zoom li
 nk and password\n\nCS Colloquium flyer\n\n\n\nhttps://cpsc.yale.edu/event/
 cs-colloquium-deepak-narayanan
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-deepak-narayanan
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Marios Kogias
DTSTART;VALUE=DATE-TIME:20210218T153000
DTEND;VALUE=DATE-TIME:20210218T163000
DESCRIPTION:Event description:\nCS Colloquium\nMarios Kogias\n\nTitle: Bui
 lding Latency-Critical Datacenter Systems\n\nHost: Avi Silberschatz\n\nAbs
 tract:\n\nOnline services play a major role in our everyday life for commu
 nication\, entertainment\, socializing\, e-commerce\, etc.  These service
 s run inside the datacenter under strict tail-latency service level object
 ives in order to remain interactive. The emergence of new hardware for IO
  has enabled microsecond-scale datacenter communications that challenge th
 e efficiency of existing operating system and network mechanisms. Also\, 
 new in-network programmable devices start being deployed in datacenters an
 d introduce a new computing paradigm that shifts functionality traditional
 ly performed at the end-points to the network.\n\nIn this talk I will revi
 sit the operating systems\, networking\, and distributed systems infrastru
 cture specifically targeting latency-critical datacenter systems\, while d
 rawing intuition from basic queueing theory results. In the first part of
  the talk\, I will focus on ZygOS[SOSP 2017]\, a system optimized for μs-
 scale\, in-memory computing on multicore servers. ZygOS implements a work
 -conserving scheduler within a specialized operating system designed for h
 igh request rates and a large number of network connections. ZygOS reveal
 ed the challenges associated with serving remote procedure calls (RPCs) on
  top of a byte-stream oriented protocol\, such as TCP. In the second part
  of the talk\, I will present R2P2[ATC 2019]. R2P2 is a transport protoco
 l specifically designed for datacenter RPCs\, that exposes the RPC abstrac
 tion to the endpoints and the network\, making RPCs first-class datacenter
  citizens. R2P2 enables pushing functionality\, such as scheduling\, faul
 t-tolerance\, and tail-tolerance\, inside the transport protocol. I will 
 show how using R2P2 allowed us to offload RPC scheduling to programmable s
 witches that can schedule requests directly on individual CPU cores.\n\nBi
 o:\n\nMarios Kogias is a researcher at MSR Cambridge. He graduated from E
 PFL in August 2020. His main research focus is at the intersection of oper
 ating systems and networking in the datacenter. He’s working on buildin
 g and understanding systems with strict tail-latency SLOs leveraging new 
 emerging hardware. He was an IBM PhD Fellow and won the best student paper
  award at Eurosys2020. Before joining EPFL he got his undergrad degree fro
 m the National Technical University of Athens. He has interned at Cern\, 
 Google\, and Microsoft Research.\n\n*Contact\nAlicia\nor\nNancy\nfor Zoom 
 link and password\n\nCS Colloquium flyer\n\n\n\nhttps://cpsc.yale.edu/even
 t/cs-colloquium-marios-kogias
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-marios-kogias
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Amy Zhang
DTSTART;VALUE=DATE-TIME:20210224T210000
DTEND;VALUE=DATE-TIME:20210224T220000
DESCRIPTION:Event description:\nCS Colloquium\nAmy Zhang\n\nTitle: Exploit
 ing latent structure and bisimulation metrics for better generalization in
  reinforcement learning\n\nHost: Marynel Vázquez\n\nAbstract:\n\nThe adve
 nt of deep learning has shepherded unprecedented progress in various field
 s of machine learning. Despite recent advances in deep reinforcement learn
 ing (RL) algorithms\, however\, there is no method today that exhibits any
 where near the generalization that we have seen in computer vision and NLP
 . Indeed\, one might ask whether deep RL algorithms are even capable of th
 e kind of generalization that is needed for open-world environments.  Thi
 s challenge is fundamental and will not be solved with incremental algorit
 hmic advances.\n\nIn this talk\, we propose to incorporate different assum
 ptions that better reflect the real world and allow the design of novel al
 gorithms with theoretical guarantees to address this fundamental problem. 
 We first present how state abstractions can accelerate reinforcement learn
 ing from rich observations\, such as images\, without relying either on do
 main knowledge or pixel-reconstruction. Our goal is to learn state abstrac
 tions that both provide for effective downstream control and invariance to
  task-irrelevant details. We use bisimulation metrics to quantify behavior
 al similarity between states\, and learn robust latent representations whi
 ch encode only the task-relevant information from observations. We provide
  theoretical guarantees for the learned approximate abstraction and extend
  this notion to families of tasks with varying dynamics.\n\nBio:\n\nI am a
  final year PhD candidate at McGill University and the Mila Institute\, co
 -supervised by Profs. Joelle Pineau and Doina Precup. I am also a research
 er at Facebook AI Research. My work focuses on bridging theory and practic
 e through learning approximate state abstractions and learning representat
 ions for generalization in reinforcement learning. I previously obtained a
 n M.Eng. in EECS and dual B.Sci. degrees in Mathematics and EECS from MIT.
 \n\n*Contact\nAlicia\nor\nNancy\nfor Zoom link and password\n\n\nhttps://c
 psc.yale.edu/event/cs-colloquium-amy-zhang
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-amy-zhang
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Alexander R. Fabbri
DTSTART;VALUE=DATE-TIME:20210225T140000
DTEND;VALUE=DATE-TIME:20210225T150000
DESCRIPTION:Event description:\nDissertation Defense\nAlexander R. Fabbri\
 n\nTitle: Text Summarization Across High and Low-resource Settings\n\nZoo
 m Link:\nhttps://yale.zoom.us/j/97743606943\n\nAdvisor: Dragomir Radev\n\
 nOther committee members:\n\nNisheeth Vishnoi\nRobert Frank\nSmaranda Mure
 san (Columbia University)\n\nAbstract:\n\nNatural language processing aims
  to build automated systems that can both understand and generate natural 
 language textual data. As the amount of textual data available online has 
 increased exponentially\, so has the need for intelligence systems to comp
 rehend and present this data to the world. As a result\, automatic text su
 mmarization\, the process by which a text’s salient content is automatic
 ally distilled into a concise form\, has become a necessary tool.\n\nAutom
 atic text summarization approaches and applications vary based on the inpu
 t summarized\, which may constitute single or multiple documents of differ
 ent genres. Furthermore\, the desired output style may consist of a senten
 ce or sub-sentential units chosen directly from the input in extractive su
 mmarization or a fusion and paraphrase of the input document in abstractiv
 e summarization. Despite differences in the above use-cases\, specific the
 mes\, such as the role of large-scale data for training these models\, the
  application of summarization models in real-world scenarios\, and the nee
 d for adequately evaluating and comparing summaries\, are common across th
 ese settings.\n\nThis dissertation presents novel data and modeling techni
 ques for deep neural network-based summarization models trained across lar
 ge-scale and low-resource data settings and a comprehensive evaluation of 
 the model and metric progress in the field.  We examine both Recurrent Ne
 ural Network (RNN)-based and Transformer-based models to extract and gener
 ate summaries from the input. We introduce datasets to facilitate the trai
 ning of large-scale networks in two applications of multi-document summari
 zation. We also propose unsupervised learning techniques for both extracti
 ve summarization in question answering and abstractive summarization and f
 ew-shot and distant supervision learning to use unlabeled data better.\n\n
 In particular\, this dissertation addresses the following research objecti
 ves:\n\n1) High-resource Summarization. We introduce two datasets for mult
 i-document summarization\, focusing on pedagogical applications for NLP an
 d news summarization. In both cases\, we analyze how the models trained on
  these large-scale datasets fare when applied to real-world scenarios and 
 introduce a novel model to reduce redundancy in multi-document summaries.\
 n2) Low-resource Summarization. We propose a pipeline for creating synthet
 ic training data for training extractive question-answering models\, a for
 m of query-based extractive summarization with short-phrase summaries. In 
 other work\, we propose an automatic pipeline for training a multi-documen
 t summarizer in answer summarization on community question-answering forum
 s without labeled data. Finally\, we push the boundaries of abstractive su
 mmarization model performance when little or no training data is available
 .\n3) Automatic Summarization Evaluation. We study the current metrics use
 d to compare summarization output quality across 12 metrics across 23 deep
  neural network models and propose better-motivated summarization evaluati
 on guidelines.\n\n\nhttps://cpsc.yale.edu/event/dissertation-defense-alexa
 nder-r-fabbri
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-alexander-r-fabbri
END:VEVENT
BEGIN:VEVENT
SUMMARY:JBPO Meeting Dates\, AY 2020-21 - Information Only
DTSTART;VALUE=DATE-TIME:20210225T210000
DTEND;VALUE=DATE-TIME:20210225T220000
DESCRIPTION:Event description:\nThe dates for the Joint Boards of Permanen
 t Officers (JBPO) have been scheduled for the 2020-21 academic year.  Ple
 ase reserve:\n\nThursday\, February 25\, 2021\n\nThursday\, April 15\, 202
 1\n\nThursday\, May 13\, 2021\n\nAll meetings start at 4:00 p.m. and will 
 be via Zoom for the foreseeable future. Two weeks prior to each meeting\, 
 an email will be sent with the link to preregister for the meeting\, along
  with the CONFIDENTIAL agenda and supporting materials. After preregisteri
 ng you will receive a confirmation email containing the Zoom link to join 
 the meeting.\n\nIn order to ensure a quorum*\, please attend if you are ab
 le\, especially if you are a designated quorum officer of your department 
 or program.\n\n*Voting in the Joint Boards of Permanent Officers. Full pro
 fessors whose primary or fully joint appointments are in a Faculty of Arts
  and Sciences department may vote\, as may full professors of professional
  schools with secondary appointments in a Faculty of Arts and Sciences dep
 artment and explicit Corporation approval for such voting rights. The only
  exception to this rule is for faculty in Molecular Biophysics and Biochem
 istry who are assigned to vote in the School of Medicine’s Board of Perm
 anent Officers and may not also vote in the Joint Boards of Permanent Offi
 cers of Yale College and the Graduate School. By long standing custom\, a 
 quorum for the conduct of business at a meeting of the Joint Boards consis
 ts of 37 members eligible to vote. No vote has force if the number of vote
 s\, plus recorded abstentions\, falls short of that number. Tenure appoint
 ments are forwarded to the Corporation only upon an affirmative vote by tw
 o-thirds of the members present and eligible to vote. All other appointmen
 ts are approved by majority vote. (Faculty Handbook\, Section IV.F.5)\n\nY
 ale University | Faculty of Arts and Sciences |\nhttp://fas.yale.edu/\n\n\
 nhttps://cpsc.yale.edu/event/jbpo-meeting-dates-ay-2020-21-information-onl
 y
LOCATION:Zoom
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/jbpo-meeting-dates-ay-2020-21-information-
 only
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Arman Cohan
DTSTART;VALUE=DATE-TIME:20210310T210000
DTEND;VALUE=DATE-TIME:20210310T220000
DESCRIPTION:Event description:\nCS Colloquium\nArman Cohan\n\nTitle: Adapt
 ing Transformer models for Document-level Natural Language Tasks\n\nHost: 
 Dragomir Radev\n\nAbstract:\n\nTransformer models have been extremely effe
 ctive at producing word- and sentence-level contextualized representations
 \, achieving state-of-the-art results in many Natural Language Processing 
 (NLP) tasks. However\, extending these models to document-level NLP tasks 
 faces challenges\, including lack of inter-document relatedness informatio
 n\, decreased performance in low-resource settings\, and computational ine
 fficiency when scaling to long documents.\n\nIn this talk\, I will describ
 e a few of my recent works on developing Transformer-based models that tar
 get document-level natural language tasks. I will first introduce SPECTER\
 , a method for producing document representations using a Transformer mode
 l that incorporates document-level relatedness signals and achieves state-
 of-the-art results in multiple document-level tasks in the scientific doma
 in.  Second\, I will describe TLDR\, the task of extreme summarization fo
 r scientific papers as well as CATTs\, a simple yet effective training str
 ategy for generating summaries in low-resource settings. Next\, I will dis
 cuss the practical challenges of scaling existing Transformer models to lo
 ng documents\, and our proposed solution\, Longformer. Longformer\, introd
 uces a new sparse self-attention pattern that scales linearly with the inp
 ut length while capturing both local and global context in the document\, 
 achieving state-of-the-art results in both character-level language modeli
 ng and document NLP tasks. Finally\, I’ll discuss CDLM\, our newly propo
 sed general pre-trained model for addressing multi-document tasks.\n\nBio:
 \n\nArman Cohan is a Research Scientist at the Allen Institute for AI (AI2
 ). He received his PhD in computer Science at Georgetown University in May
  2018\, advised by Prof. Nazli Goharian. His research is primarily focused
  on developing general Natural Language Processing capabilities to address
  information overload\, particularly in specialized domains that pose uniq
 ue challenges. These include core representation learning and language mod
 eling methods\, systems and models designed for extracting and summarizing
  salient information\, and models for improved search and categorization i
 n large collections of data.\n\nHe has served as program committee member 
 of major NLP venues including ACL\, EMNLP\, and NAACL in the past 4 years\
 , served as area chair at ACL 2020\, ICLR 2021 and NAACL 2021\, and organi
 zed workshops including SciNLP and SDP.\n\nHis research has been recognize
 d with multiple awards including best paper award at EMNLP 2017\, area cha
 ir favorite paper award at COLING 2018\, and Harold N. Glassman Distinguis
 hed Doctoral Dissertation award in 2019.\n\n*Contact\nAlicia\nor\nNancy\nf
 or Zoom link and password\n\n\nhttps://cpsc.yale.edu/event/cs-colloquium-a
 rman-cohan
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-arman-cohan
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Tao Yu
DTSTART;VALUE=DATE-TIME:20210310T223000
DTEND;VALUE=DATE-TIME:20210310T233000
DESCRIPTION:Event description:\nDissertation Defense\nTao Yu\n\nTitle: Le
 arning to Map Natural Language to Executable Programs Over Databases\n\nZo
 om Link:\nhttps://yale.zoom.us/j/96388771156\n\nAdvisor: Dragomir Radev\n
 \nOther committee members:\n\nRobert Frank\nMarynel Vazquez\nKathleen McKe
 own (Columbia University)\nLuke Zettlemoyer (University of Washington)\n\n
 Abstract:\n\nNatural language is a fundamental form of information and com
 munication and will be the next frontier in computer interfaces. Natural L
 anguage Interfaces (NLI) bridge the data and the user\, significantly prom
 oting the possibility and efficiency of information access for many users 
 besides data experts. All consumer-facing software will one day have a dia
 logue interface\, the next vital leap in the evolution of search engines. 
 Such intelligent dialogue systems should be able to understand the meaning
  of language grounded in various contexts and generate effective language 
 responses in different forms for information requests and human-computer c
 ommunication. In particular\, this dissertation focuses on answering the f
 ollowing three questions: 1) How can NLI ground human requests in natural 
 language into formal programs (e.g.\, SQL)? 2) How can NLI converse with h
 umans in a robust manner? 3) How can neural models understand compositiona
 lity in human language?\n\n\nhttps://cpsc.yale.edu/event/dissertation-defe
 nse-tao-yu
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-tao-yu
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Karl Wüst
DTSTART;VALUE=DATE-TIME:20210311T153000
DTEND;VALUE=DATE-TIME:20210311T163000
DESCRIPTION:Event description:\nCS Colloquium\nKarl Wüst\n\nTitle: Trust 
 or Decentralize? Balancing Trust and Performance in Decentralized Systems\
 n\nHost: Zhong Shao\n\nAbstract:\n\nIn recent years\, cryptocurrencies and
  blockchains have received widespread attention. These systems are general
 ly designed to be decentralized in order to reduce the required trust assu
 mptions as much as possible. However\, there are choices to be made about 
 how much to trust and how much to decentralize which in turn greatly affec
 t the properties that can be achieved efficiently.\nIn this talk\, I will 
 discuss how these choices can be leveraged for large performance gains and
  to achieve new properties in smart contract systems and for privacy-prese
 rving cryptocurrency transactions.\nIn particular\, I will show how smart 
 contract scalability can be improved by executing contracts in smaller com
 mittees\, while at the same time allowing safe interaction between untrust
 ed contracts. Further\, I will show how lightweight blockchain clients for
  fully anonymous cryptocurrencies can be enabled efficiently\, and how pri
 vacy and accountability can be balanced in central bank digital currencies
 .\n\nBio:\n\nKarl Wüst is a PhD Candidate in the System Security Group at
  ETH Zurich.\nHis research focuses on the security and privacy of blockcha
 in technology with a particular focus on smart contract scalability and ce
 ntral bank cryptocurrencies. In his research\, he combines techniques from
  cryptography\, distributed systems\, and trusted computing to balance the
  trade-off between reducing trust and achieving high performance. His rese
 arch has been published at top venues in security (CCS\, Usenix Security\,
  NDSS) and resulted in multiple patent applications.\n\n*Contact\nAlicia\n
 or\nNancy\nfor Zoom link and password\n\n\nhttps://cpsc.yale.edu/event/cs-
 colloquium-karl-wust
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-karl-wust
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Angelique Taylor
DTSTART;VALUE=DATE-TIME:20210315T200000
DTEND;VALUE=DATE-TIME:20210315T210000
DESCRIPTION:Event description:\nCS Colloquium\nAngelique Taylor\n\nTitle: 
 Perception and Decision-Making Systems for Human-Robot Teaming in Safety-C
 ritical Environments\n\nHost: Brian Scassellati\n\nAbstract:\n\nIn this ta
 lk\, I will present my current and future work on developing perception an
 d decision making systems that enable robots to team with groups of people
 . My core focus is on problems that robots encounter in human-robot teamin
 g\, including perceptions of human groups and social navigation\, particul
 arly in safety-critical environments.\n\nFirst\, I will discuss how I deve
 loped computer vision methods that enable robots to detect and track their
  teammates in real-world environments. Most group perception methods emplo
 y fixed\, overhead cameras (i.e.\, an exo-centric / third-person perspecti
 ve) to sense groups of people\, rendering them impractical for mobile robo
 ts working in most settings. I have developed a group detection and tracki
 ng system designed for ego-centric (i.e.\, first-person) perspective sensi
 ng\, which is more suitable for mobile robots\, to enable them to enter an
 y environment and accomplish their goals without external sensing requirem
 ents.\n\nNext\, I will discuss this work contextualized within a real-worl
 d application: human-robot teaming in healthcare. I am developing systems 
 for hospital Emergency Departments (ED)\, where frontline healthcare worke
 rs have been overwhelmed by the COVID-19 pandemic. I will describe my work
  characterizing ED care delivery and staff workflow to enable robots to op
 erate in these challenging environments. Building on this\, I designed a s
 ocial navigation system that enables robots to incorporate the severity of
  patients’ health while navigating in the ED\, to prevent interruptions 
 in care delivery. My work will enable robots to work in safety-critical\, 
 human-centered environments\, and ultimately help improve patient outcomes
  and alleviate clinician workload.\n\nBio:\n\nAngelique Taylor is a Ph.D. 
 candidate in Computer Science and Engineering at UC San Diego. Her researc
 h lies at the intersection of computer vision\, robotics\, and health info
 rmatics. She develops systems that enable robots to interact and work with
  groups of people in safety-critical environments. She has received the NS
 F GRFP\, Microsoft Dissertation Award\, the Google Anita Borg Memorial Fel
 lowship\, the Arthur J. Schmitt Presidential Fellowship\, a GEM Fellowship
 \, and an award from the National Center for Women in Information Technolo
 gy (NCWIT). More information on her research can be found at\nangeliquemta
 ylor.com\n.\n\n*Contact\nAlicia\nor\nNancy\nfor Zoom link and password\n\n
 CS Colloquium flyer\n\n\n\nhttps://cpsc.yale.edu/event/cs-colloquium-angel
 ique-taylor
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-angelique-taylor
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Kexin Rong
DTSTART;VALUE=DATE-TIME:20210316T200000
DTEND;VALUE=DATE-TIME:20210316T210000
DESCRIPTION:Event description:\nCS Colloquium\nKexin Rong\n\nTitle: Priori
 tizing Computation and Analyst Resources in Large-scale Data Analytics\n\n
 Host: Abhishek Bhattacharjee\n\nAbstract:\n\nData volumes are growing expo
 nentially\, fueled by an increased number of automated processes such as s
 ensors and devices. Meanwhile\, the computational power available for proc
 essing this data – as well as analysts’ ability to interpret it – re
 main limited. As a result\, database systems must evolve to address these 
 new bottlenecks in analytics. In my work\, I ask: how can we adapt classic
  ideas from database query processing to modern compute- and analyst-limit
 ed data analytics?\n\nIn this talk\, I will discuss the potential for this
  kind of systems development through the lens of several practical systems
  I have developed. By drawing insights from database query optimization\, 
 such as pushing workload- and domain-specific filtering\, aggregation\, an
 d sampling into core analytics workflows\, we can dramatically improve the
  efficiency of analytics at scale. I will illustrate these ideas by focusi
 ng on two systems — one designed to optimize visualizations for streamin
 g infrastructure and application telemetry and one designed for high-volum
 e seismic waveform analysis — both of which have been field-tested at sc
 ale. I will also discuss lessons from production deployments at companies 
 including Datadog\, Microsoft\, Google and Facebook.\n\nBio:\n\nKexin Rong
  is a Ph.D. student in Computer Science at Stanford University\, co-advise
 d by Professor Peter Bailis and Professor Philip Levis. She designs and bu
 ilds systems to enable data analytics at scale\, supporting applications i
 ncluding scientific analysis\, infrastructure monitoring\, and analytical 
 queries on big data clusters. Prior to Stanford\, she received her bachelo
 r’s degree in Computer Science from California Institute of Technology.\
 n\n*Contact\nAlicia\nor\nNancy\nfor Zoom link and password\n\n\n\n\nhttps:
 //cpsc.yale.edu/event/cs-colloquium-kexin-rong
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-kexin-rong
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Yongshan Ding
DTSTART;VALUE=DATE-TIME:20210318T143000
DTEND;VALUE=DATE-TIME:20210318T153000
DESCRIPTION:Event description:\nCS Colloquium\nYongshan Ding\n\nTitle: Arc
 hitecting Quantum Computing Systems in the Presence of Noise\n\nHost: Lin 
 Zhong\n\nAbstract:\n\nQuantum computers may solve some problems beyond the
  reach of classical digital computers. However\, emerging quantum systems 
 are typically noisy and difficult to control\, leaving a significant gap b
 etween the exacting requirements of quantum applications and the realities
  of noisy devices. Bridging this gap is crucial – my work adapts convent
 ional computer systems techniques to meet the critical theoretical and exp
 erimental constraints in quantum processors. I divide my talk into three p
 arts: (i) introducing my recent work on systematic noise mitigation for su
 perconducting transmon qubits [MICRO’20]\, which enhances the robustness
  of quantum processors through coordination of control instructions\; (ii)
  demonstrating efficient and reliable quantum memory management [ISCA’20
 ]\, which implements automated tools for allocation\, reclamation and reus
 e of qubits in quantum programs\, much like in garbage collection for clas
 sical programs\; (iii) discussing on-going work on implementing quasi-faul
 t-tolerant rotation gates in quantum error correction\, which seeks to pro
 vide correctness guarantees for quantum applications by encoding quantum b
 its in a way that errors can be detected and corrected\, analogous to clas
 sical error-correcting codes.\n\nBio:\n\nYongshan Ding is a Ph.D. candidat
 e at the University of Chicago advised by Fred Chong. He received his B.Sc
 . degrees in computer science and physics from Carnegie Mellon University.
  His research focuses on quantum computer systems\, specifically through c
 o-design of quantum algorithms\, software\, and devices. Ding has develope
 d novel techniques for quantum error correction\, quantum memory managemen
 t\, and optimizations at the quantum-classical interface. His work has bee
 n recognized with two Best Paper Awards by IBM Q and QCE’20 and two Hono
 rable Mentions in IEEE Micro Top Picks. Additionally\, Ding is the lead au
 thor of a textbook\, Quantum Computer Systems\, in Morgan-Claypool Publish
 er’s synthesis lectures in computer architecture. He has been supported 
 by a Siebel Scholarship and a William Rainey Harper Dissertation Fellowshi
 p. His personal website is\nhttps://people.cs.uchicago.edu/~yongshan/\n.\n
 \n*Contact\nAlicia\nor\nNancy\nfor Zoom link and password\n\n\nhttps://cps
 c.yale.edu/event/cs-colloquium-yongshan-ding
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-yongshan-ding
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Maria Apostolaki
DTSTART;VALUE=DATE-TIME:20210325T143000
DTEND;VALUE=DATE-TIME:20210325T153000
DESCRIPTION:Event description:\nCS Colloquium\nMaria Apostolaki\n\nTitle: 
 Building secure distributed systems atop the insecure Internet\n\nHost: An
 urag Khandelwal\n\nAbstract:\n\nDistributed systems are increasingly impor
 tant for our everyday life\, allowing for high performance\, fault toleran
 ce\, and flexibility. Many of these systems nowadays rely on the inherentl
 y insecure Internet infrastructure. Surely though\, they should have been 
 designed to take this into account…?\n\nIn this talk\, I will answer neg
 atively to this question using a concrete example: public blockchain syste
 ms such as Bitcoin. These are novel distributed systems that are designed 
 according to stringent failure models. In this context\, I will explain ho
 w an adversary controlling pieces of Internet infrastructure can practical
 ly compromise: (i) Bitcoin’s consensus protocol (by partitioning the net
 work)\; (ii) Bitcoin’s anonymity guarantees (by mapping pseudonyms to re
 al-world identities)\; and (iii) Bitcoin’s availability (by eclipsing cl
 ients).\n\nWhile these attacks are worrying\, I will also introduce practi
 cal and effective defenses to counter them both at the network and the app
 lication layer. Beyond Bitcoin\, this work teaches essential lessons for d
 istributed-system design.\n\nBio:\n\nMaria Apostolaki is a PhD Student at 
 ETH Zurich advised by Laurent Vanbever.\nDuring her studies\, she has been
  a visiting student at MIT (2019) and a research intern at Microsoft Resea
 rch (2018) and Google (2017). Before joining ETH\, she earned her diploma 
 in Electrical and Computer Engineering at the National Technical Universit
 y of Athens\, Greece.\n\nHer research focuses on building secure\, perform
 ant\, and deployable networked systems using both hardware and software. H
 er research led to discovering significant vulnerabilities in the Bitcoin 
 system and spearheaded changes to the Bitcoin codebase. Maria’s work rec
 eived widespread media coverage and was awarded an Applied Networking Rese
 arch Prize by IETF.\n\n*Contact\nAlicia\nor\nNancy\nfor Zoom link and pass
 word\n\nColloquium Flyer\n\n\n\n\n\nhttps://cpsc.yale.edu/event/cs-colloqu
 ium-maria-apostolaki
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-maria-apostolaki
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Ranjay Krishna
DTSTART;VALUE=DATE-TIME:20210331T200000
DTEND;VALUE=DATE-TIME:20210331T210000
DESCRIPTION:Event description:\nCS Colloquium\nRanjay Krishna\n\nTitle: Vi
 sual Intelligence from Human Learning\n\nHost: Marynel Vázquez\n\nAbstrac
 t:\n\nAt the core of human development is the ability to adapt to new\, pr
 eviously unseen stimuli. We comprehend new situations as a composition of 
 previously seen information and ask one another for clarification when we 
 encounter new concepts. Yet\, this ability to go beyond the confounds of t
 heir training data remains an open challenge for artificial intelligence a
 gents. My research designs visual intelligence to reason over new composit
 ions and acquire new concepts. My talk will explore these challenges and p
 resent the two following lines of work:\n\nFirst\, I will introduce scene 
 graphs\, a cognitively-grounded\, compositional visual representation. I w
 ill discuss how to integrate scene graphs into a variety of computer visio
 n tasks\, enabling models to generalize to novel compositions from a few t
 raining examples. Since our introduction of scene graphs\, the Computer Vi
 sion community has developed hundreds of scene graph models and utilized s
 cene graphs to achieve state-of-the-art results across multiple core tasks
 \, including object localization\, captioning\, image generation\, questio
 n answering\, 3D understanding\, and spatio-temporal action recognition.\n
 \nSecond\, I will introduce a framework for socially situated learning. Th
 is framework pushes agents beyond traditional computer vision training par
 adigms and enables learning from human interactions in online social envir
 onments. I will showcase a real-world deployment of our agent\, which lear
 ned to acquire new visual concepts by asking people targeted questions on 
 social media. By interacting with over 230K people over 8 months\, our age
 nt learned to recognize hundreds of new concepts. This work demonstrates t
 he possibility for agents to adapt and self-improve in real-world social e
 nvironments.\n\nBio:\n\nRanjay Krishna is a 5th-year Ph.D. candidate at St
 anford University\, where he is co-advised by Fei-Fei Li and Michael Berns
 tein. His research lies at the intersection of computer vision and human-c
 omputer interaction\; it draws on ideas from behavioral and social science
 s to improve visual intelligence. His work has been recognized by the Chri
 stofer Stephenson Memorial award\, as an Accell Innovation Scholar and by 
 two Brown Institute for Media Innovation grants. His work has also been fe
 atured in Forbes magazine and in a PBS NOVA documentary. During his Ph.D.\
 , he re-designed Stanford’s undergraduate Computer Vision course and cur
 rently also instructs the graduate Computer Vision course\, Stanford’s s
 econd largest course. He received an M.Sc. from Stanford University. Befor
 e that\, he conferred a B.Sc. with a double major in Electrical Engineerin
 g and in Computer Science from Cornell University. In the past\, he has in
 terned at Google AI\, Facebook AI Research\, and Yahoo Research.\n\n*Conta
 ct\nAlicia\nor\nNancy\nfor Zoom link and password\n\n\n\n\nhttps://cpsc.ya
 le.edu/event/cs-colloquium-ranjay-krishna
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-ranjay-krishna
END:VEVENT
END:VCALENDAR
