BEGIN:VCALENDAR
X-WR-CALDESC:Yale Department of Computer Science
X-WR-CALNAME:Yale CS Events
BEGIN:VEVENT
SUMMARY:CS Talk - Xinyun Chen
DTSTART;VALUE=DATE-TIME:20220222T210000
DTEND;VALUE=DATE-TIME:20220222T220000
DESCRIPTION:Event description:\nCS Talk\nXinyun Chen\n\nHost: Dragomir Rad
 ev\n\nTitle: Learning-Based Program Synthesis: Learning for Program Synthe
 sis and Program Synthesis for Learning\n\nAbstract:\n\nWith the advancemen
 t of modern technologies\, programming becomes ubiquitous not only among p
 rofessional software developers\, but also for general computer users. How
 ever\, gaining programming expertise is time-consuming and challenging. Th
 erefore\, program synthesis has many applications\, where the computer aut
 omatically synthesizes programs from specifications such as natural langua
 ge descriptions and input-output examples. In this talk\, I will present m
 y work on learning-based program synthesis\, where I have developed deep l
 earning techniques for various program synthesis problems. Despite the rem
 arkable success of deep neural networks for many domains\, including natur
 al language processing and computer vision\, existing deep neural networks
  are still insufficient for handling challenging symbolic reasoning and ge
 neralization problems.\n\nMy learning-based program synthesis research lie
 s in two folds: (1) learning to synthesize programs from potentially ambig
 uous and complex specifications\; and (2) neural-symbolic learning for lan
 guage understanding. I will first talk about program synthesis application
 s\, where my work demonstrates the applicability of learning-based program
  synthesizers for production usage. I will then present my work on neural-
 symbolic frameworks that integrate symbolic components into neural network
 s\, which achieve better reasoning and generalization capabilities. In clo
 sing\, I will discuss the challenges and opportunities of further improvin
 g the complexity and generalizability of learning-based program synthesis 
 for future work.\n\nBio:\n\nXinyun Chen is a Ph.D. candidate at UC Berkele
 y\, working with Prof. Dawn Song. Her research lies at the intersection of
  deep learning\, programming languages\, and security. Her recent research
  focuses on learning-based program synthesis and adversarial machine learn
 ing. She received the Facebook Fellowship in 2020. She was selected for Ri
 sing Stars in EECS in 2020 and 2021\, and Rising Stars in Machine Learning
  in 2021.\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/cs-talk-xinyun-ch
 en
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-xinyun-chen
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Maria Pacheco
DTSTART;VALUE=DATE-TIME:20220223T210000
DTEND;VALUE=DATE-TIME:20220223T220000
DESCRIPTION:Event description:\nCS Talk\nMaria Pacheco\n\nHost: Marynel V
 ázquez\n\nTitle: Neural-Symbolic Modeling for Natural Language Discourse
 \n\nAbstract:\n\nLanguage “in the wild” is complex and ambiguous and r
 elies on a shared understanding of the world for its interpretation. Most 
 current NLP methods represent language by learning word co-occurrence patt
 erns from massive amounts of linguistic data. This representation can be v
 ery powerful\, but it is insufficient to capture the meaning behind writte
 n and spoken communication. In this talk\, I will motivate neural-symbolic
  representations for dealing with these challenges. On the one hand\, symb
 ols have inherent explanatory power\, and they can help us express domain 
 knowledge and enforce consistency across different decisions. On the other
  hand\, expressive distributed representations allow us to leverage the st
 rengths of statistical language models to make sense of large amounts of l
 inguistic data.\n\nIn this talk\, I will introduce a holistic framework th
 at covers all stages of the neural-symbolic pipeline: modeling\, learning\
 , inference\, and its application for analyzing discourse in real-world sc
 enarios and show its advantages with respect to end-to-end neural approach
 es and traditional statistical relational learning methods.\n\nBio\n:\n\nM
 aria Pacheco is a PhD Candidate in the Department of Computer Science at P
 urdue University. Her research focuses broadly on neural-symbolic methods
  to model natural language discourse scenarios\, such as analyzing convers
 ations\, argumentation\, and narratives. Before joining Purdue\, she spent
  a couple of years working as a data scientist and software engineer for v
 arious startups in her hometown of Caracas\, Venezuela. She has published 
 in top Natural Language Processing conferences and journals and has delive
 red tutorials on neural-symbolic modeling for NLP to diverse audiences\, i
 ncluding an IJCAI ‘21 tutorial and an upcoming COLING ‘22 tutorial. Ma
 ria is a recipient of the 2021 Microsoft Research Dissertation Grant\, and
  one of the main organizers of the LatinX in AI events in NLP.\n\nTalk fly
 er\n\n\nhttps://cpsc.yale.edu/event/cs-talk-maria-pacheco-0
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-maria-pacheco-0
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Arman Cohan
DTSTART;VALUE=DATE-TIME:20220228T210000
DTEND;VALUE=DATE-TIME:20220228T220000
DESCRIPTION:Event description:\nCS Talk\n\nArman\nCohan\n\nHost: Dragomir 
 Radev\n\nTitle: Beyond Sentences and Paragraphs: Towards Document and Mult
 i-document Understanding\n\nAbstract:\n\nDuring the past few years\, there
  has been significant progress in natural language understanding\, primari
 ly due to the advancements in transfer learning methods and the increasing
  scale of pre-trained language models. However\, the majority of progress 
 has been made on tasks concerning short texts with sentences or paragraphs
  as the basic unit of analysis. Yet\, many real-world natural language tas
 ks require understanding full documents which includes learning effective 
 representation of documents\, resolving longer range dependencies\, struct
 ure\, and argumentation. Further\, certain tasks require incorporating add
 itional context from multiple related documents (e.g.\, understanding a sc
 ientific paper) and aggregating information across multiple documents. In 
 this talk\, I will discuss some of our recent works on addressing these ch
 allenges. I will first discuss general methods for document representation
  learning that help to achieve strong downstream performance on a variety 
 of document-level tasks. Then I will focus on how we can have a general pr
 e-trained language model that can process long documents. Using this frame
 work\, I will discuss extensions to multi-document natural language unders
 tanding for a variety of classification\, extraction\, and summarization t
 asks. I will also briefly discuss a few of our newly developed benchmarks 
 from challenging domains that enable us to better measure progress on docu
 ment natural language understanding.\n\nBio:\n\nArman Cohan is a Research 
 Scientist at the Allen Institute for AI (AI2) and an Affiliate Assistant P
 rofessor at the University of Washington. His broad research interest is d
 eveloping natural language processing (NLP) methods for addressing informa
 tion overload. This includes models and benchmarks for document and multi-
 document understanding\, natural language generation and summarization\, a
 s well as information discovery and filtering. He is additionally interest
 ed in real-world interdisciplinary applications of NLP in the science and 
 health domains. His research has been recognized with multiple awards\, in
 cluding a best paper award at EMNLP 2017\, an honorable mention at COLING 
 2018\, and the 2019 Harold N. Glassman Distinguished Doctoral Dissertation
  award.\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/cs-talk-arman-cohan
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-arman-cohan
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Suguman Bansal
DTSTART;VALUE=DATE-TIME:20220307T210000
DTEND;VALUE=DATE-TIME:20220307T220000
DESCRIPTION:Event description:\nCS Talk\nSuguman Bansal\n\nHost: Ruzica Pi
 skac\n\nTitle: Specification-Guided Policy Synthesis\n\nAbstract:\n\nPolic
 y synthesis\nor algorithms to design policies for computational systems is
  one of the fundamental problems in computer science. Standing on the shou
 lders of simplified yet concise\ntask-specification\nusing high-level logi
 cal specification languages\, this talk will cover synthesis algorithms us
 ing two contrasting approaches. First\, the classical logic-based approach
  of reactive synthesis\; Second\, the modern learning-based approach of re
 inforcement learning. This talk will cover our scalable and efficient stat
 e-of-the-art algorithms for synthesis from high-level specifications using
  both these approaches\, and investigate whether formal guarantees are pos
 sible. We will conclude with a forward-looking view of these contributions
  to trustworthy AI.\n\nBio:\n\nSuguman Bansal\nis an NSF/CRA Computing Inn
 ovation Postdoctoral Fellow at the University of Pennsylvania\, mentored b
 y Prof. Rajeev Alur. Her primary area of research is Formal Methods and Pr
 ogramming Langauge\, and her secondary area of research is Artificial Inte
 lligence.\n\nShe is the recipient of the 2020 NSF CI Fellowship and has be
 en named a 2021 MIT EECS Rising Star. Her research has appeared at venues 
 in formal methods and programming languages (CAV\, POPL\, TACAS)\, and art
 ificial intelligence and machine learning (AAAI\, NeurIPS). She completed 
 her Ph.D. in 2020\, advised by Prof. Moshe Y. Vardi\, from Rice University
 . She received B.S. with Honors in 2014 from Chennai Mathematical Institut
 e.\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/cs-talk-suguman-bansal
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-suguman-bansal
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Matthew Amodio
DTSTART;VALUE=DATE-TIME:20220308T200000
DTEND;VALUE=DATE-TIME:20220308T210000
DESCRIPTION:Event description:\nDissertation Defense\nMatthew Amodio\n\nTi
 tle: Deep Learning for Embedding and Integrating Multimodal Biomedical Dat
 a\n\nAdvisor\n:\nSmita Krishnaswamy\n\nOther committee members:\n\nRonald 
 Coifman\nVladimir Rokhlin\n\nAbstract:\n\nBiomedical data is being generat
 ed in extremely high throughput and high dimension by technologies in area
 s ranging from single-cell genomics\, proteomics\, and transcriptomics (cy
 tometry\, single-cell RNA and ATAC sequencing) to neuroscience and cogniti
 on (fMRI and PET) to pharmaceuticals (drug perturbations and interactions)
 . These new and emerging technologies and the datasets they create give an
  unprecedented view into the workings of their respective biological entit
 ies. However\, there is a large gap between the information contained in t
 hese datasets and the insights that current machine learning methods can e
 xtract from them.\n\nThis is especially the case when multiple technologie
 s can measure the same underlying biological entity or system. By separate
 ly analyzing the same system but from different views gathered by differen
 t data modalities\, patterns are left unobserved if they only emerge from 
 the multi-dimensional joint representation of all of the modalities togeth
 er. Through an interdisciplinary approach that emphasizes active collabora
 tion with data domain experts\, my research has developed models for \\tex
 tbf{data integration}\, extracting important insights through the joint an
 alysis of varied data sources.\n\nIn this thesis\, I discuss models that a
 ddress this task of multi-modal data integration\, especially generative a
 dversarial networks (GANs) and autoencoders (AEs). My research has been fo
 cused on using both of these models in a generative way for concrete probl
 ems in cutting-edge scientific applications rather than the exclusive focu
 s on the generation of high-resolution natural images. The research in thi
 s thesis is united around ideas of building models that can extract new kn
 owledge from scientific data inaccessible to currently existing methods.\n
 \n\nhttps://cpsc.yale.edu/event/dissertation-defense-matthew-amodio
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-matthew-amodio
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Manolis Zampetakis
DTSTART;VALUE=DATE-TIME:20220308T210000
DTEND;VALUE=DATE-TIME:20220308T220000
DESCRIPTION:Event description:\nCS Talk\nManolis Zampetakis\n\nHost: Yang 
 Cai\n\nTitle: How to handle Biased Data and Multiple Agents in Machine Lea
 rning?\n\nAbstract:\n\nModern machine learning (ML) methods commonly postu
 late strong assumptions such as: (1) access to data that adequately captur
 es the application environment\, (2) the goal is to optimize the objective
  function of a single agent\, assuming that the application environment is
  isolated and is not affected by the outcome chosen by the ML system. In t
 his talk I will present methods with theoretical guarantees that are appli
 cable in the absence of (1) and (2) as well as corresponding fundamental l
 ower bounds. In the context of (1) I will focus on how to deal with trunca
 tion and self-selection bias and in the context of (2) I will present a fo
 undational comparison between two-objective and single objective optimizat
 ion.\n\nBio:\n\nManolis Zampetakis is currently a post-doctoral researcher
  at the EECS Department of UC Berkeley working with Michael Jordan. He rec
 eived his PhD from the EECS Department at MIT where he was advised by Cons
 tantinos Daskalakis. He has been awarded the Google PhD Fellowship and the
  ACM SIGEcom Doctoral Dissertation Award. He works on the foundations of m
 achine learning (ML)\, statistics\, and data science\, with focus on stati
 stical analysis from systematically biased data\, optimization methods for
  multi-agent environments\, and convergence properties of popular heuristi
 c methods.\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/cs-talk-manolis-
 zampetakis
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-manolis-zampetakis
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - William Hallahan
DTSTART;VALUE=DATE-TIME:20220309T210000
DTEND;VALUE=DATE-TIME:20220309T220000
DESCRIPTION:Event description:\nDissertation Defense\nWilliam Hallahan\n\n
 Title: Automated Approaches for Program Verification and Repair\n\nAdviso
 r\n:\nRuzica Piskac\n\nOther committee members:\nZhong Shao\nAbhishek Bhat
 tacharjee\nNate Foster (Cornell University)\n\nAbstract:\n\nFormal methods
  techniques such as verification\, analysis\, and synthesis allow programm
 ers to prove properties of their programs\, or automatically derive progra
 ms from specifications. This dissertation presents automated analysis and 
 synthesis techniques to ease the debugging of modular verification systems
 \, allow easy access to constraint solvers from functional code\, and to r
 educe the burden of network administrators writing and analyzing firewalls
 .\n\nWe describe the design and implementation of a symbolic execution eng
 ine\, G2\, for non-strict functional languages such as Haskell. We then ex
 tended G2 to assist with modular verification. Modular verifiers allow pro
 grammers to write and prove specifications of their code. When a modular v
 erifier fails to verify a program\, it could be because of an actual bug i
 n the program\, but it could also be because a specification somewhere in 
 the program is too weak. We present a technique\, counterfactual symbolic 
 execution\, to aid in the debugging of both types of modular verification 
 failures\, by finding counterexample or counterexample-like explanations o
 f the failure. Further\, a counterexample-guided inductive synthesis (CEGI
 S) loop based technique is introduced to fully automate modular verificati
 on\, by using found counterexamples to automatically infer needed function
  specifications. The counterfactual symbolic execution and automated speci
 fication inference techniques are evaluated on existing LiquidHaskell erro
 rs and programs.\n\nIn addition to leveraging G2 to explain modular verifi
 cation errors\, we built a library\, G2Q\, which makes it easy for Haskell
  programmers to call G2 to solve constraint problem written in Haskell. G2
 Q uses symbolic execution to unroll recursive function definitions\, and g
 uarantees that the use of G2Q constraints will preserve type correctness.\
 n\nFinally\, we describe techniques to ease analysis and repair of firewal
 ls. Firewalls are widely deployed to manage network security. However\, fi
 rewall systems provide only a primitive interface\, in which the specifica
 tion is given as an ordered list of rules. This makes it hard to manually 
 track and maintain the behavior of a firewall. We introduce a formal seman
 tics for iptables firewall rules via a translation to first-order logic wi
 th uninterpreted functions and linear integer arithmetic\, which allows en
 coding of firewalls into a decidable logic. We then describe techniques to
  automate the analysis and repair of firewalls using SMT solvers\, based o
 n user provided specifications of the desired behavior. We evaluate this a
 pproach with real world case studies collected from StackOverflow users.\n
 \n\nhttps://cpsc.yale.edu/event/dissertation-defense-william-hallahan
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-william-hallahan
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Matthew Mirman
DTSTART;VALUE=DATE-TIME:20220310T153000
DTEND;VALUE=DATE-TIME:20220310T163000
DESCRIPTION:Event description:\nCS Talk\nMatthew Mirman\n\nHost: Abhishek 
 Bhattacharjee\n\nTitle: Trustworthy Deep Learning: methods\, systems and t
 heory\n\nAbstract:\n\nDeep learning models are quickly becoming an integra
 l part of a plethora of high stakes applications\, including autonomous dr
 iving and health care.  As the discovery of vulnerabilities and flaws in 
 these models has become frequent\, so has the interest in ensuring their s
 afety\, robustness and reliability.  My research addresses this need by i
 ntroducing new core methods and systems that can establish desirable mathe
 matical guarantees of deep learning models.\n\nIn the first part of my tal
 k I will describe how we leverage abstract interpretation to scale verific
 ation to orders of magnitude larger deep neural networks than prior work\,
  at the same time demonstrating the correctness of significantly more prop
 erties.  I will then show how these techniques can be extended to ensure\
 , for the first time\, formal guarantees of probabilistic semantic specifi
 cations using generative models.\n\nIn the second part\, I will show how t
 o fuse abstract interpretation with the training phase so as to improve a 
 model’s amenability to certification\, allowing us to guarantee orders o
 f magnitude more properties than possible with prior work.  Finally\, I w
 ill discuss exciting theoretical advances which address fundamental questi
 ons on the very existence of certified deep learning.\n\nBio:\n\nMatthew M
 irman is a final-year PhD student at ETH Zürich\, supervised by Martin Ve
 chev. His main research interests sit at the intersection of programming l
 anguages\, machine learning\, and theory with applications to creating saf
 e and reliable artificial intelligence systems. Prior to ETH\, he complete
 d his B.Sc. and M.Sc. at Carnegie-Mellon University supervised by Frank Pf
 enning.\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/cs-talk-matthew-mir
 man
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-matthew-mirman
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Dr. Tesca Fitzgerald
DTSTART;VALUE=DATE-TIME:20220314T200000
DTEND;VALUE=DATE-TIME:20220314T210000
DESCRIPTION:Event description:\nCS Talk\nDr. Tesca Fitzgerald\n\nHost: Bri
 an Scassellati\n\nTitle: Learning to address novel situations through huma
 n-robot collaboration\n\nAbstract\n\nAs our expectations for robots’ ada
 ptive capacities grow\, it will be increasingly important for\nthem to rea
 son about the novel objects\, tasks\, and interactions inherent to everyda
 y life. Rather\nthan attempt to pre-train a robot for all potential task v
 ariations it may encounter\, we can\ndevelop more capable and robust robot
 s by assuming they will inevitably encounter situations\nthat they are ini
 tially unprepared to address. My work enables a robot to address these nov
 el\nsituations by learning from a human teacher’s domain knowledge of th
 e task\, such as the\ncontextual use of an object or tool. Meeting this ch
 allenge requires robots to be flexible not only\nto novelty\, but to diffe
 rent forms of novelty and their varying effects on the robot’s task\ncom
 pletion. In this talk\, I will focus on (1) the implications of novelty\, 
 and its various causes\, on\nthe robot’s learning goals\, (2) methods fo
 r structuring its interaction with the human teacher in\norder to meet tho
 se learning goals\, and (3) modeling and learning from interaction-derived
 \ntraining data to address novelty.\n\nBio\n\nDr. Tesca Fitzgerald\nis a P
 ostdoctoral Fellow in the Robotics Institute at Carnegie Mellon\nUniversit
 y. Her research is centered around interactive robot learning\, with the a
 im of developing\nrobots that are adaptive\, robust\, and collaborative wh
 en faced with novel situations. Before\njoining Carnegie Mellon\, Dr. Fitz
 gerald received her PhD in Computer Science at Georgia Tech\nand completed
  her B.Sc at Portland State University. She is an NSF Graduate Research Fe
 llow\n(2014)\, Microsoft Graduate Women Scholar (2014)\, and IBM Ph.D. Fel
 low (2017).\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/cs-talk-dr-tesc
 a-fitzgerald
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-dr-tesca-fitzgerald
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Yue Wang
DTSTART;VALUE=DATE-TIME:20220315T200000
DTEND;VALUE=DATE-TIME:20220315T210000
DESCRIPTION:Event description:\nCS Talk\nYue Wang\n\nHost: Steven Zucker\n
 \nTitle: Learning 3D representations with minimal supervision\n\nAbstract:
 \n\nDeep learning has demonstrated considerable success embedding images a
 nd more general 2D representations into compact feature spaces for downstr
 eam tasks like recognition\, registration\, and generation. Learning on 3D
  data\, however\, is the missing piece needed for embodied agents to perce
 ive their surrounding environments. To bridge the gap between 3D perceptio
 n and robotic intelligence\, my present efforts focus on learning 3D repre
 sentations with minimal supervision.\n\nIn this talk\, I will discuss two 
 key aspects to reduce the amount of human supervision in current 3D deep l
 earning algorithms. First\, I will talk about how to recover structures fr
 om 3D data such as point clouds and incorporate such inductive bias into p
 oint cloud learning pipelines. Second\, I will present our works on levera
 ging natural supervision in point clouds to perform self-supervised learni
 ng. In addition\, I will discuss how these 3D learning algorithms enable h
 uman-level perception for robotic applications such as self-driving cars.
   Finally\, the talk will conclude with a discussion about future inquiri
 es to design complete and active 3D learning systems.\n\nBio:\n\nYue Wang 
 is a final year PhD student with Prof. Justin Solomon at MIT. His research
  interests lie in the intersection of computer vision\, computer graphics\
 , and machine learning. His major field is learning from point clouds. His
  paper “Dynamic Graph CNN” has been widely adopted in 3D visual comput
 ing and other fields. He is a recipient of the Nvidia Fellowship and is na
 med the first place recipient of the William A. Martin Master’s Thesis A
 ward for 2021. Yue received his BEng from Zhejiang University and MS from 
 University of California\, San Diego. He has spent time at Nvidia Research
 \, Google Research and Salesforce Research.\n\nTalk flyer\n\n\nhttps://cps
 c.yale.edu/event/cs-talk-yue-wang
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-yue-wang
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Alane Suhr
DTSTART;VALUE=DATE-TIME:20220317T143000
DTEND;VALUE=DATE-TIME:20220317T153000
DESCRIPTION:Event description:\nCS Talk\nAlane Suhr\n\nHost: Holly Rushmei
 er\n\nTitle: Reasoning and Learning in Interactive Natural Language System
 s\n\nAbstract\n\nSystems that support expressive\, situated natural langua
 ge interactions are essential for expanding access to complex computing sy
 stems\, such as robots and databases\, to non-experts. Reasoning and learn
 ing in such natural language interactions is a challenging open problem. F
 or example\, resolving sentence meaning requires reasoning not only about 
 word meaning\, but also about the interaction context\, including the hist
 ory of the interaction and the situated environment. In addition\, the seq
 uential dynamics that arise between user and system in and across interact
 ions make learning from static data\, i.e.\, supervised data\, both challe
 nging and ineffective. However\, these same interaction dynamics result in
  ample opportunities for learning from implicit and explicit feedback that
  arises naturally in the interaction. This lays the foundation for systems
  that continually learn\, improve\, and adapt their language use through i
 nteraction\, without additional annotation effort. In this talk\, I will f
 ocus on these challenges and opportunities. First\, I will describe our wo
 rk on modeling dependencies between language meaning and interaction conte
 xt when mapping natural language in interaction to executable code. In the
  second part of the talk\, I will describe our work on language understand
 ing and generation in collaborative environments\, focusing on learning to
  recover from errors and on continual learning from explicit and implicit 
 user feedback.\n\nBio\n\nAlane Suhr is a PhD Candidate in the Department o
 f Computer Science at Cornell University\,  advised by Yoav Artzi. Her re
 search spans natural language processing\, machine learning\, and computer
  vision\, with a focus on building systems that participate and continuall
 y learn in situated natural language interactions with human users. Alane
 ’s work has been recognized by paper awards at ACL and NAACL\, and has b
 een supported by fellowships and grants\, including an NSF Graduate Resear
 ch Fellowship\, a Facebook PhD Fellowship\, and research awards from AI2\,
  ParlAI\, and AWS. Alane has also co-organized multiple workshops and tuto
 rials appearing at NeurIPS\, EMNLP\, NAACL\, and ACL. Previously\, Alane r
 eceived a BS in Computer Science and Engineering as an Eminence Fellow at 
 the Ohio State University.\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/
 cs-talk-alane-suhr
LOCATION:TBA
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-alane-suhr
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Irene Chen
DTSTART;VALUE=DATE-TIME:20220330T200000
DTEND;VALUE=DATE-TIME:20220330T210000
DESCRIPTION:Event description:\nCS Talk\nIrene Chen\n\nHost: Steven Zucker
 \n\nTitle: Machine learning for equitable healthcare\n\nAbstract:\n\nAdvan
 ces in machine learning and the explosion of clinical data have demonstrat
 ed immense potential to fundamentally improve clinical care and deepen our
  understanding of human health. However\, algorithms for medical intervent
 ions and scientific discovery in heterogeneous patient populations are par
 ticularly challenged by the complexities of healthcare data. Not only are 
 clinical data noisy\, missing\, and irregularly sampled\, but questions of
  equity and fairness also raise grave concerns and create additional compu
 tational challenges.\n\nIn this talk\, I present two approaches for levera
 ging machine learning towards equitable healthcare. First\, I demonstrate 
 how to adapt disease progression modeling to account for differences in ac
 cess to care. Using a deep generative model\, we can correct for patient m
 isalignment in disease onset time to learn more clinically useful disease 
 subtypes. Second\, I examine how to address algorithmic bias in supervised
  learning for cost-based metrics discimination. By decomposing discriminat
 ion into bias\, variance\, and noise components\, I propose tailored actio
 ns for estimating and reducing each term of the total dscimination. The ta
 lk concludes with a discussion about how to rethink the entire machine lea
 rning pipeline with an ethical lens to building algorithms that serve the 
 entire patient population.\n\nBio:\n\nIrene Chen is a PhD student in the C
 linical Machine Learning group at MIT’s Computer Science and Artificial 
 Intelligence Lab (CSAIL)\, advised by David Sontag. Her work centers on ma
 chine learning methods for improving clinical care and making it more equi
 table\, as well as auditing and addressing bias in algorithmic models. Her
  work has been published in machine learning conferences (NeurIPS\, AAAI) 
 and medical journals (Nature Medicine\, Lancet Digital Health)\, and has b
 een covered by media outlets including MIT Tech Review\, NPR/WGBH\, and St
 at News. She has been named a Rising Star in EECS by University of Califor
 nia Berkeley\, Harvard\, and University of Maryland. Prior to her PhD\, Ir
 ene received her AB/SM from Harvard and worked at Dropbox.\n\nTalk flyer\n
 \n\nhttps://cpsc.yale.edu/event/cs-talk-irene-chen
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-irene-chen
END:VEVENT
END:VCALENDAR
