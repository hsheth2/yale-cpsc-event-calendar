BEGIN:VCALENDAR
X-WR-CALDESC:Yale Department of Computer Science
X-WR-CALNAME:Yale CS Events
BEGIN:VEVENT
SUMMARY:CS Colloquium - Siddharth Srivastava\, Arizona State University
DTSTART:20221114T210000
DTEND:20221114T220000
DESCRIPTION:Event description:\n\n\nCS Colloquium\nSiddharth Srivastava\, 
 Arizona State University\n\nHost: Tesca Fitzgerald\n\nTitle: From Sample-E
 fficiency to User-Driven AI Assessment:\nLearning Generalizable Knowledge 
 for Reliable Sequential Decision Making\n\nAbstract:\n\nI will present rec
 ent advances on learning for a range of sequential decision-making problem
 s\, from generalizable planning and learning for long-horizon tasks in det
 erministic and stochastic environments to enabling end-users to assess the
  limits and capabilities of their AI systems\, even as these systems adapt
  and learn. In the first part of the talk I will focus on neuro-symbolic a
 bstractions for robot planning and our recent work on learning such abstr
 actions from scratch. These methods facilitate generalizable learning that
  can be transferred to much larger problems and they outperform existing a
 pproaches on tasks that were not seen during training. In the second part 
 of the talk\, I will discuss research challenges and solution approaches f
 or a new\, emerging problem: while we expect AI systems to continually ada
 pt and learn\, the problem of enabling end-users to safely determine the l
 imits and capabilities of their changing AI systems remains largely unaddr
 essed. I will conclude with some of our recent results on user-driven asse
 ssment of adaptive black-box AI systems.\n\nBio:\n\nSiddharth Srivastava i
 s an Assistant Professor of Computer Science in the School of Computing an
 d Augmented Intelligence at Arizona State University. Before joining ASU\,
  Siddharth was a Staff Scientist at the United Technologies Research Cente
 r in Berkeley. Prior to that\, he was a postdoctoral researcher in the RUG
 S group at the University of California Berkeley. Siddharth received his P
 hD in Computer Science from the University of Massachusetts Amherst. His r
 esearch interests include robotics and AI\, with a focus on reasoning\, pl
 anning\, and acting under uncertainty. He is a recipient of the NSF CAREER
  award\, a Best Paper award at the International Conference on Automated P
 lanning and Scheduling (ICAPS) and an Outstanding Dissertation award from 
 the Department of Computer Science at UMass Amherst. He served as conferen
 ce chair for ICAPS 2019 and currently serves as an Associate Editor for th
 e Journal of AI Research.\n\n\n\n\nhttps://cpsc.yale.edu/event/cs-colloqui
 um-siddharth-srivastava-arizona-state-university
LOCATION:TBA
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-siddharth-srivastava-arizona
 -state-university
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Tushar Krishna\, Georgia Tech
DTSTART:20221115T210000
DTEND:20221115T220000
DESCRIPTION:Event description:\nCS Colloquium\nTushar Krishna\, Georgia Te
 ch\n\nHost: Abhishek Bhattacharjee\n\nTitle: Communication-centric System
  Architectures for AI Acceleration\n\nAbstract:\n\nAI has become pervasive
  in our lives today. Given the heavy computational demands for AI\, there 
 has been a sustained investment from industry\, academia and government pr
 ograms in creating specialized compute acceleration systems for running AI
  efficiently across edge\, HPC and datacenters. There are several open cha
 llenges and emerging opportunities in designing efficient AI systems. On t
 he workload end\, emerging AI models are increasingly complex with diverse
  shapes and sparsity-levels\, driven in part by techniques like neural arc
 hitecture search\, and are increasingly memory-bound. The size of AI model
 s has also been exponentially increasing\, especially for domains like lan
 guage translation and recommendations. These trends necessitate careful pa
 rtitioning of AI models and/or datasets across multiple AI accelerators\, 
 and stage data accesses through the memory hierarchy on to the compute uni
 ts. Unfortunately\, the resultant data movement is a key bottleneck in AI 
 systems today - showing up as energy and performance overheads. On the tec
 hnology end\, recent trends such as chiplets\, wafer-scale architectures\,
  CXL-based memory-pools\, all open up several novel avenues for system opt
 imization. The resultant design-spaces\, especially for HW-SW co-design\, 
 are extremely large\, necessitating sample-efficient search techniques to 
 find optimized design-points.\n\nIn my talk\, I will present my vision to 
 address the aforementioned challenges via a systematic “communication-ce
 ntric” approach to AI system design\, where we proposed configurable com
 munication fabric(s) within the system and co-optimize it along with the r
 est of the HW-SW stack. We have demonstrated several instances of this app
 roach to tackle diverse AI workloads and scales (on-chip\, on-package\, on
 -wafer\, on-rack) across both inference and training. I will also briefly 
 present some open-source simulation infrastructures we developed and relea
 sed to enable this research\, that are now being actively used by academia
 \, industry and national labs.\n\nBio:\n\nTushar Krishna is an Associate P
 rofessor in the School of Electrical and Computer Engineering at Georgia T
 ech. He also serves as an Associate Director for the Center for Research i
 nto Novel Computing Hierarchies (CRNCH). He held the ON Semiconductor (End
 owed) Junior Professorship from 2019-2021. He has a Ph.D. in Electrical En
 gineering and Computer Science from MIT (2014)\, a M.S.E in Electrical Eng
 ineering from Princeton University (2009)\, and a B.Tech in Electrical Eng
 ineering from the Indian Institute of Technology (IIT) Delhi (2007). Befor
 e joining Georgia Tech in 2015\, Dr. Krishna spent a year as a researcher 
 at the VSSAD group at Intel\, Massachusetts.\n\nDr. Krishna’s research s
 pans computer architecture\, interconnection networks\, networks-on-chip (
 NoC)\, and deep learning accelerators – with a focus on optimizing data 
 movement in modern computing systems. His research is funded via multiple 
 awards from NSF\, DARPA\, IARPA\, Department of Energy\, Intel\, Google\, 
 Facebook\, Qualcomm\, TSMC and SRC. His papers have been cited over 11\,00
 0 times. Three of his papers have been selected for IEEE Micro’s Top Pic
 ks from Computer Architecture\, one more received an honorable mention\, a
 nd four have won best paper awards. He was inducted into the HPCA Hall of 
 Fame in 2022. He received the “Class of 1940 Course Survey Teaching Effe
 ctiveness” Award from Georgia Tech in 2018 and the “Roger P. Webb Outs
 tanding Junior Faculty Award” from the School of ECE in Georgia Tech in 
 2021.\n\n\nhttps://cpsc.yale.edu/event/cs-colloquium-tushar-krishna-georgi
 a-tech
LOCATION:AKW 200
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-tushar-krishna-georgia-tech
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS/YQI Colloquium - Hsin Yuan (Robert) Huang\, Caltech
DTSTART:20221118T170000
DTEND:20221118T180000
DESCRIPTION:Event description:\nCS/YQI Colloquium\nHsin Yuan (Robert) Huan
 g\, Caltech\n\nTitle:\nLearning in the quantum universe\n\nAbstract:\n\nI 
 will present recent progress in building a mathematical theory for underst
 anding how scientists\, machines\, and future quantum computers could lea
 rn models of our inherently quantum universe. The talk will review an exp
 erimentally feasible procedure for learning a succinct classical represent
 ation\, the classical shadow\, of a quantum state. Classical shadows can 
 be applied to predict efficiently many properties of interest\, including
  expectation values of few-body observables and subsystem entanglement en
 tropy. The theoretical insights obtained from classical shadow tomography
  enable us to rigorously answer two fundamental questions at the intersect
 ion of machine learning and quantum physics: Can classical machines learn
  to solve challenging problems in quantum physics? Can quantum machines l
 earn exponentially faster than classical machines?\n\nLunch will be provid
 ed.\n\n\nhttps://cpsc.yale.edu/event/csyqi-colloquium-hsin-yuan-robert-hua
 ng-caltech
LOCATION:YQI Seminar Room and Zoom
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/csyqi-colloquium-hsin-yuan-robert-huang-ca
 ltech
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Ning Luo
DTSTART:20221201T180000
DTEND:20221201T190000
DESCRIPTION:Event description:\nDissertation Defense\nNing Luo\n\nTime is 
 tentative\n\nTitle: Privacy-preserving formal methods\n\nAdvisor: Ruzica P
 iskac\n\nOther Committee Members:\n\nTimos Antonopoulos\nClark Barrett (St
 anford University)\nDan Boneh (Stanford University)\nZhong Shao\n\nAbstrac
 t:\n\nSoftware and hardware can often exhibit undesirable behaviors\, whic
 h can lead to catastrophic consequences. Formal methods offer a vast colle
 ction of techniques to analyze and verify these systems mathematically to 
 ensure the correctness\, robustness\, and safety of software and hardware 
 systems against a specification.\n\nDespite the significant success of for
 mal method techniques\, privacy requirements are not being considered in t
 heir design. On the other hand\, formal methods are often used to verify t
 he critical components of systems\, which is frequently valuable intellect
 ual property. Furthermore\, the specification requirements are often impos
 ed by outside parties in some settings\, such as regulatory agencies or so
 ftware marketplaces\, entities that are not always trusted by the system o
 wners.\n\nMy study of designing efficient formal methods that retain a pro
 gram’s privacy is guided by these proprietary concerns. In this disserta
 tion\, I introduce a suite of privacy-preserving formal method techniques 
 I have designed:\n\n\nPrivacy-preserving SAT solving. The SAT problem is f
 inding an assignment of variables to make a Boolean formula evaluate to tr
 ue. As one of the most fundamental problems\, it is the core of many verif
 ication techniques with SMT solvers often being crucial components. This d
 issertation describes ppSAT: a privacy-preserving SAT solver that enables 
 two parties to decide whether the conjunction of their secret formulae is 
 satisfiable or not while maintaining the privacy of each party’s input f
 ormulae.\n\nRefutation proofs in zero knowledge.  Proving that a given Bo
 olean formula is unsatisfiable is critical in formal methods for illustrat
 ing the safety or robustness of a system\, and the existing state-of-the-a
 rt techniques utilize resolution proofs. This dissertation presents a zero
 -knowledge protocol for proving the unsatisfiability of Boolean formulae i
 n propositional logic. We encode the verification of a resolution proof us
 ing polynomial equivalence checking\, which enabled us to use a fast ZK pr
 otocol for verifying relations between polynomials.\n\nPrivacy-preserving 
 model checking for CTL formulae. Model checking is the problem of verifyin
 g whether an abstract model of a computational system meets a specificatio
 n of behavior given as a logic formula. This dissertation explains how to 
 apply secure multiparty computation (MPC) to model-checking algorithms to 
 maintain the privacy of both the model and the specification. Our approach
  adopts oblivious graph algorithms to allow for secure computation of glob
 al explicit state model checking with specifications written in Computatio
 n Tree Logic (CTL).\n\nPrivate regular expression pattern matching based o
 n NFA. Regular expression pattern matching is one of the fundamental query
  operations in computer science and formal languages. Many applications\, 
 such as network intrusion detection and policy checking for DNS queries\, 
 depend on such queries which are also increasingly concerned with privacy 
 issues. This dissertation demonstrates a private regular expression patter
 n-matching design based on the oblivious stack and transfer protocols. The
  former results in the best-known asymptotic complexity for regular expres
 sion pattern matching\, while the latter leads to optimal numerical perfor
 mance.\n\n\n\nhttps://cpsc.yale.edu/event/dissertation-defense-ning-luo
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-ning-luo
END:VEVENT
END:VCALENDAR
