BEGIN:VCALENDAR
X-WR-CALDESC:Yale Department of Computer Science
X-WR-CALNAME:Yale CS Events
BEGIN:VEVENT
SUMMARY:CS Talk - Lydia T. Liu
DTSTART:20230309T153000
DTEND:20230309T163000
DESCRIPTION:Event description:\nCS Talk\nLydia T. Liu\n\nHost: Andre Wibis
 ono\n\nTitle: Towards Responsible Machine Learning in Societal Systems\n\
 nAbstract:\n\nMachine learning systems are deployed in consequential domai
 ns such as education\, employment\, and credit\, where decisions have prof
 ound effects on socioeconomic opportunity and life outcomes. High stakes d
 ecision settings present new statistical\, algorithmic\, and ethical chall
 enges. In this talk\, we examine the distributive impact of machine learni
 ng algorithms in societal contexts\, and investigate the algorithmic and s
 ociotechnical interventions that bring machine learning systems into align
 ment with societal values—equity and long-term welfare. First\, we study
  the dynamic interactions between machine learning algorithms and populati
 ons\, for the purpose of mitigating disparate impact in applications such 
 as algorithmic lending and hiring. Next\, we consider data-driven decision
  systems in competitive environments such as markets\, and devise learning
  algorithms to ensure efficiency and allocative fairness. We end by outlin
 ing future directions for responsible machine learning in societal systems
  that bridge the gap between the optimization of predictive models and the
  evaluation of downstream decisions and impact.\n\nBio:\n\nLydia T. Liu is
  a postdoctoral researcher in Computer Science at Cornell University\, wor
 king with Jon Kleinberg\, Karen Levy\, and Solon Barocas. Her research exa
 mines the theoretical foundations of machine learning and algorithmic deci
 sion-making\, with a focus on societal impact and human welfare. She obtai
 ned her PhD in Electrical Engineering and Computer Sciences from UC Berkel
 ey\, advised by Moritz Hardt and Michael Jordan\, and has received a Micro
 soft Ada Lovelace Fellowship\, an Open Philanthropy AI Fellowship\, an NUS
  Development Grant\, and a Best Paper Award at the International Conferenc
 e on Machine Learning.\n\n\nhttps://cpsc.yale.edu/event/cs-talk-lydia-t-li
 u
LOCATION:AKW 200
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-lydia-t-liu
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Quanquan Liu
DTSTART:20230328T143000
DTEND:20230328T153000
DESCRIPTION:Event description:\n\n\nCS Talk\nQuanquan Liu\n\nHost: Holly R
 ushmeier\n\nTitle: Scalable Graph Algorithms: Parallel\, Dynamic\, and Pri
 vate\n\nAbstract:\n\nGraph algorithms are ubiquitous in today’s world wh
 ere graph analytics are performed over massive datasets containing potenti
 ally sensitive information. Modern graphs present many new challenges not 
 considered by classic static\, sequential computation models. First\, grap
 hs have up to trillions of edges and are several orders of magnitude large
 r than what traditional sequential algorithms can handle. In addition to s
 cale\, modern graphs are also dynamically evolving with up to millions of 
 changes per second. Second\, data leaks and commercial data trading threat
 en to expose the large volume of sensitive private information contained i
 n these graphs. Third\, the monetary and resource incentives associated wi
 th large distributed graphs (e.g.\, for cryptocurrency) make them vulnerab
 le to malicious adversaries. Thus\, modern graph algorithms must achieve s
 everal simultaneous goals: efficiency\, scalability\, privacy\, and robust
 ness against adversaries.\n\nIn this talk\, I will present algorithms that
  rise to these aforementioned challenges. I will first present novel scala
 ble algorithms for k-core decomposition and related important problems in 
 computational models that take advantage of modern parallel computing arch
 itectures and dynamic environments. These algorithms not only achieve theo
 retical improvements but also hundreds of times speedups over the state-of
 -the-art in practice. Then\, I will formalize models and give algorithms t
 hat combat broader societal concerns of privacy breaches and susceptibilit
 y to adversarial attacks. Finally\, I’ll discuss my broader research vis
 ion in combining scalability with adversary-robustness.\n\nBio:\n\nQuanqua
 n C. Liu is a postdoctoral scholar at Northwestern University advised by S
 amir Khuller. She completed her PhD in Computer Science at MIT where she w
 as advised by Erik D. Demaine and Julian Shun. Before that\, she obtained 
 her dual bachelor’s degree in computer science and math also at MIT. She
  has worked on a number of problems in algorithms and the intersection bet
 ween theory and practice. Her most recent work focuses on parallel dynamic
  and static graph algorithms as well as differentially private graph algor
 ithms. She has earned the Best Paper Award at SPAA 2022\, a NSF Graduate R
 esearch Fellowship\, and participated in the 2021 EECS Rising Stars worksh
 op.\n\n\n\n\nhttps://cpsc.yale.edu/event/cs-talk-quanquan-liu
LOCATION:AKW 200
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-quanquan-liu
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Andrea Zanette
DTSTART:20230411T200000
DTEND:20230411T210000
DESCRIPTION:Event description:\nCS Talk\nAndrea Zanette\n\nHost: Yang Cai\
 n\nTitle: Towards a Statistical Foundation for Reinforcement Learning\n\n
 Abstract:\n\nIn recent years\, reinforcement learning algorithms have achi
 eved a number of headline-grabbing empirical successes on various complex 
 tasks. However\, applying the reinforcement learning paradigm to new probl
 ems remains highly challenging. In many cases\, the existing algorithms ne
 ed to be modified\, and new ones may have to be developed to solve the pro
 blem at hand. In order to do so effectively\, we must gain some understand
 ing about the foundations of reinforcement learning.\n\nIn this talk I wil
 l present some recent results of my research towards this goal. I will fir
 st present an algorithm that can exploit the domain structure to learn muc
 h faster on easier problems\, while retaining state-of-the art worst-case 
 guarantees on pathologically hard ones.  Then I will discuss a fundamenta
 l information-theoretic lower-bound\, which establishes that reinforcement
  learning can be exponentially harder than supervised learning even when s
 imple linear predictors are implemented. Finally\, I will discuss a stati
 stically optimal algorithm to learn from historical data.\n\nBio:\n\nAndr
 ea Zanette is a postdoctoral scholar in the Department of Electrical Engin
 eering and Computer Sciences at the University of California\, Berkeley\, 
 supported by a fellowship from the Foundation of Data Science Institute. 
 He completed his PhD (2017-2021) in the Institute for Computational and Ma
 thematical Engineering at Stanford University\, advised by Prof Emma Bruns
 kill and Mykel J. Kochenderfer. His PhD dissertation investigated modern 
 Reinforcement Learning challenges such as exploration\, function approxima
 tion\, adaptivity\, and learning from offline data. His work was supported
  by a Total Innovation Fellowship and his PhD thesis was awarded the Gene
  Golub Outstanding Dissertation Award from his department. Andrea’s back
 ground is in mechanical engineering. Before Stanford\, he worked as a soft
 ware developer in high-performance computing\, as well as at the von Karma
 n Institute for Fluid Dynamics\, a NATO-affiliated international research 
 establishment.\n\n\nhttps://cpsc.yale.edu/event/cs-talk-andrea-zanette
LOCATION:AKW 200
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-andrea-zanette
END:VEVENT
END:VCALENDAR
