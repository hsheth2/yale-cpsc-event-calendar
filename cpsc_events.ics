BEGIN:VCALENDAR
X-WR-CALDESC:Yale Department of Computer Science
X-WR-CALNAME:Yale CS Events
BEGIN:VEVENT
SUMMARY:CS Talk - Fardina Fathmiul Alam
DTSTART:20230202T153000
DTEND:20230202T163000
DESCRIPTION:Event description:\nCS Talk\nFardina Fathmiul Alam\n\nHost: Ho
 lly Rushmeier\n\nTitle of Teaching Demo:  ”Understanding K-Means Clust
 ering Machine Learning”\n\nAbstract:\n\n“There is a growing amount of 
 data that is being generated today. Data scientists are attempting to tur
 n large datasets from industries like business\, healthcare\, and social m
 edia into actionable insights and data-driven decisions. With the advent 
 of machine learning (ML) and artificial intelligence (AI)\, machines are g
 etting more and more advanced and their abilities are frequently pushed to
  the limit. Over the last decade\, ML has made huge progress in technolog
 y in everything from photo recognition to self-driving cars. ”Unsupervi
 sed Machine Learning” draws inferences from datasets without labels. If
  we don’t know what we’re looking for\, it’s great for finding patte
 rns. Since labeled data is difficult or expensive to gather\, many real-wo
 rld datasets are unlabeled or partially labeled\, making unsupervised lear
 ning approaches like k-means clustering valuable tools for dealing with la
 rge amounts of unlabeled data. Due to its simplicity\, efficiency\, and in
 terpretation\, K-means clustering is one of the most used unsupervised lea
 rning techniques for grouping related data points. In this lecture\, I wil
 l talk about what is k-means clustering and how it works\, which can hel
 p us to understand our data in a unique way by grouping or dividing data i
 nto groups. ”\n\nBio:\n\nFardina Fathmiul Alam is a Ph.D. candidate in 
 the Department of Computer Science at George Mason University (GMU) in Fai
 rfax\, Virginia. In addition\, She works as a Graduate Research Assistant 
 in Dr. Amarda Shehu’s Computational Biology Lab at GMU. Her research fo
 cuses on Machine Learning (ML)\, specifically the intersection of Deep Lea
 rning (DL) with bioinformatics and computational biology. She works on 
 designing novel deep neural-network-based latent variable models to organi
 ze high-dimensional\, non-linear molecular structure space (in terms of re
 presentation learning)\, and for that her application domain is Protein St
 ructure data. Fardina already has a good number of publications in her wor
 k. In 2013\, She received her undergraduate degree in Computer Science an
 d Engineering from the Military Institute of Science and Technology (MIST)
  in Dhaka\, Bangladesh. She earned her MS degree in Computer Science from 
 Mason. She worked for about four years as a Full-Time Teaching Faculty (Le
 cturer) at the International University of Business\, Agriculture\, and Te
 chnology (IUBAT) in Dhaka\, Bangladesh\, before joining Mason. She also
  spent about 3 years at Mason as a Graduate Teaching Assistant for variou
 s graduate and undergraduate courses. Fardina intends to complete my Ph.
 D. by the end of the Spring of 2023.”\n\n\nhttps://cpsc.yale.edu/event/c
 s-talk-fardina-fathmiul-alam
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-fardina-fathmiul-alam
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Frederic Koehler
DTSTART:20230202T210000
DTEND:20230202T220000
DESCRIPTION:Event description:\nCS Talk\nFrederic Koehler\n\nHost: Andre W
 ibisono\n\nTitle: Towards the Statistically Principled Design of ML Algori
 thms\n\nAbstract:\n\nWhat are the optimal algorithms for learning from dat
 a? Have we found them already\, or are better ones out there to be discove
 red? Making these questions precise\, and answering them\, requires taking
  on the mathematically deep interplay between statistical and computationa
 l constraints.  It also requires reconciling our theoretical toolbox with
  surprising new phenomena arising from practice\, which seem to violate co
 nventional rules of thumb regarding algorithm and model design. I will dis
 cuss progress along these lines: in terms of designing new algorithms for 
 basic learning problems\, controlling generalization in large statistical 
 models\, and understanding key statistical questions for generative modeli
 ng.\n\nBio:\n\nFrederic is currently a Motwani Postdoctoral Fellow in the
  Department of Computer Science at Stanford University.  He was previous
 ly a research fellow at the Simons Institute\, and before that received
  his PHD in\nMathematics and Statistics.\n\n\nhttps://cpsc.yale.edu/event/
 cs-talk-frederic-koehler
LOCATION:AKW 200
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-frederic-koehler
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Vikram V. Ramaswamy
DTSTART:20230203T153000
DTEND:20230203T163000
DESCRIPTION:Event description:\nCS Talk\nVikram V. Ramaswamy\n\nHost: Holl
 y Rushmeier\n\nTitle: Measuring machine learning models for fairness\n\nAb
 stract:\n\nCurrent machine learning models are now incredibly powerful and
  can be used for tasks that make important decisions about people. In this
  lecture\, we’ll discuss three different metrics to evaluate these model
 s for fairness: demographic parity\, equalized odds and parity of predicti
 ve values\, and show that they are very often incompatible with each other
 . We’ll reason about what normative standards each of these metrics set\
 , and finally\, see how they interact with the larger space of machine lea
 rning fairness.\n\nBio:\n\nVikram V. Ramaswamy is a PhD candidate at Princ
 eton University\, working with Olga Russakovsky. He is interested in fairn
 ess and interpretability in machine learning\, and how it applies to visua
 l systems. In addition to his research and teaching\, he is passionate abo
 ut increasing diversity in higher education and has participated in numero
 us programs for the same\, including the Princeton Freshman Scholars Initi
 ative\, a program for first gen / low-income students\, and Princeton AI4A
 ll\, a program for high school students aimed at increasing diversity in A
 I.\n\n\nhttps://cpsc.yale.edu/event/cs-talk-vikram-v-ramaswamy
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-vikram-v-ramaswamy
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Sebastian Caldas
DTSTART:20230209T153000
DTEND:20230209T163000
DESCRIPTION:Event description:\nCS Talk\nSebastian Caldas\n\nHost: Holly R
 ushmeier\n\nTitle\n:\nIntroduction to Linear Regression\n\nAbstract\n:\n\n
 In this lecture\, we will introduce linear regression: motivating its use 
 and covering a variety of techniques to learn its optimal parameters from 
 training data. The focus will be on developing the intuitions behind the d
 ifferent optimization algorithms\, and their advantages and disadvantages.
  We will end the lecture by briefly discussing the general trend of optimi
 zation in machine learning.\n\nBio:\n\nSebastian Caldas is a Ph.D. candida
 te in the Machine Learning Department at Carnegie Mellon University\, wher
 e he is advised by Artur Dubrawski. His research focuses on building intel
 ligent systems that are collaborative\, useful and practical. Currently\, 
 he is focused on federated scenarios\, particularly healthcare domains.\n\
 n\nhttps://cpsc.yale.edu/event/cs-talk-sebastian-caldas
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-sebastian-caldas
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Omar Montasser
DTSTART:20230209T210000
DTEND:20230209T220000
DESCRIPTION:Event description:\nCS Talk\nOmar Montasser\n\nHost: Andre Wib
 isono\n\nTitle: What\, When\, and How can we Learn Adversarially Robustly?
 \n\nAbstract:\n\nDespite extraordinary progress\, current machine learning
  systems have been shown to be brittle against adversarial examples: seemi
 ngly innocuous but carefully crafted perturbations of test examples that c
 ause machine learning predictors to misclassify. Can we learn predictors r
 obust to adversarial examples? and how? There has been much empirical inte
 rest in this major challenge in machine learning\, and in this talk\, we w
 ill present a theoretical perspective. We will illustrate the need to go b
 eyond traditional approaches and principles\, such as empirical (robust) r
 isk minimization\, and present new algorithmic ideas with stronger robust 
 learning guarantees.\n\nBio:\n\nOmar Montasser is a PhD candidate at TTI-C
 hicago advised by Nathan Srebro. His research broadly explores the theory 
 and foundations of machine learning. Recently\, his research has focused o
 n understanding and characterizing adversarially robust learning\, and on 
 designing learning algorithms with provable robustness guarantees under di
 fferent settings. His work has been recognized by a best student paper awa
 rd at COLT (2019).\n\n\nhttps://cpsc.yale.edu/event/cs-talk-omar-montasser
LOCATION:AKW 200
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-omar-montasser
END:VEVENT
END:VCALENDAR
