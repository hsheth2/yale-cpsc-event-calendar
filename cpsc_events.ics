BEGIN:VCALENDAR
X-WR-CALDESC:Yale Department of Computer Science
X-WR-CALNAME:Yale CS Events
BEGIN:VEVENT
SUMMARY:CS Talk - Irene Chen
DTSTART;VALUE=DATE-TIME:20220201T210000
DTEND;VALUE=DATE-TIME:20220201T220000
DESCRIPTION:Event description:\nCS Talk\nIrene Chen\n\nHost: Steven Zucker
 \n\nTitle: Machine learning for equitable healthcare\n\nAbstract:\n\nAdvan
 ces in machine learning and the explosion of clinical data have demonstrat
 ed immense potential to fundamentally improve clinical care and deepen our
  understanding of human health. However\, algorithms for medical intervent
 ions and scientific discovery in heterogeneous patient populations are par
 ticularly challenged by the complexities of healthcare data. Not only are 
 clinical data noisy\, missing\, and irregularly sampled\, but questions of
  equity and fairness also raise grave concerns and create additional compu
 tational challenges.\n\nIn this talk\, I present two approaches for levera
 ging machine learning towards equitable healthcare. First\, I demonstrate 
 how to adapt disease progression modeling to account for differences in ac
 cess to care. Using a deep generative model\, we can correct for patient m
 isalignment in disease onset time to learn more clinically useful disease 
 subtypes. Second\, I examine how to address algorithmic bias in supervised
  learning for cost-based metrics discimination. By decomposing discriminat
 ion into bias\, variance\, and noise components\, I propose tailored actio
 ns for estimating and reducing each term of the total dscimination. The ta
 lk concludes with a discussion about how to rethink the entire machine lea
 rning pipeline with an ethical lens to building algorithms that serve the 
 entire patient population.\n\nBio:\n\nIrene Chen is a PhD student in the C
 linical Machine Learning group at MIT’s Computer Science and Artificial 
 Intelligence Lab (CSAIL)\, advised by David Sontag. Her work centers on ma
 chine learning methods for improving clinical care and making it more equi
 table\, as well as auditing and addressing bias in algorithmic models. Her
  work has been published in machine learning conferences (NeurIPS\, AAAI) 
 and medical journals (Nature Medicine\, Lancet Digital Health)\, and has b
 een covered by media outlets including MIT Tech Review\, NPR/WGBH\, and St
 at News. She has been named a Rising Star in EECS by University of Califor
 nia Berkeley\, Harvard\, and University of Maryland. Prior to her PhD\, Ir
 ene received her AB/SM from Harvard and worked at Dropbox.\n\n\nhttps://cp
 sc.yale.edu/event/cs-talk-irene-chen
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-irene-chen
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Qi Lei
DTSTART;VALUE=DATE-TIME:20220203T153000
DTEND;VALUE=DATE-TIME:20220203T163000
DESCRIPTION:Event description:\nCS Talk\nQi Lei\n\nHost: Andre Wibisono\n\
 nTitle:  Theoretical Foundations of Pre-trained Models\n\nAbstract:\n\nA 
 pre-trained model refers to any model trained on broad data at scale and c
 an be adapted (e.g.\, fine-tuned) to a wide range of downstream tasks. The
  rise of pre-trained models (e.g.\, BERT\, GPT-3\, CLIP\, Codex\, MAE) tra
 nsforms applications in various domains and aligns with how humans learn. 
 Humans and animals first establish their concepts or impressions from diff
 erent data domains and data modalities. The learned concepts then help the
 m learn specific tasks with minimal external instructions. Accordingly\, w
 e argue that a pre-trained model follows a similar procedure through the l
 ens of deep representation learning. 1) Learn a data representation that f
 ilters out irrelevant information from the training tasks\; 2) Transfer th
 e data representation to downstream tasks with few labeled samples and sim
 ple models.\n\nThis talk establishes some theoretical understanding for pr
 e-trained models under different settings\, ranging from supervised pretra
 ining\, meta-learning\, and self-supervised learning to domain adaptation 
 or domain generalization. I will discuss the sufficient (and sometimes nec
 essary) conditions for pre-trained models to work based on the statistical
  relation between training and downstream tasks. The theoretical analyses 
 partly answer how they work\, when they fail\, guide technical decisions f
 or future work\, and inspire new methods in pre-trained models.\n\nBio:\n\
 nQi Lei is an associate research scholar at the ECE department of Princeto
 n University. She received her Ph.D. from Oden Institute for Computational
  Engineering & Sciences at UT Austin. She visited the Institute for Advanc
 ed Study (IAS)/Princeton for the Theoretical Machine Learning Program from
  2019-2020. Before that\, she was a research fellow at Simons Institute fo
 r the Foundations of Deep Learning Program. Her research aims to develop s
 ample- and computationally efficient machine learning algorithms and bridg
 e the theoretical and empirical gap in machine learning. Qi has received s
 everal awards\, including the Outstanding Dissertation Award\, National In
 itiative for Modeling and Simulation Graduate Research Fellowship\, Comput
 ing Innovative Fellowship\, and Simons-Berkeley Research Fellowship.\n\n\n
 https://cpsc.yale.edu/event/cs-talk-qi-lei
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-qi-lei
END:VEVENT
BEGIN:VEVENT
SUMMARY:Cs Talk - Jiaoyang Li
DTSTART;VALUE=DATE-TIME:20220208T210000
DTEND;VALUE=DATE-TIME:20220208T220000
DESCRIPTION:Event description:\nDetails coming soon.\n\nHost: Brian Scasse
 llati\n\n\nhttps://cpsc.yale.edu/event/cs-talk-jiaoyang-li
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-jiaoyang-li
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Maria Brbic
DTSTART;VALUE=DATE-TIME:20220214T210000
DTEND;VALUE=DATE-TIME:20220214T220000
DESCRIPTION:Event description:\nCS Talk\nMaria Brbic\n\nHost: Steven Zucke
 r\n\nTitle: Open-World Learning for Biomedicine\n\nAbstract:\n\nBiomedical
  data poses multiple hard challenges that break conventional machine learn
 ing assumptions. In this talk\, I will highlight the need to move beyond o
 ur prevalent machine learning paradigms and methods to enable them to driv
 e novel biomedical discoveries. I will give an overview of my work on deve
 loping open-world deep learning methods that generalize to scenarios never
  seen during training and demonstrate their impact in single-cell genomics
 . I will first present a method that transfers knowledge across a collecti
 on of heterogeneous datasets generated under different distributions\, and
  then describe the paradigm and methods needed to discover novel phenomena
 . I will discuss the biological findings enabled by my methods and the con
 ceptual shift they bring in annotating comprehensive single-cell atlas dat
 asets. Altogether\, my work demonstrates that generalization to never-befo
 re-seen scenarios is not only possible\, but it is a necessary component i
 n developing next-generation machine learning methods that can reveal new 
 scientific insights.\n\nBio:\n\nMaria Brbic\nis a postdoctoral researcher 
 in Computer Science at Stanford University. She develops new machine learn
 ing methods inspired by challenging problems in biomedicine and applies he
 r methods to advance biomedical research. Her methods have been used by gl
 obal cell atlas consortia efforts aiming to create reference maps of all c
 ell types\, including the Human BioMolecular Atlas Program (HuBMAP) and Fl
 y Cell Atlas consortium. Previously\, she received her PhD degree from Uni
 versity of Zagreb while also researching at Stanford University and Univer
 sity of Tokyo. Her research was awarded with the Fulbright Scholarship\, L
 ’Oreal UNESCO for Women in Science Scholarship\, Branimir Jernej award f
 or outstanding publication in biology and biomedicine\, and Josip Loncar S
 ilver Plaque award for the best doctoral dissertation. She has been named 
 a Rising Star in EECS by MIT. She is a member of the Chan Zuckerberg Biohu
 b at Stanford.\n\n\nhttps://cpsc.yale.edu/event/cs-talk-maria-brbic
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-maria-brbic
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Osbert Bastani
DTSTART;VALUE=DATE-TIME:20220215T210000
DTEND;VALUE=DATE-TIME:20220215T220000
DESCRIPTION:Event description:\nCS Talk\nOsbert Bastani\n\nHost: Abhishek 
 Bhattacharjee\n\nTitle: Trustworthy Machine Learning Systems via PAC Uncer
 tainty Quantification\n\nAbstract:\n\nMachine learning models are increasi
 ngly being incorporated into real-world systems\, targeting domains such a
 s robotics\, healthcare\, and software systems. A key challenge is ensurin
 g that such systems are trustworthy. I will describe a novel strategy for 
 composing machine learning models while providing provable correctness gua
 rantees. First\, we show how to quantify the uncertainty of any given mode
 l in a way that satisfies PAC correctness guarantees. Second\, we show how
  to compose guarantees for individual models to obtain a guarantee for the
  overall system. Then\, I will discuss applications to ensuring safety in 
 reinforcement learning from visual inputs\, and to speeding up inference t
 ime of deep neural networks. I will conclude with ongoing work on preservi
 ng correctness guarantees in the face of distribution shift.\n\nBio:\n\nOs
 bert Bastani is a research assistant professor at the Department of Comput
 er and Information Science at the University of Pennsylvania. He is broadl
 y interested in techniques for designing trustworthy machine learning syst
 ems\, focusing on their correctness\, programmability\, and efficiency. Pr
 eviously\, he completed his Ph.D. in computer science from Stanford and hi
 s A.B. in mathematics from Harvard.\n\n\nhttps://cpsc.yale.edu/event/cs-ta
 lk-osbert-bastani
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-osbert-bastani
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Irene Li
DTSTART;VALUE=DATE-TIME:20220216T170000
DTEND;VALUE=DATE-TIME:20220216T180000
DESCRIPTION:Event description:\nDissertation Defense\nIrene Li\n\nTitle: N
 eural Graph Transfer Learning in Natural Language Processing Tasks\n\nAdvi
 sor: Dragomir Radev\n\nOther committee members:\nMarynel Vázquez\nYang Ca
 i\nElisa Celis\n\nAbstract:\n\nNatural language is essential in our daily 
 lives as we rely on languages to communicate and exchange information. A f
 undamental goal for natural language processing (NLP) is to let the machin
 e understand natural language to help or replace human experts to mine kno
 wledge and complete tasks.\n\nMany NLP tasks deal with sequential data. Fo
 r example\, a sentence is considered as a sequence of works. However\, not
  all tasks can be formulated using sequence models. Specifically\, graph-s
 tructured data is also fundamental in NLP\, including entity linking\, ent
 ity classification\, relation extraction\, abstractive meaning representat
 ion\, and knowledge graphs. In this scenario\,  BERT-based pretrained mod
 els may not be suitable. Graph Convolutional Neural Network (GCN) is a dee
 p neural network model designed for graphs. It has shown great potential i
 n text classification\, link prediction\, question answering and so on.\n\
 nThis dissertation presents novel graph models for NLP tasks\, including t
 ext classification\, prerequisite chain learning\, and coreference resolut
 ion. We focus on different perspectives of graph convolutional network mod
 eling: for text classification\, a novel graph construction method is prop
 osed which allows interpretability for the prediction\; for prerequisite c
 hain learning\, we propose multiple aggregation functions that utilize nei
 ghbors for better information exchange\; for coreference resolution\, we s
 tudy how graph pretraining can help when labeled data is limited. Moreover
 \, an important branch is to apply pretrained language models for the ment
 ioned tasks. So\, this dissertation also focuses on the transfer learning 
 method that generalizes pretrained models to other domains\, including med
 ical\, cross-lingual\, and web data. Finally\, we propose a new task calle
 d unsupervised cross-domain prerequisite chain learning\, and study novel 
 graph-based methods to transfer knowledge over graphs.\n\n\nhttps://cpsc.y
 ale.edu/event/dissertation-defense-irene-li
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-irene-li
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Erik Waingarten
DTSTART;VALUE=DATE-TIME:20220216T210000
DTEND;VALUE=DATE-TIME:20220216T220000
DESCRIPTION:Event description:\nDetails coming soon.\n\nHost: Richard Yang
 \n\n\nhttps://cpsc.yale.edu/event/cs-talk-erik-waingarten
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-erik-waingarten
END:VEVENT
END:VCALENDAR
