BEGIN:VCALENDAR
X-WR-CALDESC:Yale Department of Computer Science
X-WR-CALNAME:Yale CS Events
BEGIN:VEVENT
SUMMARY:CS Distinguished Colloquium - James E. Smith\, University of Wisco
 nsin-Madison (Emeritus)
DTSTART;VALUE=DATE-TIME:20210212T150000
DTEND;VALUE=DATE-TIME:20210212T160000
DESCRIPTION:Event description:\nCS Distinguished Colloquium\n\nJames E. Sm
 ith\nUniversity of Wisconsin-Madison (Emeritus)\n\nTitle: A Temporal Neura
 l Network Architecture for Online Learning\n\nZoom link: Join from PC\, M
 ac\, Linux\, iOS or Android:\nhttps://yale.zoom.us/j/98080001575\nOr Telep
 hone：203-432-9666 (2-ZOOM if on-campus) or 646 568 7788\nMeeting ID: 980
  8000 1575\nInternational numbers available:\nhttps://yale.zoom.us/u/acO3V
 IdKco\n\nHost: Abhishek Bhattacharjee\n\nAbstract:\n\nA long-standing prop
 osition is that by emulating the operation of the brain’s neocortex\, a 
 spiking neural network (SNN) can achieve similar desirable features: flexi
 ble learning\, speed\, and efficiency.  Temporal neural networks (TNNs) a
 re SNNs that communicate and process information encoded as relative spike
  times (in contrast to spike rates).  A TNN architecture is proposed\, an
 d as a proof-of-concept\, TNN operation is demonstrated within the larger 
 context of online supervised classification.  First\, through unsupervise
 d learning\, a TNN partitions input patterns into clusters based on simila
 rity.  The TNN learning process adjusts synaptic weights by using only si
 gnals local to each synapse\, and global clustering behavior emerges. The 
 TNN then passes a cluster identifier to a simple online supervised decoder
  which finishes the classification task. Besides features of the overall a
 rchitecture\, several TNN components and methods are new to this work.  A
  long term research objective is a direct hardware implementation.  Conse
 quently\, the architecture is described at a level analogous to the gate a
 nd register transfer levels used in conventional digital design\, and proc
 essing is done at very low precision.\n\nBio:\n\nJames E. Smith is Profess
 or Emeritus in the Department of Electrical and Computer Engineering at th
 e University of Wisconsin-Madison. He received his PhD from the University
  of Illinois in 1976. He then joined the faculty of the University of Wisc
 onsin-Madison\, teaching and conducting research  ̶  first in fault-tol
 erant computing\, then in computer architecture.  He has been involved in
  a number of computer research and development projects both as a faculty 
 member at Wisconsin and in industry.\n\nProf. Smith made a number of contr
 ibutions to the development of superscalar processors. These contributions
  include basic mechanisms for dynamic branch prediction and implementing p
 recise traps.  He has also studied vector processor architectures and wor
 ked on the development of innovative microarchitecture paradigms. He recei
 ved the 1999 ACM/IEEE Eckert-Mauchly Award for these contributions.\n\nFor
  the past several years\, he has been studying neuron-based computing para
 digms at home along the Clark Fork near Missoula\, Montana.\n\n\nhttps://c
 psc.yale.edu/event/cs-distinguished-colloquium-james-e-smith-university-wi
 sconsin-madison-emeritus
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-distinguished-colloquium-james-e-smith-
 university-wisconsin-madison-emeritus
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Jonathan K. Kummerfeld
DTSTART;VALUE=DATE-TIME:20210215T210000
DTEND;VALUE=DATE-TIME:20210215T220000
DESCRIPTION:Event description:\nCS Colloquium\nJonathan K. Kummerfeld\n\nT
 itle: You Are What You Train On:  Creating Robust Natural Language Inte
 rfaces\n\nZoom Presentation*\n\nHost: Dragomir Radev\n\nAbstract:\n\nNatur
 al Language Interfaces like Siri and Alexa help people do things more effi
 ciently\, but they are brittle\, unable to handle the full range of ways p
 eople naturally express themselves. Each of their actions is manually defi
 ned by developers\, with limited ability to compose actions to make more s
 ophisticated ones. The choice of action is made by a statistical model tha
 t is limited by the range of data seen in training. Despite steady progres
 s in the accuracy of these systems\, the true scope of remaining challenge
 s has been obscured by the way researchers collect and prepare data.\n\nIn
  this talk\, I will describe two of my projects that have revealed previou
 sly unknown limitations of natural language interfaces and ways to address
  them. First\, I will show that systems for converting questions to SQL qu
 eries have limited generalizability beyond examples seen in training (ACL 
 2018). I propose a new model and a new way to split data into training and
  test sets that explore this challenge. Second\, I will show that standard
  crowd-worker data collection processes miss the long and heavy tail of wa
 ys people speak (ACL 2017). I propose an outlier-based data collection wor
 kflow (NAACL 2019)\, and a complementary taboo list workflow (EMNLP 2020)\
 , that improve data diversity and reduce the cost of data cleaning. I will
  conclude by outlining a research agenda for fundamentally changing the ca
 pabilities of these systems. Today we use these systems to do simple tasks
 \, e.g. “start a 5 minute timer”. My work will enable systems to do co
 mplex tasks as part of applications\, e.g. “Plot population over the las
 t 2000 years with a trend line only and a log scale on the y-axis”.\n\nB
 io:\n\nJonathan K. Kummerfeld is a Postdoctoral Research Fellow in Compute
 r Science and Engineering at the University of Michigan. He completed his 
 Ph.D. at the University of California\, Berkeley\, advised by Prof. Dan Kl
 ein. Jonathan’s research has revealed new challenges in syntactic parsin
 g\, coreference resolution\, and dialogue. He has proposed models and algo
 rithms to address these challenges\, improving the speed and accuracy of n
 atural language processing systems. He has been on the program committee f
 or 55 conferences and workshops\, including Area Chair at ACL and Shared T
 ask Coordinator for the DSTC workshops. He currently serves as a standing 
 reviewer for the Computational Linguistics journal and the Transactions of
  the Association for Computational Linguistics journal. For more details\,
  see his website:\nhttps://www.jkk.name\n\n*Contact\nalicia.vignola@yale.e
 du\nor\nnancy.pellegrino@yale.edu\nfor Zoom link\n\n\n\n\nhttps://cpsc.yal
 e.edu/event/cs-colloquium-jonathan-k-kummerfeld
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-jonathan-k-kummerfeld
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Amy Zhang
DTSTART;VALUE=DATE-TIME:20210224T210000
DTEND;VALUE=DATE-TIME:20210224T220000
DESCRIPTION:Event description:\nCS Colloquium\nAmy Zhang\n\nTitle: Exploit
 ing latent structure and bisimulation metrics for better generalization in
  reinforcement learning\n\nHost: Marynel Vázquez\n\nAbstract:\n\nThe adve
 nt of deep learning has shepherded unprecedented progress in various field
 s of machine learning. Despite recent advances in deep reinforcement learn
 ing (RL) algorithms\, however\, there is no method today that exhibits any
 where near the generalization that we have seen in computer vision and NLP
 . Indeed\, one might ask whether deep RL algorithms are even capable of th
 e kind of generalization that is needed for open-world environments.  Thi
 s challenge is fundamental and will not be solved with incremental algorit
 hmic advances.\n\nIn this talk\, we propose to incorporate different assum
 ptions that better reflect the real world and allow the design of novel al
 gorithms with theoretical guarantees to address this fundamental problem. 
 We first present how state abstractions can accelerate reinforcement learn
 ing from rich observations\, such as images\, without relying either on do
 main knowledge or pixel-reconstruction. Our goal is to learn state abstrac
 tions that both provide for effective downstream control and invariance to
  task-irrelevant details. We use bisimulation metrics to quantify behavior
 al similarity between states\, and learn robust latent representations whi
 ch encode only the task-relevant information from observations. We provide
  theoretical guarantees for the learned approximate abstraction and extend
  this notion to families of tasks with varying dynamics.\n\nBio:\n\nI am a
  final year PhD candidate at McGill University and the Mila Institute\, co
 -supervised by Profs. Joelle Pineau and Doina Precup. I am also a research
 er at Facebook AI Research. My work focuses on bridging theory and practic
 e through learning approximate state abstractions and learning representat
 ions for generalization in reinforcement learning. I previously obtained a
 n M.Eng. in EECS and dual B.Sci. degrees in Mathematics and EECS from MIT.
 \n\n*Contact\nalicia.vignola@yale.edu\nor\nnancy.pellegrino@yale.edu\nfor 
 Zoom link\n\n\nhttps://cpsc.yale.edu/event/cs-colloquium-amy-zhang
LOCATION:Zoom Presentation*
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-amy-zhang
END:VEVENT
BEGIN:VEVENT
SUMMARY:JBPO Meeting Dates\, AY 2020-21 - Information Only
DTSTART;VALUE=DATE-TIME:20210225T210000
DTEND;VALUE=DATE-TIME:20210225T220000
DESCRIPTION:Event description:\nThe dates for the Joint Boards of Permanen
 t Officers (JBPO) have been scheduled for the 2020-21 academic year.  Ple
 ase reserve:\n\nThursday\, February 25\, 2021\n\nThursday\, April 15\, 202
 1\n\nThursday\, May 13\, 2021\n\nAll meetings start at 4:00 p.m. and will 
 be via Zoom for the foreseeable future. Two weeks prior to each meeting\, 
 an email will be sent with the link to preregister for the meeting\, along
  with the CONFIDENTIAL agenda and supporting materials. After preregisteri
 ng you will receive a confirmation email containing the Zoom link to join 
 the meeting.\n\nIn order to ensure a quorum*\, please attend if you are ab
 le\, especially if you are a designated quorum officer of your department 
 or program.\n\n*Voting in the Joint Boards of Permanent Officers. Full pro
 fessors whose primary or fully joint appointments are in a Faculty of Arts
  and Sciences department may vote\, as may full professors of professional
  schools with secondary appointments in a Faculty of Arts and Sciences dep
 artment and explicit Corporation approval for such voting rights. The only
  exception to this rule is for faculty in Molecular Biophysics and Biochem
 istry who are assigned to vote in the School of Medicine’s Board of Perm
 anent Officers and may not also vote in the Joint Boards of Permanent Offi
 cers of Yale College and the Graduate School. By long standing custom\, a 
 quorum for the conduct of business at a meeting of the Joint Boards consis
 ts of 37 members eligible to vote. No vote has force if the number of vote
 s\, plus recorded abstentions\, falls short of that number. Tenure appoint
 ments are forwarded to the Corporation only upon an affirmative vote by tw
 o-thirds of the members present and eligible to vote. All other appointmen
 ts are approved by majority vote. (Faculty Handbook\, Section IV.F.5)\n\nY
 ale University | Faculty of Arts and Sciences |\nhttp://fas.yale.edu/\n\n\
 nhttps://cpsc.yale.edu/event/jbpo-meeting-dates-ay-2020-21-information-onl
 y
LOCATION:Zoom
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/jbpo-meeting-dates-ay-2020-21-information-
 only
END:VEVENT
END:VCALENDAR
