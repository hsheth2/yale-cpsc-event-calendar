BEGIN:VCALENDAR
X-WR-CALDESC:Yale Department of Computer Science
X-WR-CALNAME:Yale CS Events
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Irene Li
DTSTART;VALUE=DATE-TIME:20220216T170000
DTEND;VALUE=DATE-TIME:20220216T180000
DESCRIPTION:Event description:\nDissertation Defense\nIrene Li\n\nTitle: N
 eural Graph Transfer Learning in Natural Language Processing Tasks\n\nAdvi
 sor: Dragomir Radev\n\nOther committee members:\nMarynel Vázquez\nYang Ca
 i\nElisa Celis\n\nAbstract:\n\nNatural language is essential in our daily 
 lives as we rely on languages to communicate and exchange information. A f
 undamental goal for natural language processing (NLP) is to let the machin
 e understand natural language to help or replace human experts to mine kno
 wledge and complete tasks.\n\nMany NLP tasks deal with sequential data. Fo
 r example\, a sentence is considered as a sequence of works. However\, not
  all tasks can be formulated using sequence models. Specifically\, graph-s
 tructured data is also fundamental in NLP\, including entity linking\, ent
 ity classification\, relation extraction\, abstractive meaning representat
 ion\, and knowledge graphs. In this scenario\,  BERT-based pretrained mod
 els may not be suitable. Graph Convolutional Neural Network (GCN) is a dee
 p neural network model designed for graphs. It has shown great potential i
 n text classification\, link prediction\, question answering and so on.\n\
 nThis dissertation presents novel graph models for NLP tasks\, including t
 ext classification\, prerequisite chain learning\, and coreference resolut
 ion. We focus on different perspectives of graph convolutional network mod
 eling: for text classification\, a novel graph construction method is prop
 osed which allows interpretability for the prediction\; for prerequisite c
 hain learning\, we propose multiple aggregation functions that utilize nei
 ghbors for better information exchange\; for coreference resolution\, we s
 tudy how graph pretraining can help when labeled data is limited. Moreover
 \, an important branch is to apply pretrained language models for the ment
 ioned tasks. So\, this dissertation also focuses on the transfer learning 
 method that generalizes pretrained models to other domains\, including med
 ical\, cross-lingual\, and web data. Finally\, we propose a new task calle
 d unsupervised cross-domain prerequisite chain learning\, and study novel 
 graph-based methods to transfer knowledge over graphs.\n\n\nhttps://cpsc.y
 ale.edu/event/dissertation-defense-irene-li
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-irene-li
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Erik Waingarten
DTSTART;VALUE=DATE-TIME:20220216T210000
DTEND;VALUE=DATE-TIME:20220216T220000
DESCRIPTION:Event description:\nCS Talk\nErik Waingarten\n\nHost: Yang Cai
 \n\nTitle: Sublinear Algorithms for Massive Datasets\n\nAbstract:\n\nThe i
 nflux of massive data systems poses a unique challenge for algorithms rese
 arch. In this modern era\, the classical theory of algorithms is often ins
 ufficient\, and our goal is to develop the theory of sublinear computation
 .\n\nThis talk will cover various scenarios where the resources used by an
  algorithm (running time\, memory\, number of measurements\, … etc) shou
 ld be significantly smaller than the input size. We will spend most of the
  time on\nsublinear time\nalgorithms for similarity search in high-dimensi
 onal spaces and\nsublinear space\nalgorithms for the optimal transport pro
 blem\, where we will present new algorithmic and analytical techniques for
  tackling these questions. A central theme throughout the talk is the noti
 on of randomized space partitions\, and how they lead to algorithms which 
 are simple\, have provable guarantees\, and are extremely useful.\n\nBio:\
 n\nErik Waingarten is an NSF Postdoctoral Fellow at Stanford University’
 s Computer Science department hosted by Moses Charikar. Prior to that\, h
 e was a research fellow at the Simons Institute for the Theory of Computin
 g. He obtained his PhD from Columbia University\, where he was advised by 
 Xi Chen and Rocco Servedio. He is interested in the design and analysis of
  algorithms for massive datasets\, with a particular focus on the interpla
 y of high-dimensional geometry\, sketching\, and property testing.\n\nTalk
  flyer\n\n\nhttps://cpsc.yale.edu/event/cs-talk-erik-waingarten
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-erik-waingarten
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Daniel Rakita
DTSTART;VALUE=DATE-TIME:20220221T210000
DTEND;VALUE=DATE-TIME:20220221T220000
DESCRIPTION:Event description:\nCS Talk\nDaniel Rakita\n\nHost: Marynel V
 ázquez\n\nTitle: Intuitive Robot Shared-Control Interfaces via Real-time 
 Motion Planning and Optimization\n\nAbstract:\n\nMy research focuses on ma
 king robots intuitive to control and work alongside for as many people as 
 possible\, specifically in areas where people are understaffed or overwork
 ed such as nursing\, homecare\, and manufacturing.  In this talk\, I will
  overview numerous robot shared-control interfaces I have developed to be 
 intuitive and easy-to-use\, even for novice users\, by blending users’ i
 nputs with robot autonomy on-the-fly.  I will highlight novel motion plan
 ning and motion optimization methods that enable these interfaces by quick
 ly synthesizing smooth\, feasible\, and safe motions that effectively refl
 ect objectives specified by the user and robot autonomy signals in real-ti
 me.  I will comment on my ongoing and future work that will push the pote
 ntial of these technical methods and physical robot systems\, all striving
  towards broad and motivating applications such as remote homecare\, tele-
 nursing\, and assistive technologies.\n\nBio:\n\nDaniel Rakita is a Ph.D. 
 candidate of computer science at the University of Wisconsin-Madison.  Hi
 s research involves creating motion optimization approaches that allow rob
 ot manipulators to move smoothly\, safely\, and accurately in real-time. 
  Using these motion algorithms as core components\, he subsequently develo
 ps and evaluates robot shared-control interfaces that are intuitive and ea
 sy to use\, even for novice users.  Previously\, he received his Master
 ’s Degree in Computer Science from the University of Wisconsin-Madison a
 nd a Bachelors of Music Performance from the Indiana University Jacobs Sch
 ool of Music.  His work has been supported by a Microsoft PhD Fellowship 
 (2019-2021) and a Cisco Graduate Student Fellowship (2021-2022).  He is a
 dvised by Michael Gleicher and Bilge Mutlu.\n\nTalk flyer\n\n\nhttps://cps
 c.yale.edu/event/cs-talk-daniel-rakita
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-daniel-rakita
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Xinyun Chen
DTSTART;VALUE=DATE-TIME:20220222T210000
DTEND;VALUE=DATE-TIME:20220222T220000
DESCRIPTION:Event description:\nCS Talk\nXinyun Chen\n\nHost: Dragomir Rad
 ev\n\nTitle: Learning-Based Program Synthesis: Learning for Program Synthe
 sis and Program Synthesis for Learning\n\nAbstract:\n\nWith the advancemen
 t of modern technologies\, programming becomes ubiquitous not only among p
 rofessional software developers\, but also for general computer users. How
 ever\, gaining programming expertise is time-consuming and challenging. Th
 erefore\, program synthesis has many applications\, where the computer aut
 omatically synthesizes programs from specifications such as natural langua
 ge descriptions and input-output examples. In this talk\, I will present m
 y work on learning-based program synthesis\, where I have developed deep l
 earning techniques for various program synthesis problems. Despite the rem
 arkable success of deep neural networks for many domains\, including natur
 al language processing and computer vision\, existing deep neural networks
  are still insufficient for handling challenging symbolic reasoning and ge
 neralization problems.\n\nMy learning-based program synthesis research lie
 s in two folds: (1) learning to synthesize programs from potentially ambig
 uous and complex specifications\; and (2) neural-symbolic learning for lan
 guage understanding. I will first talk about program synthesis application
 s\, where my work demonstrates the applicability of learning-based program
  synthesizers for production usage. I will then present my work on neural-
 symbolic frameworks that integrate symbolic components into neural network
 s\, which achieve better reasoning and generalization capabilities. In clo
 sing\, I will discuss the challenges and opportunities of further improvin
 g the complexity and generalizability of learning-based program synthesis 
 for future work.\n\nBio:\n\nXinyun Chen is a Ph.D. candidate at UC Berkele
 y\, working with Prof. Dawn Song. Her research lies at the intersection of
  deep learning\, programming languages\, and security. Her recent research
  focuses on learning-based program synthesis and adversarial machine learn
 ing. She received the Facebook Fellowship in 2020. She was selected for Ri
 sing Stars in EECS in 2020 and 2021\, and Rising Stars in Machine Learning
  in 2021.\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/cs-talk-xinyun-ch
 en
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-xinyun-chen
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Maria Pacheco
DTSTART;VALUE=DATE-TIME:20220223T210000
DTEND;VALUE=DATE-TIME:20220223T220000
DESCRIPTION:Event description:\nCS Talk\nMaria Pacheco\n\nHost: Marynel V
 ázquez\n\nTitle: Neural-Symbolic Modeling for Natural Language Discourse
 \n\nAbstract:\n\nLanguage “in the wild” is complex and ambiguous and r
 elies on a shared understanding of the world for its interpretation. Most 
 current NLP methods represent language by learning word co-occurrence patt
 erns from massive amounts of linguistic data. This representation can be v
 ery powerful\, but it is insufficient to capture the meaning behind writte
 n and spoken communication. In this talk\, I will motivate neural-symbolic
  representations for dealing with these challenges. On the one hand\, symb
 ols have inherent explanatory power\, and they can help us express domain 
 knowledge and enforce consistency across different decisions. On the other
  hand\, expressive distributed representations allow us to leverage the st
 rengths of statistical language models to make sense of large amounts of l
 inguistic data.\n\nIn this talk\, I will introduce a holistic framework th
 at covers all stages of the neural-symbolic pipeline: modeling\, learning\
 , inference\, and its application for analyzing discourse in real-world sc
 enarios and show its advantages with respect to end-to-end neural approach
 es and traditional statistical relational learning methods.\n\nBio\n:\n\nM
 aria Pacheco is a PhD Candidate in the Department of Computer Science at P
 urdue University. Her research focuses broadly on neural-symbolic methods
  to model natural language discourse scenarios\, such as analyzing convers
 ations\, argumentation\, and narratives. Before joining Purdue\, she spent
  a couple of years working as a data scientist and software engineer for v
 arious startups in her hometown of Caracas\, Venezuela. She has published 
 in top Natural Language Processing conferences and journals and has delive
 red tutorials on neural-symbolic modeling for NLP to diverse audiences\, i
 ncluding an IJCAI ‘21 tutorial and an upcoming COLING ‘22 tutorial. Ma
 ria is a recipient of the 2021 Microsoft Research Dissertation Grant\, and
  one of the main organizers of the LatinX in AI events in NLP.\n\nTalk fly
 er\n\n\nhttps://cpsc.yale.edu/event/cs-talk-maria-pacheco-0
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-maria-pacheco-0
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Arman Cohan
DTSTART;VALUE=DATE-TIME:20220228T210000
DTEND;VALUE=DATE-TIME:20220228T220000
DESCRIPTION:Event description:\nCS Talk\n\nArman\nCohan\n\nHost: Dragomir 
 Radev\n\nTitle: Beyond Sentences and Paragraphs: Towards Document and Mult
 i-document Understanding\n\nAbstract:\n\nDuring the past few years\, there
  has been significant progress in natural language understanding\, primari
 ly due to the advancements in transfer learning methods and the increasing
  scale of pre-trained language models. However\, the majority of progress 
 has been made on tasks concerning short texts with sentences or paragraphs
  as the basic unit of analysis. Yet\, many real-world natural language tas
 ks require understanding full documents which includes learning effective 
 representation of documents\, resolving longer range dependencies\, struct
 ure\, and argumentation. Further\, certain tasks require incorporating add
 itional context from multiple related documents (e.g.\, understanding a sc
 ientific paper) and aggregating information across multiple documents. In 
 this talk\, I will discuss some of our recent works on addressing these ch
 allenges. I will first discuss general methods for document representation
  learning that help to achieve strong downstream performance on a variety 
 of document-level tasks. Then I will focus on how we can have a general pr
 e-trained language model that can process long documents. Using this frame
 work\, I will discuss extensions to multi-document natural language unders
 tanding for a variety of classification\, extraction\, and summarization t
 asks. I will also briefly discuss a few of our newly developed benchmarks 
 from challenging domains that enable us to better measure progress on docu
 ment natural language understanding.\n\nBio:\n\nArman Cohan is a Research 
 Scientist at the Allen Institute for AI (AI2) and an Affiliate Assistant P
 rofessor at the University of Washington. His broad research interest is d
 eveloping natural language processing (NLP) methods for addressing informa
 tion overload. This includes models and benchmarks for document and multi-
 document understanding\, natural language generation and summarization\, a
 s well as information discovery and filtering. He is additionally interest
 ed in real-world interdisciplinary applications of NLP in the science and 
 health domains. His research has been recognized with multiple awards\, in
 cluding a best paper award at EMNLP 2017\, an honorable mention at COLING 
 2018\, and the 2019 Harold N. Glassman Distinguished Doctoral Dissertation
  award.\n\n\nhttps://cpsc.yale.edu/event/cs-talk-arman-cohan
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-arman-cohan
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - Matthew Amodio
DTSTART;VALUE=DATE-TIME:20220308T200000
DTEND;VALUE=DATE-TIME:20220308T210000
DESCRIPTION:Event description:\nDissertation Defense\nMatthew Amodio\n\nTi
 tle: Deep Learning for Embedding and Integrating Multimodal Biomedical Dat
 a\n\nAdvisor\n:\nSmita Krishnaswamy\n\nOther committee members:\n\nRonald 
 Coifman\nVladimir Rokhlin\n\nAbstract:\n\nBiomedical data is being generat
 ed in extremely high throughput and high dimension by technologies in area
 s ranging from single-cell genomics\, proteomics\, and transcriptomics (cy
 tometry\, single-cell RNA and ATAC sequencing) to neuroscience and cogniti
 on (fMRI and PET) to pharmaceuticals (drug perturbations and interactions)
 . These new and emerging technologies and the datasets they create give an
  unprecedented view into the workings of their respective biological entit
 ies. However\, there is a large gap between the information contained in t
 hese datasets and the insights that current machine learning methods can e
 xtract from them.\n\nThis is especially the case when multiple technologie
 s can measure the same underlying biological entity or system. By separate
 ly analyzing the same system but from different views gathered by differen
 t data modalities\, patterns are left unobserved if they only emerge from 
 the multi-dimensional joint representation of all of the modalities togeth
 er. Through an interdisciplinary approach that emphasizes active collabora
 tion with data domain experts\, my research has developed models for \\tex
 tbf{data integration}\, extracting important insights through the joint an
 alysis of varied data sources.\n\nIn this thesis\, I discuss models that a
 ddress this task of multi-modal data integration\, especially generative a
 dversarial networks (GANs) and autoencoders (AEs). My research has been fo
 cused on using both of these models in a generative way for concrete probl
 ems in cutting-edge scientific applications rather than the exclusive focu
 s on the generation of high-resolution natural images. The research in thi
 s thesis is united around ideas of building models that can extract new kn
 owledge from scientific data inaccessible to currently existing methods.\n
 \n\nhttps://cpsc.yale.edu/event/dissertation-defense-matthew-amodio
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-matthew-amodio
END:VEVENT
BEGIN:VEVENT
SUMMARY:Dissertation Defense - William Hallahan
DTSTART;VALUE=DATE-TIME:20220309T210000
DTEND;VALUE=DATE-TIME:20220309T220000
DESCRIPTION:Event description:\nDissertation Defense\nWilliam Hallahan\n\n
 Title: Automated Approaches for Program Verification and Repair\n\nAdviso
 r\n:\nRuzica Piskac\n\nOther committee members:\nZhong Shao\nAbhishek Bhat
 tacharjee\nNate Foster (Cornell University)\n\nAbstract:\n\nFormal methods
  techniques such as verification\, analysis\, and synthesis allow programm
 ers to prove properties of their programs\, or automatically derive progra
 ms from specifications. This dissertation presents automated analysis and 
 synthesis techniques to ease the debugging of modular verification systems
 \, allow easy access to constraint solvers from functional code\, and to r
 educe the burden of network administrators writing and analyzing firewalls
 .\n\nWe describe the design and implementation of a symbolic execution eng
 ine\, G2\, for non-strict functional languages such as Haskell. We then ex
 tended G2 to assist with modular verification. Modular verifiers allow pro
 grammers to write and prove specifications of their code. When a modular v
 erifier fails to verify a program\, it could be because of an actual bug i
 n the program\, but it could also be because a specification somewhere in 
 the program is too weak. We present a technique\, counterfactual symbolic 
 execution\, to aid in the debugging of both types of modular verification 
 failures\, by finding counterexample or counterexample-like explanations o
 f the failure. Further\, a counterexample-guided inductive synthesis (CEGI
 S) loop based technique is introduced to fully automate modular verificati
 on\, by using found counterexamples to automatically infer needed function
  specifications. The counterfactual symbolic execution and automated speci
 fication inference techniques are evaluated on existing LiquidHaskell erro
 rs and programs.\n\nIn addition to leveraging G2 to explain modular verifi
 cation errors\, we built a library\, G2Q\, which makes it easy for Haskell
  programmers to call G2 to solve constraint problem written in Haskell. G2
 Q uses symbolic execution to unroll recursive function definitions\, and g
 uarantees that the use of G2Q constraints will preserve type correctness.\
 n\nFinally\, we describe techniques to ease analysis and repair of firewal
 ls. Firewalls are widely deployed to manage network security. However\, fi
 rewall systems provide only a primitive interface\, in which the specifica
 tion is given as an ordered list of rules. This makes it hard to manually 
 track and maintain the behavior of a firewall. We introduce a formal seman
 tics for iptables firewall rules via a translation to first-order logic wi
 th uninterpreted functions and linear integer arithmetic\, which allows en
 coding of firewalls into a decidable logic. We then describe techniques to
  automate the analysis and repair of firewalls using SMT solvers\, based o
 n user provided specifications of the desired behavior. We evaluate this a
 pproach with real world case studies collected from StackOverflow users.\n
 \n\nhttps://cpsc.yale.edu/event/dissertation-defense-william-hallahan
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/dissertation-defense-william-hallahan
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Matthew Mirman
DTSTART;VALUE=DATE-TIME:20220310T153000
DTEND;VALUE=DATE-TIME:20220310T163000
DESCRIPTION:Event description:\nCS Talk\nMatthew Mirman\n\nHost: Abhishek 
 Bhattacharjee\n\nTitle: Trustworthy Deep Learning: methods\, systems and t
 heory\n\nAbstract:\n\nDeep learning models are quickly becoming an integra
 l part of a plethora of high stakes applications\, including autonomous dr
 iving and health care.  As the discovery of vulnerabilities and flaws in 
 these models has become frequent\, so has the interest in ensuring their s
 afety\, robustness and reliability.  My research addresses this need by i
 ntroducing new core methods and systems that can establish desirable mathe
 matical guarantees of deep learning models.\n\nIn the first part of my tal
 k I will describe how we leverage abstract interpretation to scale verific
 ation to orders of magnitude larger deep neural networks than prior work\,
  at the same time demonstrating the correctness of significantly more prop
 erties.  I will then show how these techniques can be extended to ensure\
 , for the first time\, formal guarantees of probabilistic semantic specifi
 cations using generative models.\n\nIn the second part\, I will show how t
 o fuse abstract interpretation with the training phase so as to improve a 
 model’s amenability to certification\, allowing us to guarantee orders o
 f magnitude more properties than possible with prior work.  Finally\, I w
 ill discuss exciting theoretical advances which address fundamental questi
 ons on the very existence of certified deep learning.\n\nBio:\n\nMatthew M
 irman is a final-year PhD student at ETH Zürich\, supervised by Martin Ve
 chev. His main research interests sit at the intersection of programming l
 anguages\, machine learning\, and theory with applications to creating saf
 e and reliable artificial intelligence systems. Prior to ETH\, he complete
 d his B.Sc. and M.Sc. at Carnegie-Mellon University supervised by Frank Pf
 enning.\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/cs-talk-matthew-mir
 man
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-matthew-mirman
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Dr. Tesca Fitzgerald
DTSTART;VALUE=DATE-TIME:20220314T200000
DTEND;VALUE=DATE-TIME:20220314T210000
DESCRIPTION:Event description:\nCS Talk\nDr. Tesca Fitzgerald\n\nHost: Bri
 an Scassellati\n\nTitle: Learning to address novel situations through huma
 n-robot collaboration\n\nAbstract\n\nAs our expectations for robots’ ada
 ptive capacities grow\, it will be increasingly important for\nthem to rea
 son about the novel objects\, tasks\, and interactions inherent to everyda
 y life. Rather\nthan attempt to pre-train a robot for all potential task v
 ariations it may encounter\, we can\ndevelop more capable and robust robot
 s by assuming they will inevitably encounter situations\nthat they are ini
 tially unprepared to address. My work enables a robot to address these nov
 el\nsituations by learning from a human teacher’s domain knowledge of th
 e task\, such as the\ncontextual use of an object or tool. Meeting this ch
 allenge requires robots to be flexible not only\nto novelty\, but to diffe
 rent forms of novelty and their varying effects on the robot’s task\ncom
 pletion. In this talk\, I will focus on (1) the implications of novelty\, 
 and its various causes\, on\nthe robot’s learning goals\, (2) methods fo
 r structuring its interaction with the human teacher in\norder to meet tho
 se learning goals\, and (3) modeling and learning from interaction-derived
 \ntraining data to address novelty.\n\nBio\n\nDr. Tesca Fitzgerald\nis a P
 ostdoctoral Fellow in the Robotics Institute at Carnegie Mellon\nUniversit
 y. Her research is centered around interactive robot learning\, with the a
 im of developing\nrobots that are adaptive\, robust\, and collaborative wh
 en faced with novel situations. Before\njoining Carnegie Mellon\, Dr. Fitz
 gerald received her PhD in Computer Science at Georgia Tech\nand completed
  her B.Sc at Portland State University. She is an NSF Graduate Research Fe
 llow\n(2014)\, Microsoft Graduate Women Scholar (2014)\, and IBM Ph.D. Fel
 low (2017).\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/cs-talk-dr-tesc
 a-fitzgerald
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-dr-tesca-fitzgerald
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Yue Wang
DTSTART;VALUE=DATE-TIME:20220315T200000
DTEND;VALUE=DATE-TIME:20220315T210000
DESCRIPTION:Event description:\nCS Talk\nYue Wang\n\nHost: Steven Zucker\n
 \nTitle: Learning 3D representations with minimal supervision\n\nAbstract:
 \n\nDeep learning has demonstrated considerable success embedding images a
 nd more general 2D representations into compact feature spaces for downstr
 eam tasks like recognition\, registration\, and generation. Learning on 3D
  data\, however\, is the missing piece needed for embodied agents to perce
 ive their surrounding environments. To bridge the gap between 3D perceptio
 n and robotic intelligence\, my present efforts focus on learning 3D repre
 sentations with minimal supervision.\n\nIn this talk\, I will discuss two 
 key aspects to reduce the amount of human supervision in current 3D deep l
 earning algorithms. First\, I will talk about how to recover structures fr
 om 3D data such as point clouds and incorporate such inductive bias into p
 oint cloud learning pipelines. Second\, I will present our works on levera
 ging natural supervision in point clouds to perform self-supervised learni
 ng. In addition\, I will discuss how these 3D learning algorithms enable h
 uman-level perception for robotic applications such as self-driving cars.
   Finally\, the talk will conclude with a discussion about future inquiri
 es to design complete and active 3D learning systems.\n\nBio:\n\nYue Wang 
 is a final year PhD student with Prof. Justin Solomon at MIT. His research
  interests lie in the intersection of computer vision\, computer graphics\
 , and machine learning. His major field is learning from point clouds. His
  paper “Dynamic Graph CNN” has been widely adopted in 3D visual comput
 ing and other fields. He is a recipient of the Nvidia Fellowship and is na
 med the first place recipient of the William A. Martin Master’s Thesis A
 ward for 2021. Yue received his BEng from Zhejiang University and MS from 
 University of California\, San Diego. He has spent time at Nvidia Research
 \, Google Research and Salesforce Research.\n\nTalk flyer\n\n\nhttps://cps
 c.yale.edu/event/cs-talk-yue-wang
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-yue-wang
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Alane Suhr
DTSTART;VALUE=DATE-TIME:20220317T143000
DTEND;VALUE=DATE-TIME:20220317T153000
DESCRIPTION:Event description:\nCS Talk\nAlane Suhr\n\nHost: Holly Rushmei
 er\n\nTitle: Reasoning and Learning in Interactive Natural Language System
 s\n\nAbstract\n\nSystems that support expressive\, situated natural langua
 ge interactions are essential for expanding access to complex computing sy
 stems\, such as robots and databases\, to non-experts. Reasoning and learn
 ing in such natural language interactions is a challenging open problem. F
 or example\, resolving sentence meaning requires reasoning not only about 
 word meaning\, but also about the interaction context\, including the hist
 ory of the interaction and the situated environment. In addition\, the seq
 uential dynamics that arise between user and system in and across interact
 ions make learning from static data\, i.e.\, supervised data\, both challe
 nging and ineffective. However\, these same interaction dynamics result in
  ample opportunities for learning from implicit and explicit feedback that
  arises naturally in the interaction. This lays the foundation for systems
  that continually learn\, improve\, and adapt their language use through i
 nteraction\, without additional annotation effort. In this talk\, I will f
 ocus on these challenges and opportunities. First\, I will describe our wo
 rk on modeling dependencies between language meaning and interaction conte
 xt when mapping natural language in interaction to executable code. In the
  second part of the talk\, I will describe our work on language understand
 ing and generation in collaborative environments\, focusing on learning to
  recover from errors and on continual learning from explicit and implicit 
 user feedback.\n\nBio\n\nAlane Suhr is a PhD Candidate in the Department o
 f Computer Science at Cornell University\,  advised by Yoav Artzi. Her re
 search spans natural language processing\, machine learning\, and computer
  vision\, with a focus on building systems that participate and continuall
 y learn in situated natural language interactions with human users. Alane
 ’s work has been recognized by paper awards at ACL and NAACL\, and has b
 een supported by fellowships and grants\, including an NSF Graduate Resear
 ch Fellowship\, a Facebook PhD Fellowship\, and research awards from AI2\,
  ParlAI\, and AWS. Alane has also co-organized multiple workshops and tuto
 rials appearing at NeurIPS\, EMNLP\, NAACL\, and ACL. Previously\, Alane r
 eceived a BS in Computer Science and Engineering as an Eminence Fellow at 
 the Ohio State University.\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/
 cs-talk-alane-suhr
LOCATION:TBA
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-alane-suhr
END:VEVENT
END:VCALENDAR
