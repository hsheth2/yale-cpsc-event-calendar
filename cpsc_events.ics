BEGIN:VCALENDAR
X-WR-CALDESC:Yale Department of Computer Science
X-WR-CALNAME:Yale CS Events
BEGIN:VEVENT
SUMMARY:CS Talk - Yuanzhi Li\, CMU
DTSTART;VALUE=DATE-TIME:20201106T160000
DTEND;VALUE=DATE-TIME:20201106T170000
DESCRIPTION:Event description:\nCS Talk\n\nYuanzhi Li\n\, CMU\n\nTitle: On
  the power of over-parameterization in neural networks – Going beyond N
 TKs\n\nZoom link:\nhttps://yale.zoom.us/j/97035602733\n\nHost: Nisheeth Vi
 shnoi\n\nAbstract:\n\nOver-parameterization is one of the most widely used
  tools in deep learning: It has been observed that larger neural networks 
 (e.g. networks with much more parameters than the total number of trainin
 g data) are often much easier to train and also generalizes better compar
 ing to smaller ones. Prior works try to explain this phenomenon in the lan
 guage of neural tangent kernels (NTKs)\, which shows the power of the over
 -parameterized neural network to learn functions that are learnable by ker
 nel methods. In this work\, we go beyond the theory of NTKs and consider 
 the power of over-parameterization in ReLU neural networks when the target
  function is (provably) not learnable by kernel methods.\n\nIn this work\,
  we look at the most simple example in this regime\, where the concept cla
 ss consists of (proper-parameterized) two-layer ReLU neural networks and t
 he input follows from standard Gaussian distribution. In this case\, to le
 arn functions from this concept class\, we prove (1). Any kernel methods (
 including those NTKs given by any neural networks of any structure) can n
 ot achieve small generalization error unless super polynomially many trai
 ning examples are used. (2). (Poly-size) Over-parameterized two-layer ReLU
  neural networks can learn the target efficiently (using poly-sample and 
 in poly-time)\, simply using (stochastic) gradient descent starting from
  random initialization.\n\nOur work relies on a brand new framework for an
 alyzing over-parameterization in deep learning: We first show that in the 
 ideal case where there are infinitely many neurons and infinitely many tra
 ining examples\, the training objective reduces to a mixture of PCA + ten
 sor decomposition objectives. Although being highly non-convex\, we show t
 hat starting from random initialization\, gradient descent can still opt
 imize this objective efficiently. We then introduce an efficient coupling 
 between the idealized process and the poly-sample\, poly-neuron case\, sho
 wing the convergence of the latter.\n\nPaper:\nhttps://arxiv.org/abs/2007.
 04596\n\nBio:\n\nYuanzhi Li is an assistant professor at CMU\, Machine Le
 arning Department (2019-present). He did his Ph.D. at Princeton\, under th
 e advice of Sanjeev Arora (2014-2018) followed by a one-year postdoc at St
 anford.\n\n\nhttps://cpsc.yale.edu/event/cs-talk-yuanzhi-li-cmu
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-yuanzhi-li-cmu
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Distinguished Colloquium - Hayley Iben\, Pixar
DTSTART;VALUE=DATE-TIME:20201113T210000
DTEND;VALUE=DATE-TIME:20201113T220000
DESCRIPTION:Event description:\nCS Distinguished Colloquium\n\nSpeaker: Ha
 yley Iben\, Pixar\n\nTitle: Simulating Hair for Animated Films\n\nHost: Te
 d Kim\n\nAbstract:\n\nHair simulation in animated feature films presents m
 any challenges\, ranging from incorporating artistic control to dealing wi
 th extreme\, non-physical character motion. In a production environment\, 
 hair simulation needs to be fast\, stable\, and usable without excessive p
 arameter tuning in order to produce content efficiently. These challenges 
 only increase when simulating a variety of hair styles on numerous charact
 ers in the film. In this talk I will present our method for stably simulat
 ing stylized hair that addresses these artistic needs and performance dema
 nds. In addition to the underlying hair model that defines the physical mo
 tion\, I will discuss various artistic controls and approaches used to pro
 duce our final hair simulations in several feature films.\n\nBio:\n\nHayle
 y Iben is the Director of Engineering for Applications in the Software R&D
  department at Pixar Animation Studios. Her teams are responsible for film
  production technologies for sets\, layout\, characters\, shading\, crowds
 \, animation\, simulation\, lighting and rendering. Prior to undertaking t
 his role\, Hayley led the engineering team responsible for character simul
 ation technologies\, including cloth\, hair\, flesh\, and skin\, for seven
  of her fourteen years at the studio. Hayley’s expertise is in hair simu
 lation and she has been developing the studio’s hair technology\, Taz\, 
 that debuted in Disney Pixar’s “Brave”. She has also built tools for
  character articulation and animation\, focusing on inverse kinematics and
  mathematical techniques. Hayley earned a B.S. in computer science from Du
 quesne University and a M.S. and Ph.D. in computer science from the Univer
 sity of California\, Berkeley.\n\n\nhttps://cpsc.yale.edu/event/cs-disting
 uished-colloquium-hayley-iben-pixar
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-distinguished-colloquium-hayley-iben-pi
 xar
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Distinguished Colloquium - Joel Emer\, MIT
DTSTART;VALUE=DATE-TIME:20201204T210000
DTEND;VALUE=DATE-TIME:20201204T220000
DESCRIPTION:Event description:\nCS Distinguished Colloquium\n\nSpeaker:\nJ
 oel Emer\, MIT\n\nHost: Abhishek Bhattacharjee\n\nTitle: Data Orchestratio
 n is the New Compute: Computer Architecture for the Post-Moore Era\n\nHost
 : Abhishek Bhattacharjee\n\nAbstract:\n\nRecent history is replete with my
 riad examples of new applications that have changed the course of computin
 g and the world. These include the spreadsheet\, visual editing\, graphics
 \, networking and many more. Behind each of these advances were programs d
 eveloped on easily-programmable and ever-faster processors. Unfortunately\
 , as is widely acknowledged\, the technological trend articulated by Moore
 ’s Law\, which contributed significantly to creating the “ever faster
 ” part of that recipe\, is dead (or at least slowing significantly). How
 ever\, as outlined in our “Science” article\, “There’s plenty of r
 oom at the top”\, there is promise in continuing Moore’s Law-like impr
 ovements through a multi-pronged approach that includes software performan
 ce engineering\, algorithm improvements and hardware architecture advances
 . Among those researchers focusing on the hardware architecture advances p
 rong\, there are many who advocate significant specialization of the hardw
 are to specific domains\, which will typically be well-understood and of w
 idely-acknowledged importance. This approach\, however\, is likely to impe
 de the development of the next big application because there will be no ge
 nerally-programmable platform on which to develop it. Therefore\, I believ
 e that the biggest challenge in evolving hardware architectures in the pos
 t-Moore era lies in striking the right balance between preserving broad pr
 ogammability and enhancing efficiency. In this talk\, I will discuss how w
 e have approached that challenge by focusing on the aspects of the hardwar
 e that gives the most leverage to improve efficiency and by providing an a
 bstraction that make it possible to compile to the new hardware.  More s
 pecifically\, since data movement has become the dominant consumer of ener
 gy\, I will describe structures that facilitate “data orchestration” t
 hat reduce and optimize data movement. I also will describe abstractions t
 hat are intended to made it possible to compile high-level programs to the
 se new hardware structures.\n\nBio:\n\nFor over 40 years\, Joel Emer held 
 various research and advanced development positions investigating processo
 r microarchitecture and developing performance modeling and evaluation tec
 hniques. He has made architectural contributions to a number of VAX\, Alph
 a and X86 processors and is recognized as one of the developers of the wid
 ely employed quantitative approach to processor performance evaluation. Mo
 re recently\, he has been recognized for his contributions in the advancem
 ent of deep learning accelerator design\, spatial and parallel architectur
 es\, processor reliability analysis\, cache organization and simultaneous 
 multithreading. Currently he is a professor at the Massachusetts Institute
  of Technology and spends part time as a Senior Distinguished Research Sci
 entist in Nvidia’s Architecture Research group. Previously\, he worked a
 t Intel where he was an Intel Fellow and Director of Microarchitecture Res
 earch.  Even earlier\, he worked at Compaq and Digital Equipment Corpora
 tion. He earned a doctorate in electrical engineering from the University 
 of Illinois in 1979. He received a bachelor’s degree with highest honors
  in electrical engineering in 1974\, and his master’s degree in 1975 –
  both from Purdue University. Recognitions of his contributions include an
  ACM/SIGARCH-IEEE-CS/TCCA Most Influential Paper Award for his work on sim
 ultaneous multithreading\, and six other papers that were selected as IEEE
  Micro’s Top Picks in Computer Architecture.  Among hisprofessional ho
 nors\, he is a Fellow of both the ACM and IEEE\, and a member of the NAE. 
 In 2009 he was recipient of the Eckert-Mauchly award for lifetime contribu
 tions in computer architecture.\n\n\nhttps://cpsc.yale.edu/event/cs-distin
 guished-colloquium-joel-emer-mit
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-distinguished-colloquium-joel-emer-mit
END:VEVENT
BEGIN:VEVENT
SUMMARY:JBPO Meeting Dates\, AY 2020-21 - Information Only
DTSTART;VALUE=DATE-TIME:20201210T210000
DTEND;VALUE=DATE-TIME:20201210T220000
DESCRIPTION:Event description:\nThe dates for the Joint Boards of Permanen
 t Officers (JBPO) have been scheduled for the 2020-21 academic year.  Ple
 ase reserve:\n\nThursday\, December 10\, 2020\n\nThursday\, February 25\, 
 2021\n\nThursday\, April 15\, 2021\n\nThursday\, May 13\, 2021\n\nAll meet
 ings start at 4:00 p.m. and will be via Zoom for the foreseeable future. T
 wo weeks prior to each meeting\, an email will be sent with the link to pr
 eregister for the meeting\, along with the CONFIDENTIAL agenda and support
 ing materials. After preregistering you will receive a confirmation email 
 containing the Zoom link to join the meeting.\n\nIn order to ensure a quor
 um*\, please attend if you are able\, especially if you are a designated q
 uorum officer of your department or program.\n\n*Voting in the Joint Board
 s of Permanent Officers. Full professors whose primary or fully joint appo
 intments are in a Faculty of Arts and Sciences department may vote\, as ma
 y full professors of professional schools with secondary appointments in a
  Faculty of Arts and Sciences department and explicit Corporation approval
  for such voting rights. The only exception to this rule is for faculty in
  Molecular Biophysics and Biochemistry who are assigned to vote in the Sch
 ool of Medicine’s Board of Permanent Officers and may not also vote in t
 he Joint Boards of Permanent Officers of Yale College and the Graduate Sch
 ool. By long standing custom\, a quorum for the conduct of business at a m
 eeting of the Joint Boards consists of 37 members eligible to vote. No vot
 e has force if the number of votes\, plus recorded abstentions\, falls sho
 rt of that number. Tenure appointments are forwarded to the Corporation on
 ly upon an affirmative vote by two-thirds of the members present and eligi
 ble to vote. All other appointments are approved by majority vote. (Facult
 y Handbook\, Section IV.F.5)\n\nYale University | Faculty of Arts and Scie
 nces |\nhttp://fas.yale.edu/\n\n\nhttps://cpsc.yale.edu/event/jbpo-meeting
 -dates-ay-2020-21-information-only
LOCATION:Zoom
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/jbpo-meeting-dates-ay-2020-21-information-
 only
END:VEVENT
END:VCALENDAR
