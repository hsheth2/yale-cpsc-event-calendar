BEGIN:VCALENDAR
X-WR-CALDESC:Yale Department of Computer Science
X-WR-CALNAME:Yale CS Events
BEGIN:VEVENT
SUMMARY:CS Talk - Alex Wong
DTSTART;VALUE=DATE-TIME:20220328T200000
DTEND;VALUE=DATE-TIME:20220328T210000
DESCRIPTION:Event description:\nCS Talk\nAlex Wong\n\nHost: Steve Zucker\n
 \nTitle: Towards Depth Perception for Embodied Cognition\n\nAbstract:\n\nE
 mbodied cognition entails the ability to adapt one’s understanding of th
 e physical world through interactions with the surrounding space. Amongst 
 the many aspects of intelligence encompassed by embodied cognition\, we fo
 cus on depth perception to support agents performing spatial tasks. While 
 deep learning has seen a number of empirical successes\, many of the exist
 ing works are not suitable for realizing embodied cognition due to (i) the
 ir computational requirements i.e. model sizes up to trillions of paramete
 rs\, (ii) their need for expensive human annotations as supervision\, and 
 (iii) their sensitivity to small perturbations in their inputs. To address
  these areas\, we begin by proposing a method that enables an agent to lea
 rn to infer the structure of the 3-dimensional scene from multi-sensory ob
 servations – online\, causally\, and without human supervision. By lever
 aging priors about our physical world during the learning process or as an
  inductive bias\, we show that it is not only possible to reduce the model
  size\, but also gain performance to yield real-time depth perception syst
 ems with state-of-the-art accuracies. These priors can also improve the ro
 bustness of such systems against common perturbations of their inputs as w
 ell as adversarial perturbations that are designed to disrupt their normal
  operations. The culmination of our work is being realized in an interdepa
 rtmental collaboration at UCLA to build the first fully autonomous catarac
 t surgery robot. We plan to take another step towards embodied cognition b
 y building on top of my progress in depth perception to enable an agent to
  learn the semantics of objects populating the scene without human interve
 ntion.\n\nBio:\n\nAlex Wong is a postdoctoral scholar at the University of
  California\, Los Angeles (UCLA) under the guidance of Stefano Soatto. He 
 received his Ph.D. from UCLA\, and was co-advised by Stefano Soatto and Al
 an Yuille. His research lies in the intersection of machine learning\, com
 puter vision\, and robotics. His work has received the outstanding student
  paper award at the Conference on Neural Information Processing Systems (N
 eurIPS) 2011 and the best paper award in robot vision at the International
  Conference on Robotics and Automation (ICRA) 2019.\n\nTalk flyer\n\n\nhtt
 ps://cpsc.yale.edu/event/cs-talk-alex-wong
LOCATION:Zoom Presentation
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-alex-wong
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Talk - Hao Peng
DTSTART;VALUE=DATE-TIME:20220329T200000
DTEND;VALUE=DATE-TIME:20220329T210000
DESCRIPTION:Event description:\nCS Talk\nHao Peng\n\nHost: Dragomir Radev\
 n\nTitle: Towards Efficient and Generalizable Natural Language Processing\
 n\nAbstract:\n\nLarge-scale deep learning models have become the foundatio
 n of today’s natural language processing (NLP). Despite their recent\, t
 remendous success\, they struggle with generalization in real-world settin
 gs\, like their predecessors. Besides\, their sheer scale brings new chall
 enges—the increasing computational cost heightens the barriers to entry 
 to NLP research.\n\nThe first part of the talk will discuss innovations in
  neural architectures that can help address the efficiency concerns of tod
 ay’s NLP. I will present algorithms that reduce state-of-the-art NLP mod
 els’ overhead from quadratic to linear in input lengths without hurting 
 accuracy. Second\, I will turn to inductive biases grounded in the inheren
 t structure of natural language sentences\, which can help machine learnin
 g models generalize. I will discuss the integration of discrete\, symbolic
  structure prediction into modern deep learning.\n\nI will conclude with f
 uture directions towards making cutting-edge NLP more efficient\, and impr
 oving NLP’s generalization to serve today’s language technology applic
 ations and those to come in the future.\n\nBio:\n\nHao Peng is a final yea
 r PhD student in Computer Science & Engineering at the University of Washi
 ngton\, advised by Noah A. Smith. His research focuses on building efficie
 nt\, generalizable\, and interpretable machine learning models for natural
  language processing. His research has been presented at top-tier natural 
 language processing and machine learning venues\, and recognized with a Go
 ogle PhD fellowship and an honorable mention for the best paper at ACL 201
 8.\n\nTalk flyer\n\n\nhttps://cpsc.yale.edu/event/cs-talk-hao-peng
LOCATION:TBA
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-talk-hao-peng
END:VEVENT
BEGIN:VEVENT
SUMMARY:CS Colloquium - Richard L. Sites
DTSTART;VALUE=DATE-TIME:20220405T200000
DTEND;VALUE=DATE-TIME:20220405T210000
DESCRIPTION:Event description:\nCS Colloquium\nRichard L. Sites\n\nHost: M
 ichael Fischer\n\nTitle: Making the Invisible Visible\nObserving Complex S
 oftware Dynamics\n\nAbstract\n\nFrom mobile and cloud apps to video games 
 to driverless vehicle control\, more and more software is time-constrained
 : it must deliver reliable results seamlessly\, consistently\, and virtual
 ly instantaneously. If it doesn’t\, customers are unhappy–and sometime
 s lives are put at risk. When complex software underperforms or fails\, id
 entifying the root causes is difficult and\, historically\, few tools have
  been available to help\, leaving application developers to guess what mig
 ht be happening. How can we do better?\n\nThe key is to have low-overhead 
 observation tools that can show exactly where all the  elapsed time goes 
 in both normal responses and in delayed responses. Doing so makes visible 
 each of the seven possible reasons for such delays\, as we show.\n\nBio\n\
 nRichard L. Sites wrote his first computer program in 1959 and has spent m
 ost of his career at the boundary between hardware and software\, with a p
 articular interest in CPU/software performance interactions. His past work
  includes VAX microcode\, DEC Alpha co-architect\, and inventing the perfo
 rmance counters found in nearly all processors today. He has done low-over
 head microcode and software tracing at DEC\, Adobe\, Google\, and Tesla. D
 r. Sites earned his PhD at Stanford in 1974\; he holds 66 patents and is a
  member of the US National Academy of Engineering.\n\n\nhttps://cpsc.yale.
 edu/event/cs-colloquium-richard-l-sites
LOCATION:AKW 200
STATUS:CONFIRMED
URL:https://cpsc.yale.edu/event/cs-colloquium-richard-l-sites
END:VEVENT
END:VCALENDAR
